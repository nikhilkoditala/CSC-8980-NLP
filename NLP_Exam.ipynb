{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Exam.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPvSmUYn1Cl0QF8C8l78MDD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhilkoditala/CSC-8980-NLP/blob/main/NLP_Exam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkPgLTWcpcSy"
      },
      "source": [
        "## Name: Nikhil Koditala\n",
        "## Panther ID: 002571023"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0cm3XjuphKw"
      },
      "source": [
        "# Warning Imported google.colab"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bvwSJhxY6tA"
      },
      "source": [
        "# utility\n",
        "from google.colab import drive\n",
        "import os,random, re\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import spacy\n",
        "\n",
        "# sklearn models\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# vectorization methods\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gvjEDbTKaoJQ",
        "outputId": "eb00f111-63e5-4529-ed90-9049f665f1ab"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fEIXN-rKls-Q",
        "outputId": "ef73b791-0d37-400c-92c5-01068296cb59"
      },
      "source": [
        "# unzipping files\n",
        "!unzip /content/drive/MyDrive/exam1_dataset.zip"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: exam1_dataset/TRAINING/positive/5511_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5512_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5513_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5514_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5515_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5516_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5517_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5518_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5519_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/551_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5520_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5521_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5522_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5523_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5524_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5525_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5526_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5527_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5528_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5529_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/552_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5530_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5531_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5532_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5533_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5534_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5535_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5536_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5537_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5538_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5539_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/553_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5540_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5541_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5542_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5543_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5544_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5545_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5546_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5547_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5548_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5549_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/554_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5550_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5551_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5552_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5553_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5554_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5555_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5556_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5557_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5558_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5559_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/555_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5560_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5561_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5562_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5563_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5564_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5565_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5566_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5567_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5568_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5569_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/556_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5570_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5571_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5572_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5573_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5574_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5575_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5576_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5577_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5578_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5579_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/557_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5580_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5581_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5582_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5583_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5584_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5585_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5586_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5587_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5588_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5589_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/558_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5590_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5591_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5592_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5593_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5594_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5595_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5596_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5597_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5598_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5599_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/559_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/55_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5600_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5601_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5602_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5603_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5604_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5605_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5606_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5607_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5608_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5609_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/560_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5610_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5611_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5612_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5613_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5614_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5615_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5616_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5617_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5618_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5619_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/561_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5620_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5621_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5622_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5623_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5624_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5625_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5626_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5627_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5628_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5629_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/562_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5630_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5631_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5632_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5633_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5634_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5635_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5636_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5637_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5638_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5639_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/563_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5640_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5641_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5642_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5643_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5644_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5645_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5646_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5647_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5648_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5649_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/564_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5650_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5651_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5652_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5653_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5654_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5655_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5656_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5657_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5658_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5659_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/565_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5660_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5661_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5662_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5663_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5664_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5665_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5666_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5667_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5668_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5669_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/566_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5670_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5671_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5672_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5673_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5674_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5675_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5676_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5677_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5678_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5679_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/567_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5680_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5681_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5682_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5683_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5684_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5685_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5686_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5687_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5688_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5689_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/568_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5690_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5691_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5692_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5693_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5694_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5695_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5696_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5697_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5698_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5699_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/569_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/56_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5700_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5701_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5702_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5703_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5704_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5705_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5706_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5707_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5708_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5709_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/570_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5710_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5711_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5712_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5713_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5714_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5715_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5716_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5717_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5718_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5719_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/571_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5720_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5721_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5722_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5723_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5724_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5725_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5726_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5727_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5728_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5729_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/572_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5730_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5731_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5732_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5733_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5734_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5735_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5736_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5737_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5738_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5739_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/573_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5740_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5741_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5742_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5743_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5744_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5745_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5746_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5747_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5748_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5749_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/574_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5750_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5751_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5752_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5753_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5754_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5755_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5756_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5757_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5758_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5759_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/575_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5760_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5761_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5762_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5763_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5764_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5765_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5766_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5767_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5768_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5769_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/576_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5770_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5771_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5772_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5773_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5774_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5775_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5776_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5777_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5778_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5779_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/577_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5780_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5781_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5782_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5783_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5784_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5785_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5786_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5787_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5788_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5789_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/578_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5790_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5791_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5792_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5793_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5794_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5795_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5796_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5797_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5798_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5799_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/579_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/57_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5800_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5801_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5802_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5803_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5804_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5805_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5806_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5807_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5808_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5809_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/580_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5810_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5811_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5812_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5813_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5814_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5815_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5816_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5817_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5818_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5819_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/581_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5820_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5821_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5822_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5823_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5824_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5825_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5826_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5827_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5828_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5829_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/582_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5830_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5831_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5832_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5833_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5834_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5835_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5836_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5837_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5838_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5839_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/583_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5840_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5841_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5842_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5843_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5844_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5845_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5846_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5847_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5848_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5849_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/584_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5850_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5851_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5852_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5853_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5854_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5855_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5856_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5857_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5858_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5859_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/585_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5860_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5861_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5862_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5863_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5864_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5865_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5866_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5867_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5868_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5869_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/586_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5870_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5871_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5872_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5873_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5874_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5875_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5876_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5877_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5878_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5879_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/587_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5880_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5881_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5882_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5883_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5884_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5885_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5886_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5887_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5888_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5889_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/588_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5890_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5891_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5892_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5893_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5894_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5895_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5896_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5897_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5898_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5899_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/589_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/58_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5900_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5901_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5902_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5903_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5904_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5905_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5906_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5907_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5908_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5909_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/590_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5910_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5911_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5912_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5913_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5914_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5915_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5916_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5917_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5918_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5919_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/591_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5920_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5921_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5922_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5923_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5924_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5925_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5926_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5927_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5928_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5929_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/592_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5930_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5931_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5932_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5933_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5934_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5935_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5936_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5937_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5938_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5939_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/593_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5940_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5941_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5942_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5943_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5944_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5945_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5946_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5947_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5948_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5949_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/594_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5950_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5951_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5952_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5953_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5954_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5955_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5956_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5957_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5958_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5959_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/595_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5960_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5961_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5962_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5963_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5964_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5965_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5966_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5967_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5968_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5969_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/596_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5970_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5971_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5972_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5973_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5974_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5975_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5976_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5977_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5978_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5979_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/597_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5980_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5981_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5982_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5983_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5984_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5985_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5986_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5987_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5988_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5989_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/598_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5990_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5991_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5992_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5993_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5994_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5995_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5996_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5997_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5998_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5999_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/599_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/59_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/5_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6000_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6001_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6002_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6003_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6004_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6005_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6006_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6007_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6008_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6009_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/600_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6010_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6011_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6012_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6013_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6014_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6015_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6016_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6017_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6018_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6019_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/601_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6020_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6021_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6022_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6023_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6024_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6025_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6026_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6027_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6028_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6029_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/602_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6030_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6031_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6032_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6033_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6034_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6035_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6036_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6037_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6038_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6039_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/603_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6040_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6041_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6042_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6043_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6044_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6045_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6046_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6047_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6048_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6049_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/604_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6050_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6051_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6052_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6053_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6054_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6055_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6056_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6057_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6058_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6059_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/605_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6060_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6061_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6062_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6063_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6064_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6065_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6066_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6067_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6068_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6069_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/606_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6070_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6071_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6072_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6073_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6074_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6075_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6076_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6077_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6078_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6079_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/607_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6080_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6081_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6082_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6083_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6084_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6085_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6086_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6087_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6088_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6089_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/608_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6090_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6091_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6092_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6093_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6094_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6095_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6096_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6097_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6098_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6099_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/609_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/60_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6100_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6101_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6102_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6103_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6104_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6105_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6106_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6107_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6108_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6109_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/610_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6110_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6111_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6112_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6113_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6114_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6115_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6116_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6117_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6118_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6119_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/611_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6120_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6121_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6122_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6123_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6124_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6125_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6126_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6127_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6128_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6129_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/612_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6130_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6131_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6132_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6133_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6134_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6135_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6136_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6137_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6138_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6139_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/613_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6140_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6141_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6142_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6143_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6144_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6145_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6146_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6147_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6148_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6149_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/614_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6150_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6151_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6152_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6153_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6154_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6155_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6156_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6157_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6158_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6159_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/615_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6160_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6161_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6162_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6163_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6164_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6165_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6166_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6167_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6168_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6169_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/616_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6170_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6171_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6172_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6173_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6174_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6175_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6176_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6177_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6178_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6179_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/617_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6180_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6181_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6182_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6183_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6184_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6185_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6186_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6187_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6188_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6189_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/618_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6190_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6191_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6192_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6193_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6194_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6195_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6196_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6197_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6198_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6199_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/619_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/61_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6200_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6201_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6202_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6203_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6204_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6205_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6206_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6207_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6208_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6209_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/620_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6210_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6211_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6212_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6213_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6214_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6215_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6216_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6217_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6218_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6219_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/621_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6220_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6221_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6222_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6223_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6224_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6225_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6226_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6227_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6228_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6229_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/622_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6230_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6231_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6232_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6233_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6234_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6235_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6236_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6237_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6238_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6239_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/623_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6240_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6241_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6242_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6243_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6244_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6245_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6246_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6247_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6248_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6249_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/624_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6250_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6251_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6252_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6253_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6254_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6255_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6256_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6257_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6258_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6259_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/625_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6260_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6261_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6262_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6263_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6264_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6265_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6266_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6267_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6268_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6269_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/626_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6270_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6271_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6272_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6273_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6274_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6275_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6276_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6277_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6278_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6279_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/627_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6280_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6281_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6282_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6283_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6284_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6285_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6286_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6287_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6288_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6289_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/628_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6290_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6291_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6292_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6293_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6294_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6295_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6296_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6297_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6298_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6299_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/629_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/62_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6300_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6301_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6302_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6303_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6304_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6305_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6306_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6307_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6308_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6309_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/630_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6310_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6311_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6312_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6313_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6314_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6315_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6316_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6317_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6318_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6319_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/631_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6320_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6321_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6322_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6323_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6324_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6325_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6326_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6327_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6328_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6329_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/632_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6330_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6331_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6332_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6333_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6334_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6335_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6336_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6337_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6338_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6339_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/633_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6340_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6341_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6342_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6343_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6344_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6345_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6346_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6347_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6348_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6349_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/634_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6350_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6351_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6352_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6353_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6354_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6355_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6356_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6357_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6358_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6359_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/635_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6360_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6361_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6362_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6363_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6364_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6365_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6366_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6367_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6368_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6369_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/636_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6370_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6371_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6372_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6373_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6374_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6375_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6376_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6377_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6378_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6379_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/637_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6380_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6381_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6382_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6383_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6384_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6385_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6386_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6387_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6388_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6389_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/638_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6390_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6391_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6392_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6393_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6394_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6395_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6396_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6397_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6398_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6399_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/639_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/63_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6400_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6401_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6402_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6403_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6404_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6405_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6406_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6407_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6408_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6409_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/640_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6410_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6411_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6412_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6413_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6414_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6415_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6416_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6417_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6418_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6419_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/641_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6420_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6421_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6422_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6423_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6424_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6425_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6426_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6427_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6428_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6429_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/642_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6430_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6431_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6432_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6433_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6434_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6435_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6436_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6437_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6438_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6439_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/643_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6440_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6441_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6442_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6443_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6444_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6445_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6446_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6447_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6448_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6449_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/644_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6450_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6451_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6452_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6453_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6454_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6455_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6456_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6457_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6458_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6459_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/645_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6460_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6461_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6462_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6463_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6464_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6465_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6466_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6467_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6468_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6469_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/646_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6470_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6471_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6472_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6473_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6474_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6475_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6476_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6477_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6478_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6479_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/647_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6480_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6481_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6482_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6483_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6484_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6485_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6486_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6487_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6488_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6489_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/648_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6490_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6491_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6492_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6493_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6494_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6495_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6496_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6497_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6498_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6499_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/649_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/64_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6500_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6501_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6502_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6503_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6504_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6505_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6506_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6507_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6508_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6509_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/650_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6510_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6511_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6512_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6513_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6514_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6515_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6516_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6517_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6518_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6519_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/651_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6520_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6521_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6522_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6523_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6524_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6525_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6526_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6527_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6528_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6529_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/652_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6530_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6531_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6532_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6533_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6534_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6535_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6536_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6537_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6538_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6539_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/653_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6540_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6541_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6542_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6543_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6544_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6545_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6546_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6547_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6548_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6549_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/654_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6550_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6551_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6552_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6553_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6554_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6555_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6556_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6557_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6558_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6559_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/655_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6560_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6561_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6562_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6563_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6564_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6565_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6566_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6567_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6568_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6569_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/656_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6570_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6571_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6572_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6573_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6574_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6575_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6576_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6577_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6578_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6579_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/657_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6580_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6581_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6582_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6583_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6584_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6585_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6586_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6587_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6588_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6589_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/658_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6590_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6591_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6592_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6593_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6594_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6595_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6596_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6597_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6598_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6599_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/659_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/65_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6600_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6601_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6602_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6603_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6604_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6605_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6606_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6607_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6608_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6609_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/660_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6610_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6611_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6612_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6613_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6614_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6615_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6616_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6617_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6618_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6619_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/661_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6620_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6621_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6622_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6623_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6624_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6625_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6626_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6627_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6628_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6629_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/662_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6630_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6631_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6632_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6633_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6634_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6635_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6636_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6637_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6638_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6639_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/663_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6640_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6641_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6642_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6643_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6644_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6645_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6646_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6647_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6648_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6649_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/664_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6650_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6651_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6652_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6653_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6654_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6655_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6656_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6657_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6658_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6659_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/665_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6660_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6661_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6662_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6663_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6664_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6665_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6666_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6667_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6668_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6669_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/666_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6670_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6671_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6672_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6673_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6674_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6675_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6676_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6677_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6678_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6679_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/667_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6680_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6681_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6682_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6683_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6684_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6685_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6686_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6687_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6688_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6689_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/668_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6690_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6691_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6692_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6693_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6694_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6695_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6696_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6697_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6698_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6699_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/669_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/66_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6700_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6701_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6702_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6703_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6704_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6705_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6706_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6707_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6708_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6709_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/670_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6710_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6711_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6712_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6713_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6714_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6715_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6716_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6717_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6718_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6719_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/671_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6720_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6721_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6722_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6723_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6724_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6725_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6726_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6727_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6728_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6729_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/672_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6730_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6731_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6732_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6733_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6734_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6735_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6736_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6737_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6738_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6739_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/673_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6740_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6741_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6742_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6743_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6744_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6745_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6746_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6747_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6748_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6749_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/674_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6750_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6751_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6752_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6753_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6754_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6755_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6756_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6757_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6758_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6759_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/675_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6760_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6761_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6762_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6763_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6764_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6765_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6766_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6767_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6768_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6769_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/676_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6770_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6771_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6772_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6773_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6774_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6775_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6776_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6777_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6778_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6779_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/677_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6780_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6781_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6782_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6783_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6784_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6785_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6786_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6787_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6788_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6789_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/678_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6790_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6791_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6792_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6793_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6794_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6795_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6796_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6797_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6798_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6799_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/679_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/67_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6800_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6801_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6802_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6803_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6804_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6805_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6806_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6807_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6808_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6809_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/680_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6810_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6811_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6812_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6813_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6814_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6815_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6816_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6817_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6818_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6819_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/681_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6820_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6821_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6822_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6823_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6824_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6825_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6826_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6827_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6828_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6829_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/682_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6830_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6831_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6832_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6833_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6834_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6835_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6836_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6837_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6838_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6839_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/683_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6840_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6841_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6842_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6843_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6844_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6845_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6846_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6847_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6848_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6849_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/684_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6850_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6851_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6852_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6853_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6854_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6855_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6856_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6857_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6858_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6859_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/685_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6860_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6861_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6862_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6863_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6864_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6865_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6866_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6867_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6868_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6869_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/686_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6870_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6871_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6872_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6873_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6874_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6875_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6876_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6877_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6878_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6879_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/687_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6880_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6881_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6882_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6883_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6884_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6885_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6886_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6887_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6888_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6889_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/688_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6890_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6891_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6892_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6893_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6894_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6895_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6896_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6897_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6898_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6899_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/689_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/68_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6900_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6901_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6902_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6903_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6904_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6905_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6906_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6907_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6908_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6909_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/690_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6910_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6911_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6912_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6913_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6914_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6915_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6916_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6917_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6918_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6919_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/691_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6920_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6921_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6922_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6923_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6924_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6925_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6926_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6927_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6928_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6929_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/692_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6930_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6931_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6932_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6933_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6934_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6935_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6936_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6937_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6938_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6939_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/693_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6940_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6941_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6942_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6943_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6944_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6945_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6946_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6947_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6948_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6949_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/694_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6950_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6951_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6952_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6953_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6954_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6955_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6956_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6957_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6958_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6959_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/695_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6960_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6961_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6962_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6963_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6964_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6965_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6966_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6967_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6968_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6969_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/696_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6970_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6971_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6972_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6973_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6974_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6975_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6976_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6977_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6978_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6979_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/697_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6980_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6981_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6982_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6983_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6984_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6985_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6986_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6987_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6988_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6989_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/698_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6990_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6991_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6992_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6993_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6994_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6995_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6996_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6997_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6998_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6999_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/699_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/69_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/6_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7000_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7001_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7002_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7003_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7004_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7005_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7006_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7007_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7008_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7009_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/700_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7010_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7011_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7012_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7013_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7014_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7015_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7016_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7017_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7018_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7019_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/701_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7020_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7021_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7022_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7023_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7024_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7025_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7026_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7027_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7028_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7029_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/702_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7030_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7031_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7032_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7033_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7034_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7035_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7036_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7037_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7038_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7039_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/703_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7040_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7041_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7042_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7043_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7044_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7045_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7046_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7047_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7048_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7049_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/704_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7050_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7051_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7052_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7053_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7054_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7055_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7056_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7057_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7058_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7059_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/705_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7060_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7061_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7062_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7063_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7064_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7065_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7066_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7067_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7068_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7069_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/706_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7070_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7071_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7072_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7073_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7074_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7075_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7076_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7077_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7078_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7079_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/707_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7080_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7081_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7082_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7083_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7084_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7085_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7086_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7087_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7088_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7089_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/708_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7090_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7091_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7092_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7093_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7094_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7095_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7096_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7097_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7098_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7099_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/709_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/70_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7100_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7101_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7102_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7103_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7104_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7105_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7106_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7107_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7108_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7109_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/710_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7110_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7111_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7112_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7113_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7114_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7115_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7116_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7117_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7118_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7119_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/711_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7120_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7121_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7122_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7123_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7124_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7125_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7126_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7127_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7128_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7129_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/712_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7130_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7131_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7132_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7133_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7134_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7135_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7136_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7137_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7138_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7139_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/713_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7140_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7141_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7142_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7143_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7144_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7145_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7146_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7147_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7148_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7149_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/714_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7150_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7151_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7152_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7153_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7154_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7155_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7156_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7157_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7158_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7159_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/715_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7160_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7161_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7162_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7163_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7164_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7165_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7166_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7167_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7168_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7169_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/716_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7170_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7171_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7172_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7173_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7174_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7175_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7176_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7177_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7178_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7179_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/717_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7180_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7181_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7182_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7183_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7184_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7185_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7186_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7187_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7188_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7189_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/718_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7190_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7191_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7192_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7193_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7194_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7195_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7196_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7197_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7198_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7199_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/719_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/71_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7200_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7201_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7202_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7203_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7204_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7205_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7206_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7207_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7208_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7209_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/720_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7210_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7211_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7212_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7213_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7214_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7215_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7216_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7217_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7218_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7219_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/721_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7220_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7221_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7222_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7223_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7224_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7225_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7226_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7227_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7228_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7229_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/722_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7230_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7231_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7232_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7233_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7234_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7235_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7236_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7237_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7238_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7239_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/723_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7240_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7241_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7242_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7243_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7244_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7245_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7246_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7247_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7248_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7249_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/724_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7250_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7251_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7252_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7253_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7254_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7255_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7256_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7257_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7258_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7259_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/725_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7260_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7261_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7262_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7263_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7264_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7265_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7266_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7267_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7268_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7269_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/726_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7270_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7271_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7272_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7273_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7274_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7275_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7276_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7277_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7278_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7279_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/727_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7280_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7281_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7282_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7283_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7284_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7285_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7286_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7287_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7288_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7289_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/728_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7290_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7291_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7292_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7293_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7294_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7295_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7296_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7297_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7298_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7299_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/729_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/72_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7300_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7301_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7302_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7303_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7304_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7305_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7306_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7307_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7308_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7309_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/730_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7310_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7311_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7312_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7313_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7314_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7315_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7316_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7317_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7318_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7319_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/731_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7320_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7321_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7322_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7323_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7324_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7325_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7326_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7327_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7328_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7329_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/732_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7330_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7331_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7332_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7333_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7334_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7335_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7336_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7337_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7338_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7339_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/733_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7340_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7341_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7342_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7343_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7344_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7345_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7346_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7347_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7348_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7349_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/734_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7350_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7351_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7352_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7353_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7354_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7355_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7356_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7357_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7358_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7359_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/735_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7360_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7361_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7362_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7363_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7364_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7365_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7366_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7367_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7368_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7369_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/736_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7370_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7371_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7372_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7373_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7374_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7375_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7376_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7377_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7378_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7379_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/737_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7380_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7381_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7382_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7383_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7384_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7385_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7386_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7387_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7388_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7389_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/738_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7390_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7391_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7392_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7393_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7394_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7395_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7396_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7397_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7398_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7399_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/739_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/73_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7400_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7401_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7402_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7403_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7404_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7405_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7406_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7407_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7408_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7409_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/740_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7410_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7411_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7412_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7413_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7414_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7415_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7416_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7417_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7418_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7419_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/741_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7420_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7421_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7422_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7423_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7424_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7425_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7426_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7427_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7428_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7429_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/742_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7430_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7431_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7432_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7433_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7434_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7435_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7436_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7437_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7438_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7439_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/743_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7440_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7441_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7442_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7443_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7444_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7445_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7446_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7447_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7448_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7449_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/744_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7450_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7451_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7452_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7453_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7454_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7455_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7456_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7457_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7458_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7459_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/745_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7460_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7461_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7462_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7463_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7464_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7465_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7466_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7467_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7468_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7469_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/746_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7470_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7471_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7472_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7473_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7474_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7475_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7476_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7477_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7478_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7479_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/747_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7480_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7481_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7482_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7483_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7484_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7485_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7486_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7487_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7488_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7489_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/748_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7490_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7491_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7492_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7493_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7494_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7495_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7496_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7497_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7498_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7499_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/749_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/74_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7500_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7501_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7502_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7503_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7504_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7505_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7506_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7507_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7508_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7509_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/750_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7510_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7511_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7512_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7513_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7514_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7515_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7516_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7517_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7518_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7519_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/751_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7520_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7521_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7522_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7523_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7524_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7525_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7526_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7527_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7528_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7529_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/752_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7530_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7531_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7532_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7533_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7534_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7535_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7536_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7537_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7538_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7539_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/753_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7540_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7541_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7542_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7543_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7544_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7545_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7546_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7547_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7548_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7549_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/754_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7550_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7551_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7552_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7553_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7554_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7555_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7556_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7557_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7558_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7559_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/755_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7560_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7561_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7562_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7563_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7564_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7565_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7566_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7567_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7568_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7569_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/756_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7570_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7571_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7572_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7573_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7574_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7575_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7576_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7577_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7578_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7579_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/757_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7580_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7581_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7582_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7583_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7584_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7585_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7586_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7587_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7588_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7589_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/758_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7590_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7591_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7592_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7593_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7594_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7595_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7596_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7597_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7598_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7599_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/759_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/75_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7600_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7601_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7602_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7603_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7604_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7605_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7606_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7607_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7608_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7609_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/760_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7610_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7611_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7612_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7613_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7614_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7615_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7616_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7617_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7618_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7619_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/761_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7620_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7621_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7622_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7623_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7624_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7625_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7626_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7627_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7628_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7629_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/762_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7630_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7631_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7632_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7633_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7634_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7635_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7636_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7637_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7638_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7639_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/763_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7640_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7641_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7642_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7643_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7644_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7645_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7646_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7647_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7648_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7649_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/764_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7650_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7651_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7652_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7653_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7654_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7655_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7656_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7657_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7658_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7659_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/765_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7660_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7661_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7662_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7663_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7664_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7665_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7666_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7667_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7668_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7669_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/766_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7670_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7671_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7672_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7673_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7674_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7675_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7676_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7677_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7678_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7679_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/767_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7680_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7681_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7682_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7683_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7684_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7685_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7686_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7687_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7688_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7689_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/768_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7690_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7691_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7692_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7693_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7694_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7695_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7696_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7697_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7698_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7699_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/769_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/76_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7700_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7701_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7702_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7703_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7704_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7705_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7706_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7707_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7708_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7709_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/770_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7710_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7711_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7712_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7713_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7714_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7715_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7716_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7717_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7718_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7719_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/771_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7720_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7721_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7722_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7723_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7724_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7725_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7726_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7727_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7728_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7729_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/772_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7730_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7731_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7732_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7733_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7734_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7735_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7736_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7737_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7738_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7739_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/773_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7740_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7741_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7742_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7743_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7744_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7745_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7746_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7747_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7748_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7749_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/774_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7750_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7751_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7752_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7753_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7754_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7755_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7756_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7757_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7758_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7759_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/775_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7760_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7761_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7762_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7763_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7764_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7765_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7766_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7767_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7768_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7769_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/776_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7770_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7771_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7772_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7773_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7774_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7775_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7776_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7777_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7778_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7779_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/777_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7780_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7781_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7782_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7783_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7784_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7785_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7786_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7787_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7788_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7789_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/778_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7790_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7791_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7792_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7793_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7794_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7795_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7796_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7797_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7798_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7799_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/779_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/77_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7800_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7801_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7802_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7803_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7804_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7805_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7806_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7807_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7808_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7809_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/780_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7810_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7811_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7812_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7813_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7814_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7815_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7816_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7817_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7818_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7819_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/781_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7820_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7821_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7822_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7823_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7824_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7825_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7826_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7827_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7828_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7829_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/782_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7830_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7831_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7832_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7833_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7834_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7835_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7836_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7837_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7838_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7839_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/783_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7840_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7841_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7842_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7843_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7844_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7845_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7846_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7847_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7848_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7849_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/784_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7850_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7851_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7852_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7853_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7854_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7855_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7856_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7857_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7858_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7859_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/785_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7860_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7861_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7862_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7863_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7864_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7865_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7866_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7867_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7868_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7869_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/786_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7870_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7871_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7872_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7873_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7874_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7875_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7876_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7877_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7878_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7879_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/787_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7880_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7881_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7882_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7883_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7884_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7885_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7886_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7887_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7888_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7889_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/788_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7890_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7891_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7892_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7893_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7894_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7895_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7896_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7897_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7898_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7899_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/789_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/78_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7900_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7901_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7902_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7903_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7904_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7905_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7906_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7907_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7908_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7909_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/790_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7910_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7911_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7912_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7913_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7914_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7915_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7916_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7917_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7918_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7919_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/791_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7920_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7921_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7922_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7923_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7924_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7925_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7926_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7927_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7928_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7929_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/792_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7930_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7931_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7932_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7933_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7934_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7935_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7936_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7937_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7938_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7939_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/793_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7940_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7941_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7942_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7943_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7944_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7945_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7946_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7947_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7948_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7949_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/794_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7950_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7951_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7952_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7953_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7954_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7955_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7956_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7957_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7958_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7959_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/795_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7960_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7961_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7962_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7963_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7964_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7965_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7966_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7967_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7968_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7969_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/796_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7970_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7971_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7972_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7973_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7974_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7975_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7976_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7977_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7978_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7979_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/797_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7980_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7981_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7982_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7983_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7984_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7985_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7986_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7987_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7988_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7989_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/798_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7990_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7991_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7992_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7993_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7994_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7995_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7996_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7997_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7998_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7999_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/799_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/79_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/7_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8000_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8001_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8002_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8003_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8004_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8005_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8006_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8007_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8008_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8009_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/800_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8010_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8011_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8012_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8013_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8014_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8015_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8016_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8017_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8018_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8019_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/801_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8020_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8021_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8022_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8023_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8024_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8025_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8026_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8027_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8028_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8029_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/802_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8030_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8031_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8032_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8033_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8034_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8035_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8036_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8037_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8038_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8039_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/803_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8040_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8041_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8042_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8043_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8044_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8045_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8046_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8047_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8048_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8049_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/804_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8050_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8051_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8052_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8053_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8054_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8055_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8056_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8057_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8058_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8059_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/805_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8060_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8061_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8062_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8063_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8064_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8065_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8066_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8067_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8068_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8069_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/806_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8070_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8071_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8072_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8073_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8074_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8075_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8076_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8077_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8078_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8079_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/807_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8080_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8081_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8082_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8083_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8084_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8085_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8086_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8087_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8088_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8089_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/808_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8090_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8091_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8092_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8093_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8094_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8095_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8096_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8097_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8098_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8099_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/809_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/80_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8100_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8101_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8102_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8103_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8104_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8105_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8106_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8107_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8108_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8109_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/810_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8110_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8111_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8112_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8113_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8114_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8115_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8116_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8117_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8118_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8119_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/811_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8120_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8121_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8122_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8123_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8124_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8125_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8126_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8127_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8128_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8129_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/812_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8130_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8131_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8132_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8133_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8134_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8135_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8136_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8137_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8138_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8139_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/813_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8140_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8141_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8142_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8143_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8144_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8145_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8146_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8147_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8148_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8149_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/814_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8150_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8151_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8152_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8153_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8154_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8155_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8156_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8157_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8158_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8159_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/815_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8160_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8161_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8162_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8163_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8164_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8165_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8166_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8167_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8168_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8169_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/816_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8170_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8171_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8172_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8173_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8174_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8175_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8176_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8177_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8178_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8179_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/817_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8180_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8181_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8182_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8183_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8184_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8185_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8186_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8187_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8188_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8189_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/818_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8190_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8191_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8192_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8193_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8194_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8195_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8196_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8197_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8198_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8199_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/819_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/81_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8200_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8201_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8202_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8203_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8204_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8205_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8206_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8207_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8208_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8209_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/820_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8210_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8211_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8212_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8213_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8214_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8215_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8216_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8217_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8218_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8219_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/821_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8220_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8221_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8222_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8223_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8224_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8225_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8226_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8227_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8228_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8229_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/822_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8230_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8231_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8232_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8233_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8234_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8235_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8236_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8237_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8238_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8239_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/823_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8240_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8241_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8242_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8243_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8244_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8245_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8246_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8247_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8248_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8249_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/824_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8250_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8251_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8252_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8253_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8254_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8255_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8256_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8257_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8258_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8259_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/825_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8260_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8261_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8262_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8263_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8264_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8265_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8266_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8267_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8268_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8269_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/826_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8270_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8271_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8272_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8273_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8274_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8275_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8276_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8277_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8278_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8279_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/827_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8280_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8281_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8282_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8283_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8284_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8285_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8286_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8287_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8288_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8289_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/828_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8290_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8291_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8292_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8293_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8294_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8295_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8296_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8297_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8298_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8299_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/829_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/82_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8300_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8301_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8302_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8303_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8304_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8305_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8306_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8307_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8308_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8309_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/830_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8310_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8311_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8312_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8313_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8314_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8315_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8316_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8317_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8318_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8319_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/831_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8320_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8321_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8322_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8323_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8324_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8325_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8326_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8327_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8328_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8329_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/832_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8330_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8331_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8332_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8333_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8334_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8335_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8336_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8337_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8338_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8339_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/833_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8340_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8341_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8342_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8343_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8344_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8345_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8346_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8347_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8348_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8349_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/834_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8350_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8351_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8352_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8353_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8354_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8355_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8356_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8357_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8358_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8359_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/835_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8360_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8361_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8362_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8363_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8364_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8365_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8366_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8367_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8368_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8369_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/836_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8370_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8371_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8372_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8373_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8374_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8375_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8376_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8377_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8378_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8379_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/837_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8380_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8381_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8382_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8383_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8384_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8385_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8386_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8387_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8388_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8389_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/838_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8390_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8391_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8392_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8393_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8394_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8395_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8396_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8397_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8398_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8399_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/839_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/83_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8400_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8401_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8402_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8403_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8404_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8405_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8406_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8407_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8408_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8409_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/840_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8410_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8411_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8412_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8413_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8414_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8415_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8416_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8417_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8418_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8419_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/841_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8420_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8421_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8422_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8423_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8424_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8425_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8426_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8427_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8428_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8429_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/842_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8430_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8431_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8432_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8433_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8434_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8435_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8436_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8437_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8438_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8439_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/843_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8440_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8441_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8442_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8443_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8444_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8445_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8446_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8447_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8448_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8449_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/844_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8450_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8451_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8452_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8453_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8454_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8455_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8456_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8457_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8458_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8459_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/845_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8460_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8461_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8462_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8463_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8464_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8465_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8466_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8467_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8468_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8469_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/846_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8470_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8471_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8472_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8473_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8474_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8475_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8476_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8477_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8478_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8479_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/847_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8480_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8481_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8482_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8483_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8484_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8485_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8486_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8487_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8488_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8489_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/848_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8490_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8491_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8492_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8493_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8494_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8495_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8496_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8497_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8498_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8499_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/849_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/84_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8500_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8501_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8502_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8503_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8504_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8505_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8506_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8507_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8508_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8509_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/850_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8510_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8511_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8512_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8513_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8514_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8515_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8516_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8517_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8518_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8519_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/851_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8520_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8521_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8522_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8523_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8524_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8525_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8526_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8527_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8528_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8529_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/852_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8530_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8531_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8532_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8533_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8534_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8535_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8536_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8537_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8538_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8539_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/853_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8540_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8541_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8542_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8543_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8544_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8545_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8546_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8547_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8548_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8549_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/854_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8550_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8551_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8552_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8553_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8554_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8555_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8556_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8557_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8558_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8559_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/855_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8560_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8561_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8562_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8563_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8564_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8565_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8566_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8567_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8568_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8569_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/856_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8570_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8571_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8572_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8573_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8574_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8575_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8576_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8577_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8578_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8579_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/857_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8580_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8581_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8582_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8583_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8584_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8585_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8586_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8587_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8588_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8589_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/858_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8590_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8591_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8592_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8593_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8594_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8595_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8596_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8597_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8598_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8599_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/859_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/85_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8600_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8601_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8602_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8603_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8604_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8605_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8606_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8607_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8608_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8609_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/860_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8610_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8611_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8612_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8613_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8614_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8615_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8616_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8617_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8618_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8619_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/861_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8620_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8621_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8622_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8623_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8624_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8625_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8626_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8627_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8628_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8629_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/862_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8630_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8631_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8632_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8633_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8634_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8635_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8636_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8637_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8638_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8639_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/863_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8640_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8641_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8642_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8643_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8644_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8645_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8646_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8647_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8648_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8649_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/864_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8650_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8651_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8652_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8653_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8654_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8655_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8656_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8657_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8658_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8659_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/865_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8660_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8661_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8662_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8663_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8664_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8665_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8666_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8667_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8668_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8669_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/866_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8670_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8671_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8672_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8673_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8674_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8675_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8676_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8677_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8678_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8679_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/867_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8680_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8681_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8682_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8683_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8684_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8685_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8686_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8687_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8688_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8689_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/868_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8690_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8691_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8692_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8693_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8694_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8695_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8696_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8697_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8698_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8699_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/869_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/86_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8700_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8701_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8702_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8703_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8704_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8705_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8706_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8707_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8708_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8709_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/870_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8710_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8711_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8712_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8713_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8714_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8715_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8716_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8717_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8718_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8719_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/871_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8720_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8721_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8722_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8723_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8724_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8725_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8726_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8727_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8728_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8729_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/872_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8730_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8731_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8732_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8733_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8734_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8735_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8736_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8737_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8738_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8739_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/873_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8740_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8741_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8742_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8743_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8744_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8745_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8746_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8747_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8748_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8749_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/874_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8750_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8751_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8752_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8753_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8754_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8755_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8756_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8757_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8758_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8759_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/875_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8760_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8761_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8762_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8763_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8764_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8765_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8766_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8767_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8768_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8769_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/876_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8770_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8771_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8772_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8773_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8774_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8775_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8776_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8777_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8778_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8779_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/877_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8780_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8781_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8782_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8783_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8784_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8785_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8786_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8787_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8788_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8789_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/878_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8790_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8791_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8792_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8793_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8794_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8795_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8796_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8797_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8798_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8799_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/879_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/87_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8800_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8801_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8802_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8803_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8804_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8805_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8806_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8807_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8808_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8809_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/880_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8810_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8811_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8812_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8813_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8814_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8815_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8816_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8817_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8818_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8819_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/881_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8820_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8821_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8822_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8823_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8824_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8825_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8826_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8827_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8828_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8829_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/882_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8830_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8831_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8832_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8833_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8834_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8835_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8836_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8837_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8838_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8839_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/883_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8840_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8841_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8842_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8843_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8844_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8845_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8846_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8847_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8848_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8849_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/884_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8850_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8851_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8852_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8853_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8854_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8855_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8856_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8857_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8858_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8859_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/885_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8860_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8861_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8862_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8863_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8864_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8865_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8866_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8867_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8868_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8869_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/886_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8870_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8871_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8872_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8873_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8874_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8875_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8876_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8877_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8878_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8879_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/887_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8880_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8881_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8882_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8883_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8884_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8885_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8886_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8887_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8888_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8889_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/888_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8890_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8891_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8892_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8893_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8894_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8895_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8896_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8897_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8898_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8899_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/889_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/88_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8900_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8901_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8902_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8903_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8904_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8905_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8906_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8907_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8908_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8909_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/890_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8910_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8911_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8912_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8913_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8914_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8915_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8916_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8917_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8918_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8919_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/891_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8920_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8921_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8922_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8923_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8924_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8925_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8926_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8927_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8928_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8929_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/892_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8930_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8931_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8932_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8933_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8934_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8935_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8936_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8937_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8938_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8939_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/893_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8940_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8941_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8942_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8943_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8944_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8945_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8946_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8947_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8948_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8949_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/894_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8950_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8951_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8952_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8953_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8954_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8955_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8956_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8957_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8958_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8959_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/895_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8960_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8961_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8962_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8963_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8964_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8965_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8966_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8967_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8968_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8969_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/896_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8970_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8971_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8972_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8973_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8974_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8975_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8976_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8977_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8978_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8979_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/897_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8980_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8981_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8982_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8983_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8984_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8985_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8986_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8987_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8988_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8989_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/898_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8990_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8991_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8992_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8993_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8994_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8995_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8996_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8997_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8998_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8999_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/899_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/89_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/8_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9000_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9001_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9002_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9003_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9004_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9005_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9006_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9007_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9008_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9009_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/900_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9010_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9011_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9012_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9013_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9014_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9015_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9016_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9017_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9018_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9019_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/901_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9020_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9021_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9022_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9023_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9024_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9025_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9026_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9027_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9028_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9029_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/902_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9030_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9031_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9032_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9033_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9034_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9035_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9036_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9037_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9038_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9039_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/903_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9040_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9041_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9042_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9043_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9044_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9045_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9046_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9047_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9048_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9049_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/904_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9050_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9051_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9052_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9053_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9054_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9055_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9056_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9057_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9058_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9059_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/905_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9060_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9061_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9062_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9063_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9064_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9065_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9066_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9067_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9068_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9069_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/906_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9070_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9071_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9072_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9073_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9074_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9075_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9076_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9077_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9078_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9079_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/907_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9080_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9081_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9082_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9083_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9084_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9085_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9086_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9087_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9088_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9089_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/908_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9090_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9091_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9092_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9093_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9094_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9095_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9096_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9097_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9098_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9099_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/909_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/90_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9100_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9101_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9102_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9103_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9104_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9105_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9106_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9107_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9108_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9109_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/910_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9110_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9111_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9112_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9113_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9114_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9115_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9116_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9117_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9118_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9119_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/911_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9120_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9121_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9122_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9123_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9124_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9125_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9126_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9127_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9128_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9129_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/912_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9130_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9131_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9132_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9133_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9134_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9135_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9136_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9137_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9138_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9139_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/913_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9140_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9141_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9142_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9143_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9144_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9145_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9146_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9147_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9148_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9149_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/914_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9150_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9151_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9152_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9153_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9154_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9155_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9156_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9157_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9158_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9159_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/915_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9160_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9161_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9162_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9163_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9164_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9165_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9166_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9167_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9168_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9169_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/916_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9170_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9171_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9172_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9173_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9174_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9175_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9176_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9177_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9178_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9179_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/917_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9180_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9181_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9182_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9183_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9184_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9185_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9186_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9187_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9188_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9189_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/918_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9190_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9191_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9192_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9193_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9194_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9195_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9196_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9197_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9198_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9199_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/919_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/91_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9200_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9201_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9202_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9203_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9204_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9205_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9206_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9207_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9208_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9209_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/920_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9210_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9211_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9212_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9213_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9214_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9215_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9216_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9217_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9218_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9219_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/921_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9220_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9221_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9222_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9223_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9224_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9225_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9226_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9227_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9228_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9229_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/922_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9230_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9231_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9232_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9233_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9234_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9235_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9236_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9237_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9238_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9239_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/923_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9240_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9241_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9242_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9243_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9244_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9245_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9246_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9247_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9248_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9249_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/924_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9250_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9251_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9252_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9253_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9254_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9255_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9256_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9257_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9258_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9259_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/925_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9260_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9261_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9262_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9263_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9264_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9265_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9266_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9267_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9268_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9269_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/926_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9270_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9271_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9272_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9273_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9274_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9275_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9276_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9277_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9278_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9279_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/927_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9280_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9281_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9282_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9283_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9284_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9285_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9286_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9287_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9288_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9289_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/928_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9290_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9291_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9292_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9293_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9294_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9295_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9296_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9297_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9298_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9299_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/929_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/92_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9300_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9301_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9302_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9303_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9304_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9305_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9306_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9307_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9308_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9309_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/930_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9310_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9311_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9312_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9313_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9314_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9315_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9316_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9317_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9318_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9319_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/931_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9320_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9321_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9322_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9323_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9324_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9325_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9326_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9327_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9328_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9329_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/932_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9330_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9331_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9332_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9333_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9334_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9335_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9336_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9337_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9338_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9339_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/933_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9340_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9341_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9342_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9343_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9344_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9345_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9346_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9347_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9348_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9349_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/934_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9350_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9351_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9352_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9353_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9354_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9355_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9356_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9357_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9358_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9359_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/935_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9360_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9361_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9362_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9363_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9364_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9365_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9366_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9367_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9368_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9369_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/936_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9370_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9371_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9372_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9373_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9374_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9375_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9376_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9377_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9378_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9379_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/937_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9380_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9381_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9382_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9383_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9384_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9385_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9386_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9387_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9388_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9389_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/938_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9390_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9391_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9392_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9393_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9394_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9395_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9396_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9397_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9398_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9399_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/939_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/93_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9400_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9401_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9402_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9403_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9404_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9405_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9406_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9407_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9408_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9409_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/940_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9410_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9411_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9412_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9413_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9414_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9415_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9416_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9417_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9418_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9419_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/941_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9420_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9421_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9422_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9423_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9424_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9425_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9426_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9427_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9428_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9429_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/942_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9430_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9431_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9432_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9433_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9434_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9435_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9436_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9437_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9438_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9439_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/943_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9440_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9441_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9442_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9443_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9444_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9445_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9446_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9447_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9448_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9449_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/944_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9450_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9451_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9452_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9453_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9454_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9455_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9456_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9457_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9458_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9459_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/945_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9460_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9461_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9462_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9463_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9464_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9465_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9466_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9467_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9468_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9469_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/946_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9470_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9471_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9472_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9473_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9474_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9475_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9476_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9477_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9478_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9479_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/947_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9480_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9481_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9482_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9483_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9484_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9485_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9486_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9487_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9488_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9489_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/948_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9490_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9491_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9492_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9493_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9494_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9495_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9496_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9497_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9498_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9499_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/949_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/94_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9500_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9501_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9502_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9503_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9504_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9505_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9506_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9507_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9508_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9509_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/950_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9510_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9511_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9512_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9513_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9514_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9515_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9516_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9517_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9518_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9519_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/951_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9520_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9521_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9522_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9523_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9524_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9525_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9526_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9527_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9528_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9529_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/952_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9530_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9531_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9532_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9533_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9534_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9535_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9536_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9537_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9538_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9539_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/953_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9540_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9541_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9542_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9543_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9544_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9545_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9546_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9547_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9548_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9549_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/954_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9550_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9551_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9552_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9553_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9554_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9555_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9556_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9557_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9558_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9559_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/955_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9560_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9561_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9562_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9563_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9564_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9565_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9566_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9567_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9568_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9569_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/956_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9570_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9571_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9572_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9573_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9574_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9575_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9576_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9577_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9578_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9579_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/957_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9580_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9581_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9582_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9583_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9584_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9585_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9586_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9587_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9588_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9589_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/958_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9590_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9591_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9592_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9593_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9594_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9595_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9596_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9597_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9598_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9599_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/959_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/95_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9600_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9601_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9602_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9603_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9604_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9605_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9606_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9607_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9608_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9609_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/960_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9610_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9611_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9612_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9613_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9614_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9615_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9616_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9617_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9618_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9619_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/961_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9620_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9621_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9622_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9623_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9624_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9625_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9626_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9627_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9628_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9629_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/962_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9630_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9631_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9632_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9633_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9634_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9635_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9636_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9637_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9638_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9639_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/963_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9640_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9641_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9642_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9643_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9644_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9645_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9646_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9647_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9648_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9649_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/964_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9650_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9651_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9652_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9653_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9654_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9655_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9656_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9657_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9658_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9659_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/965_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9660_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9661_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9662_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9663_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9664_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9665_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9666_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9667_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9668_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9669_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/966_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9670_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9671_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9672_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9673_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9674_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9675_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9676_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9677_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9678_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9679_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/967_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9680_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9681_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9682_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9683_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9684_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9685_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9686_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9687_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9688_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9689_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/968_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9690_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9691_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9692_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9693_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9694_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9695_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9696_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9697_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9698_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9699_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/969_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/96_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9700_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9701_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9702_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9703_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9704_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9705_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9706_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9707_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9708_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9709_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/970_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9710_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9711_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9712_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9713_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9714_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9715_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9716_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9717_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9718_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9719_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/971_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9720_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9721_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9722_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9723_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9724_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9725_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9726_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9727_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9728_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9729_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/972_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9730_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9731_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9732_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9733_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9734_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9735_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9736_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9737_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9738_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9739_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/973_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9740_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9741_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9742_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9743_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9744_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9745_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9746_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9747_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9748_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9749_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/974_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9750_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9751_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9752_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9753_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9754_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9755_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9756_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9757_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9758_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9759_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/975_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9760_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9761_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9762_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9763_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9764_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9765_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9766_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9767_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9768_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9769_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/976_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9770_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9771_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9772_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9773_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9774_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9775_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9776_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9777_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9778_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9779_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/977_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9780_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9781_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9782_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9783_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9784_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9785_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9786_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9787_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9788_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9789_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/978_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9790_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9791_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9792_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9793_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9794_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9795_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9796_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9797_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9798_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9799_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/979_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/97_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9800_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9801_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9802_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9803_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9804_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9805_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9806_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9807_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9808_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9809_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/980_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9810_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9811_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9812_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9813_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9814_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9815_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9816_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9817_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9818_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9819_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/981_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9820_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9821_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9822_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9823_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9824_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9825_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9826_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9827_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9828_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9829_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/982_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9830_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9831_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9832_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9833_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9834_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9835_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9836_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9837_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9838_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9839_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/983_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9840_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9841_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9842_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9843_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9844_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9845_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9846_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9847_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9848_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9849_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/984_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9850_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9851_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9852_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9853_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9854_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9855_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9856_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9857_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9858_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9859_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/985_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9860_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9861_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9862_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9863_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9864_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9865_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9866_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9867_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9868_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9869_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/986_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9870_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9871_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9872_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9873_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9874_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9875_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9876_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9877_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9878_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9879_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/987_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9880_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9881_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9882_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9883_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9884_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9885_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9886_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9887_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9888_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9889_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/988_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9890_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9891_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9892_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9893_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9894_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9895_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9896_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9897_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9898_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9899_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/989_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/98_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9900_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9901_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9902_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9903_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9904_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9905_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9906_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9907_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9908_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9909_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/990_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9910_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9911_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9912_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9913_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9914_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9915_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9916_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9917_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9918_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9919_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/991_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9920_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9921_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9922_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9923_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9924_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9925_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9926_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9927_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9928_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9929_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/992_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9930_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9931_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9932_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9933_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9934_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9935_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9936_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9937_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9938_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9939_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/993_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9940_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9941_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9942_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9943_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9944_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9945_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9946_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9947_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9948_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9949_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/994_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9950_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9951_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9952_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9953_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9954_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9955_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9956_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9957_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9958_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9959_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/995_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9960_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9961_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9962_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9963_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9964_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9965_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9966_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9967_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9968_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9969_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/996_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9970_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9971_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9972_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9973_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9974_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9975_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9976_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9977_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9978_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9979_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/997_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9980_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9981_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9982_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9983_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9984_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9985_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9986_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9987_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9988_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9989_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/998_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9990_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9991_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9992_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9993_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9994_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9995_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9996_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9997_7.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9998_9.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9999_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/999_10.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/99_8.txt  \n",
            "  inflating: exam1_dataset/TRAINING/positive/9_7.txt  \n",
            "   creating: exam1_dataset/UNLABELED/\n",
            "  inflating: exam1_dataset/UNLABELED/0_0.txt  \n",
            "  inflating: exam1_dataset/UNLABELED/24221_0.txt  \n",
            "  inflating: exam1_dataset/UNLABELED/35968_0.txt  \n",
            "  inflating: exam1_dataset/UNLABELED/35991_0.txt  \n",
            "  inflating: exam1_dataset/UNLABELED/36022_0.txt  \n",
            "  inflating: exam1_dataset/UNLABELED/36149_0.txt  \n",
            "  inflating: exam1_dataset/UNLABELED/36517_0.txt  \n",
            "  inflating: exam1_dataset/UNLABELED/37154_0.txt  \n",
            "  inflating: exam1_dataset/UNLABELED/46278_0.txt  \n",
            "  inflating: exam1_dataset/UNLABELED/46705_0.txt  \n",
            "  inflating: exam1_dataset/UNLABELED/49990_0.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRG02ePffwmB"
      },
      "source": [
        "# training and unlabelled\n",
        "training_path = 'exam1_dataset/TRAINING'\n",
        "unlabeled_path = 'exam1_dataset/UNLABELED'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qjZXx6joGZe"
      },
      "source": [
        "positive_data = [] # list containing positive labeled files \n",
        "for file in os.listdir(os.path.join(training_path,'positive')):\n",
        "  f = open(os.path.join('/content/',training_path,'positive',file), \"r\")\n",
        "  data = f.read()\n",
        "  positive_data.append(data)\n",
        "\n",
        "negative_data = [] # list containing negative labeled files \n",
        "for file in os.listdir(os.path.join(training_path,'negative')):\n",
        "  f = open(os.path.join('/content/',training_path,'negative',file), \"r\")\n",
        "  data = f.read()\n",
        "  negative_data.append(data)\n",
        "\n",
        "unlabeled_data = [] # list containing  unlabeled files \n",
        "for file in os.listdir(unlabeled_path):\n",
        "  f = open(os.path.join('/content/',unlabeled_path,file), \"r\")\n",
        "  data = f.read()\n",
        "  unlabeled_data.append(data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBwzy8m2Eo7Y"
      },
      "source": [
        "list_of_documents = os.listdir(os.path.join(training_path,'positive')) + os.listdir(os.path.join(training_path,'negative'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIxBF9TkyCl7"
      },
      "source": [
        "# creating X and y lists for training\n",
        "X = positive_data + negative_data\n",
        "y = [1]*len(positive_data) + [0]*len(negative_data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoQaK3Nkb4Mx"
      },
      "source": [
        "\n",
        "Question 1)​ ​(20 points)​ Write a​ generic function​ that takes: Classification algorithm name, vectorization method name, training set with labels as parameters (total of 3 parameters should be passed). The function should take the classification algorithm name, the vectorization method’s name, and the training set and train the desired model. Use the default training parameters for the models we have seen in class. This function should return the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y360v2oxv1s"
      },
      "source": [
        "def model_train(algorithm_name, vectorization_method, training_set):\n",
        "  models = [MultinomialNB(),RandomForestClassifier(),SVC()]\n",
        "  vectorization_methods = [CountVectorizer(), TfidfVectorizer()]\n",
        "  model = None\n",
        "  vector_method = None\n",
        "  modelFound = 0\n",
        "  vectorFound = 0\n",
        "\n",
        "  for m in models: \n",
        "    if(m.__class__.__name__ == algorithm_name):\n",
        "      model = m\n",
        "      modelFound = 1\n",
        "      break\n",
        "  \n",
        "  if(not modelFound):\n",
        "    return 'Model not found, please recheck algorithm name to match sklearn class name'\n",
        "  \n",
        "  for v in vectorization_methods: \n",
        "    if(v.__class__.__name__ == vectorization_method):\n",
        "      vector_method = v\n",
        "      vectorFound = 1\n",
        "      break\n",
        "  \n",
        "  if(not vectorFound):\n",
        "    return 'Vectorization method not found, please recheck algorithm name to match sklearn class name'\n",
        "  \n",
        "  model = make_pipeline(vector_method, model)\n",
        "  model.fit(training_set['data'], training_set['labels'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfj8NGo6b8hA"
      },
      "source": [
        "**Question 2)​ ​(30 points)​ Using the function from question 1 to ​build the following models​:**\n",
        "\n",
        "a) Model a: Naive Bayes, Vectorizer: TFIDF and Bag of Words, Training set should be 75%\n",
        "of the provided dataset. Leaving the remaining 25% for testing.\n",
        "b) Model b: RandomForest, Vectorizer: TFIDF and Bag of Words, Training set should be\n",
        "70% of the provided dataset. Leaving the remaining 30% for testing.\n",
        "c) Model c: Support Vector Machines (SVC in sklearn), Vectorizer: TFIDF and Bag of\n",
        "Words, Training set should be 60% of the provided dataset. Leaving the remaining 40% for testing. \n",
        "\n",
        "NOTE: Set the r​ andom seed to: 12345​. This needs to be consistently set to train the model AND split the data in test and train. If this is not done correctly, you will lose points as your answers will not be comparable with the grading key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEHw1leFb_2-"
      },
      "source": [
        "### model a\n",
        "X_train_model_a, X_test_model_a, y_train_model_a, y_test_model_a = train_test_split(X, y, test_size=0.25, \n",
        "                                                                                    random_state=12345)\n",
        "training_set_model_a = {}\n",
        "training_set_model_a['data'] = X_train_model_a\n",
        "training_set_model_a['labels'] = y_train_model_a\n",
        "model_a_CountVectorizer = model_train('MultinomialNB','CountVectorizer',training_set_model_a)\n",
        "model_a_TfidfVectorizer = model_train('MultinomialNB','TfidfVectorizer',training_set_model_a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ETCjRH1EMzI"
      },
      "source": [
        "### model b\n",
        "X_train_model_b, X_test_model_b, y_train_model_b, y_test_model_b = train_test_split(X, y, test_size=0.30, \n",
        "                                                                                    random_state=12345)\n",
        "training_set_model_b = {}\n",
        "training_set_model_b['data'] = X_train_model_b\n",
        "training_set_model_b['labels'] = y_train_model_b\n",
        "\n",
        "model_b_CountVectorizer = model_train('RandomForestClassifier','CountVectorizer',training_set_model_b)\n",
        "model_b_TfidfVectorizer = model_train('RandomForestClassifier','TfidfVectorizer',training_set_model_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWpE-FQ2EMwc"
      },
      "source": [
        "### model c\n",
        "X_train_model_c, X_test_model_c, y_train_model_c, y_test_model_c = train_test_split(X, y, test_size=0.40, \n",
        "                                                                                    random_state=12345)\n",
        "training_set_model_c = {}\n",
        "training_set_model_c['data'] = X_train_model_c\n",
        "training_set_model_c['labels'] = y_train_model_c\n",
        "\n",
        "model_c_CountVectorizer = model_train('SVC','CountVectorizer',training_set_model_c)\n",
        "model_c_TfidfVectorizer = model_train('SVC','TfidfVectorizer',training_set_model_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oncIDdPKcCBN"
      },
      "source": [
        "**Question 3)​ ​(30 points)​ Using the models from Question 2, evaluate each model with its respective training set (for ​model a,​ that set is 25% of the data, for ​model b​, that set is 30% of the data, and for ​model c​ that set is 40% of the data. Be careful to not mix up the evaluation sets. With the predictions on the test set and show the following metrics: Accuracy, Precision, Recall, and Macro F1-score. With this in mind, please write and answer these questions in your notebook:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2GdbK18cEJZ"
      },
      "source": [
        "### model a\n",
        "y_pred_model_a = model_a_CountVectorizer.predict(X_test_model_a)\n",
        "\n",
        "model_a_CountVectorizer_accuracy = sklearn.metrics.accuracy_score(y_pred_model_a,y_test_model_a)\n",
        "model_a_CountVectorizer_recall = sklearn.metrics.recall_score(y_pred_model_a,y_test_model_a)\n",
        "model_a_CountVectorizer_percision =  sklearn.metrics.precision_score(y_pred_model_a,y_test_model_a)\n",
        "model_a_CountVectorizer_f1score =  sklearn.metrics.f1_score(y_pred_model_a,y_test_model_a)\n",
        "\n",
        "y_pred_model_a = model_a_TfidfVectorizer.predict(X_test_model_a)\n",
        "\n",
        "model_a_TfidfVectorizer_accuracy = sklearn.metrics.accuracy_score(y_pred_model_a,y_test_model_a)\n",
        "model_a_TfidfVectorizer_recall = sklearn.metrics.recall_score(y_pred_model_a,y_test_model_a)\n",
        "model_a_TfidfVectorizer_percision = sklearn.metrics.precision_score(y_pred_model_a,y_test_model_a)\n",
        "model_a_TfidfVectorizer_f1score = sklearn.metrics.f1_score(y_pred_model_a,y_test_model_a)\n",
        "\n",
        "### model b\n",
        "y_pred_model_b = model_b_CountVectorizer.predict(X_test_model_b)\n",
        "\n",
        "model_b_CountVectorizer_accuracy = sklearn.metrics.accuracy_score(y_pred_model_b,y_test_model_b)\n",
        "model_b_CountVectorizer_recall = sklearn.metrics.recall_score(y_pred_model_b,y_test_model_b)\n",
        "model_b_CountVectorizer_percision = sklearn.metrics.precision_score(y_pred_model_a,y_test_model_a)\n",
        "model_b_CountVectorizer_f1score = sklearn.metrics.f1_score(y_pred_model_b,y_test_model_b)\n",
        "\n",
        "y_pred_model_b = model_b_TfidfVectorizer.predict(X_test_model_b)\n",
        "\n",
        "model_b_TfidfVectorizer_accuracy = sklearn.metrics.accuracy_score(y_pred_model_b,y_test_model_b)\n",
        "model_b_TfidfVectorizer_recall = sklearn.metrics.recall_score(y_pred_model_b,y_test_model_b)\n",
        "model_b_TfidfVectorizer_percision =  sklearn.metrics.precision_score(y_pred_model_b,y_test_model_b)\n",
        "model_b_TfidfVectorizer_f1score = sklearn.metrics.f1_score(y_pred_model_b,y_test_model_b)\n",
        "\n",
        "### model c\n",
        "y_pred_model_c = model_c_CountVectorizer.predict(X_test_model_c)\n",
        "\n",
        "model_c_CountVectorizer_accuracy = sklearn.metrics.accuracy_score(y_pred_model_c,y_test_model_c)\n",
        "model_c_CountVectorizer_recall = sklearn.metrics.recall_score(y_pred_model_c,y_test_model_c)\n",
        "model_c_CountVectorizer_percision =  sklearn.metrics.precision_score(y_pred_model_c,y_test_model_c)\n",
        "model_c_CountVectorizer_f1score = sklearn.metrics.f1_score(y_pred_model_c,y_test_model_c)\n",
        "\n",
        "y_pred_model_c = model_c_TfidfVectorizer.predict(X_test_model_c)\n",
        "\n",
        "model_c_TfidfVectorizer_accuracy = sklearn.metrics.accuracy_score(y_pred_model_c,y_test_model_c)\n",
        "model_c_TfidfVectorizer_recall = sklearn.metrics.recall_score(y_pred_model_c,y_test_model_c)\n",
        "model_c_TfidfVectorizer_percision = sklearn.metrics.precision_score(y_pred_model_c,y_test_model_c)\n",
        "model_c_TfidfVectorizer_f1score = sklearn.metrics.f1_score(y_pred_model_c,y_test_model_c)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPqcmo97BIx1"
      },
      "source": [
        "**a) What model performs the best and why? (which metrics do you base this on, and why do you think it performs better than others).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rzAGwegO2XF"
      },
      "source": [
        "According to Accuracy, Recall, Percision and F1-Score SVM with TFIDF Vectorization works better than other models. Naive Bayes isn't performing as good as SVM because Naive Bayes algorithm assumes that all the features are independent to each other, which is not true in this case. If you consider a string 'not good' naive bayes cannot model the relation between 'not' and 'good'.\n",
        "\n",
        "Random forest usually trains well if there is less number of data points in train dataset. As the number of rows in training data increases the model gets overfitted and it will not generalize well on testing data.\n",
        "\n",
        "Because of these factors, SVM performed better than Random forest and Naive Bayes for the given dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vud96Y0_BOZO"
      },
      "source": [
        "**b) Why is it important not to mix up the testing sets between different models? Think about this one.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG1A4yhdCM4X"
      },
      "source": [
        "For each model training we are spliting the given data individually. Because of this we can't gaurantee that the training data of model X is different from the testing data of model Y. So, if we use the testing data of model Y and test model X, we are indirectly testing the model using it's training data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P875wMMH-sua"
      },
      "source": [
        "**c) Display in a single sorted dataframe (model name, training %, test %, accuracy, precision, recall, F1-score) all performance metrics, sorted by accuracy in descending manner.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZySOUSX4hTA"
      },
      "source": [
        "metrics = pd.DataFrame(np.array([['Naive Bayes with Bag of Words',75,25,model_a_CountVectorizer_accuracy,model_a_CountVectorizer_recall,\n",
        "                                  model_a_CountVectorizer_percision,model_a_CountVectorizer_f1score],\n",
        "                             ['Naive Bayes with TFIDF',75,25,model_a_TfidfVectorizer_accuracy,model_a_TfidfVectorizer_recall,\n",
        "                              model_a_TfidfVectorizer_percision,model_a_TfidfVectorizer_f1score],\n",
        "                             ['Random Forest with Bag of Words',70,30,model_b_CountVectorizer_accuracy,model_b_CountVectorizer_recall,\n",
        "                              model_b_CountVectorizer_percision,model_b_CountVectorizer_f1score],\n",
        "                             ['Random Forest with TFIDF',70,30,model_b_TfidfVectorizer_accuracy,model_b_TfidfVectorizer_recall,\n",
        "                              model_b_TfidfVectorizer_percision,model_b_TfidfVectorizer_f1score],\n",
        "                             ['Support Vector Machines with Bag of Words',60,40,model_c_CountVectorizer_accuracy,model_c_CountVectorizer_recall,\n",
        "                              model_c_CountVectorizer_percision,model_c_CountVectorizer_f1score],\n",
        "                             ['Support Vector Machines with TFIDF',60,40,model_c_TfidfVectorizer_accuracy,model_c_TfidfVectorizer_recall,\n",
        "                              model_c_TfidfVectorizer_percision,model_c_TfidfVectorizer_f1score]\n",
        "                             ]),columns=['Model Name','Training Percentage','Testing Percentage','Accuracy', 'Recall', 'Precision','F1-Score'])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "yW1SV_r79GKq",
        "outputId": "174b2547-8a83-4b12-cc5d-80bb72269158"
      },
      "source": [
        "metrics.sort_values('Accuracy',ascending=False)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Name</th>\n",
              "      <th>Training Percentage</th>\n",
              "      <th>Testing Percentage</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Support Vector Machines with TFIDF</td>\n",
              "      <td>60</td>\n",
              "      <td>40</td>\n",
              "      <td>0.8916</td>\n",
              "      <td>0.882830626450116</td>\n",
              "      <td>0.9052339413164155</td>\n",
              "      <td>0.8938919342208301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive Bayes with TFIDF</td>\n",
              "      <td>75</td>\n",
              "      <td>25</td>\n",
              "      <td>0.85552</td>\n",
              "      <td>0.8914675767918089</td>\n",
              "      <td>0.8170159524554269</td>\n",
              "      <td>0.852619552799086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Support Vector Machines with Bag of Words</td>\n",
              "      <td>60</td>\n",
              "      <td>40</td>\n",
              "      <td>0.8531</td>\n",
              "      <td>0.8387341292400985</td>\n",
              "      <td>0.8774781919111816</td>\n",
              "      <td>0.8576688305396764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Naive Bayes with Bag of Words</td>\n",
              "      <td>75</td>\n",
              "      <td>25</td>\n",
              "      <td>0.84048</td>\n",
              "      <td>0.8723764387271497</td>\n",
              "      <td>0.8060681889271192</td>\n",
              "      <td>0.837912534547228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest with Bag of Words</td>\n",
              "      <td>70</td>\n",
              "      <td>30</td>\n",
              "      <td>0.8390666666666666</td>\n",
              "      <td>0.8470712960508879</td>\n",
              "      <td>0.8170159524554269</td>\n",
              "      <td>0.8411633109619687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest with TFIDF</td>\n",
              "      <td>70</td>\n",
              "      <td>30</td>\n",
              "      <td>0.8330666666666666</td>\n",
              "      <td>0.8522167487684729</td>\n",
              "      <td>0.8139048614741244</td>\n",
              "      <td>0.832620320855615</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Model Name  ...            F1-Score\n",
              "5         Support Vector Machines with TFIDF  ...  0.8938919342208301\n",
              "1                     Naive Bayes with TFIDF  ...   0.852619552799086\n",
              "4  Support Vector Machines with Bag of Words  ...  0.8576688305396764\n",
              "0              Naive Bayes with Bag of Words  ...   0.837912534547228\n",
              "2            Random Forest with Bag of Words  ...  0.8411633109619687\n",
              "3                   Random Forest with TFIDF  ...   0.832620320855615\n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SgcJu_QcJ1s"
      },
      "source": [
        "**Question 4)​ ​(15 points)​** Using the documents in the folder named UNLABELED, please use your best performing trained model from question 3 to predict their labels. Please do this individually for each document. ​Print to the screen the following items: Document Name, Predicted Label and using a text cell, write your own opinion if the label is correct and why - note you have to read the document to make your own opinion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyrnM_xocKXq"
      },
      "source": [
        "best_performing_model = model_c_TfidfVectorizer # SVM with TfidfVectorizer\n",
        "unlabeled_files_path = os.listdir(unlabeled_path)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MHYJUb9DYvDz",
        "outputId": "80212b3c-2cee-4a85-e3a6-f39099aa1cff"
      },
      "source": [
        "# document 1\n",
        "f = open(os.path.join('/content/',unlabeled_path,unlabeled_files_path[0]), \"r\")\n",
        "data = f.read()\n",
        "pred = best_performing_model.predict([data])[0]\n",
        "\n",
        "print('Best Performing model prediction for ', unlabeled_files_path[0], ' is: ', pred)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Performing model prediction for  0_0.txt  is:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EiGa6RgbTzQ"
      },
      "source": [
        "According to me, the prediction for this document is wrongly predicted as 1. The document consists of negative review, but maybe due to certain keywords such as 'very good', 'like' and 'loved' the model might have given this wrong prediction as False positive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gaWhAcbvaVOv",
        "outputId": "5b5ea3f6-8bc0-49f1-f576-f6cdcc71fbfd"
      },
      "source": [
        "# document 2\n",
        "f = open(os.path.join('/content/',unlabeled_path,unlabeled_files_path[1]), \"r\")\n",
        "data = f.read()\n",
        "pred = best_performing_model.predict([data])[0]\n",
        "\n",
        "print('Best Performing model prediction for ', unlabeled_files_path[1], ' is: ', pred)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Performing model prediction for  36517_0.txt  is:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpiboMyHfMVI"
      },
      "source": [
        "The given document is a negative review and the model has predicted it correctly as negative. The document clearly has negative keywords such as 'worst', 'depressingly', 'poorly', 'bad' which are correctly picked up by the SVM model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "T4Bodk2Dbw27",
        "outputId": "c09fa477-2149-46ee-b466-0b5ba7bfbbf8"
      },
      "source": [
        " # document 3\n",
        "f = open(os.path.join('/content/',unlabeled_path,unlabeled_files_path[2]), \"r\")\n",
        "data = f.read()\n",
        "pred = best_performing_model.predict([data])[0]\n",
        "\n",
        "print('Best Performing model prediction for ', unlabeled_files_path[2], ' is: ', pred)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Performing model prediction for  46705_0.txt  is:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrh9GJ27fM8s"
      },
      "source": [
        "SVM model has predicted the document as a negative review which is true according to my opinion. The review consists of a lot of negative keywords such as 'painful', 'disguisting' etc. and SVM is able to capture the sentiments well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AJ1OONS4bwNu",
        "outputId": "17b5f1d3-af14-4056-f3d7-9e9a50613366"
      },
      "source": [
        "# document 4\n",
        "f = open(os.path.join('/content/',unlabeled_path,unlabeled_files_path[3]), \"r\")\n",
        "data = f.read()\n",
        "pred = best_performing_model.predict([data])[0]\n",
        "\n",
        "print('Best Performing model prediction for ', unlabeled_files_path[3], ' is: ', pred)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Performing model prediction for  36022_0.txt  is:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV2wWBiGfN5f"
      },
      "source": [
        " The given review is a negative review and it is correctly predicted by the model. Even though the length of review is less the model is able to predict the class accurately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6h1b9ZmPbwFO",
        "outputId": "15f41d0b-3677-428b-ef6e-6a5da3d69a20"
      },
      "source": [
        "# document 5\n",
        "f = open(os.path.join('/content/',unlabeled_path,unlabeled_files_path[4]), \"r\")\n",
        "data = f.read()\n",
        "pred = best_performing_model.predict([data])[0]\n",
        "\n",
        "print('Best Performing model prediction for ', unlabeled_files_path[4], ' is: ', pred)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Performing model prediction for  36149_0.txt  is:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNZrgeSGiT2D"
      },
      "source": [
        "The SVM model has correctly classified the review as negative review. The review consists of keywords such as 'bad', 'nauseous' which suggest the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uMtaJ0Afbv0Q",
        "outputId": "e103cfee-2c57-4da0-cc52-6482eeffbee3"
      },
      "source": [
        "# document 6\n",
        "f = open(os.path.join('/content/',unlabeled_path,unlabeled_files_path[5]), \"r\")\n",
        "data = f.read()\n",
        "pred = best_performing_model.predict([data])[0]\n",
        "\n",
        "print('Best Performing model prediction for ', unlabeled_files_path[5], ' is: ', pred)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Performing model prediction for  35968_0.txt  is:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLPCH2vadpQr"
      },
      "source": [
        "This review is wrongly predicted as Postive by the SVM model. This might be because of few keywords such as 'Fine', 'laughs' which are often found in positive feedbacks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NC1C6W2UcnvZ",
        "outputId": "3e75004e-8636-4703-e88d-99b5d9f382b9"
      },
      "source": [
        "# document 7\n",
        "f = open(os.path.join('/content/',unlabeled_path,unlabeled_files_path[6]), \"r\")\n",
        "data = f.read()\n",
        "pred = best_performing_model.predict([data])[0]\n",
        "\n",
        "print('Best Performing model prediction for ', unlabeled_files_path[6], ' is: ', pred)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Performing model prediction for  49990_0.txt  is:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRJxCGbJktEi"
      },
      "source": [
        " The given review is a negative review and the model predicted it correctly. The review consists of keywords such as 'bad', 'destruction' which led to this review.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "F14Ye4MYcnjZ",
        "outputId": "e46cd2d2-b02c-4a13-da85-7494dad39cbc"
      },
      "source": [
        "# document 8\n",
        "f = open(os.path.join('/content/',unlabeled_path,unlabeled_files_path[7]), \"r\")\n",
        "data = f.read()\n",
        "pred = best_performing_model.predict([data])[0]\n",
        "\n",
        "print('Best Performing model prediction for ', unlabeled_files_path[7], ' is: ', pred)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Performing model prediction for  24221_0.txt  is:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l02Y3IiMnT-g"
      },
      "source": [
        "The given review is a negative review and the model predicted it correctly. The review consists of keywords such as 'slow', 'lame', 'boring' which led to this review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "P0yORfDFcnXo",
        "outputId": "d5ab9ca7-f556-404c-b65f-71911510f56b"
      },
      "source": [
        "# document 9\n",
        "f = open(os.path.join('/content/',unlabeled_path,unlabeled_files_path[8]), \"r\")\n",
        "data = f.read()\n",
        "pred = best_performing_model.predict([data])[0]\n",
        "\n",
        "print('Best Performing model prediction for ', unlabeled_files_path[8], ' is: ', pred)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Performing model prediction for  35991_0.txt  is:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_25yOcknrmF"
      },
      "source": [
        "The SVM model has correctly classified the review as negative review. The review consists of keywords such as 'bad', 'disaster' which suggest the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_ln6mZzIczFE",
        "outputId": "74b3c0ed-cb50-4a57-c607-bb4b73cbb411"
      },
      "source": [
        "# document 10\n",
        "f = open(os.path.join('/content/',unlabeled_path,unlabeled_files_path[9]), \"r\")\n",
        "data = f.read()\n",
        "pred = best_performing_model.predict([data])[0]\n",
        "\n",
        "print('Best Performing model prediction for ', unlabeled_files_path[9], ' is: ', pred)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Performing model prediction for  46278_0.txt  is:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xrl28_xdoM2C"
      },
      "source": [
        " The model has predicted the review as negative correctly because of keywords such as 'bad' which are usually found in negative labelled reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pdSruy2hc5AK",
        "outputId": "b4cb4fa3-bc22-4c94-ceef-e9d960b417db"
      },
      "source": [
        "# document 11\n",
        "f = open(os.path.join('/content/',unlabeled_path,unlabeled_files_path[10]), \"r\")\n",
        "data = f.read()\n",
        "pred = best_performing_model.predict([data])[0]\n",
        "\n",
        "print('Best Performing model prediction for ', unlabeled_files_path[10], ' is: ', pred)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Performing model prediction for  37154_0.txt  is:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q8_CMpAo3Ee"
      },
      "source": [
        "This is a negative review and the model has labelled it correctly. This might be due to repetition of words such as 'bad', 'lame' which are frequently found in negative reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJm65R4pcMMn"
      },
      "source": [
        "**Question 5)​ ​(20 points)​** Build a function that takes the set of documents as input and returns a cosine similarity matrix for those documents. Feed all documents in the TRAINING folder to this matrix. Instead of printing the returned cosine similarity matrix, create a heatmap plot from the returned matrix. ​Make sure your plot is nicely scaled, properly labeled, and uses a nice color range to show the similarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ydfhOy6cOb_"
      },
      "source": [
        "def build_cosine(documents):\n",
        "  tfidf = TfidfVectorizer()\n",
        "  matrix = tfidf.fit_transform(documents) \n",
        "  matrix = matrix.astype(np.float32) # converting matrix to float32 to use Google Colab RAM efficiently\n",
        "  return cosine_similarity(matrix,matrix)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7eVy1l0Opqn"
      },
      "source": [
        "cosine_matrix = build_cosine(X)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "qEYcNnOy1HGe",
        "outputId": "cfdbc419-8345-483f-a0fc-1101d45a79db"
      },
      "source": [
        "# Plotting a continuous heatmap\n",
        "plt.imshow(cosine_matrix, cmap='viridis')\n",
        "plt.colorbar()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f4b6dba7c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI32hZ3McPzN"
      },
      "source": [
        "**Question 6)​ ​(15 points)​** Write a function that takes a cosine similarity matrix as input and returns a list with the top n document paris and their similarity. Note that you should only keep the document pairs that are unique and remove the comparisons of the document to itself. Print the top 50 similar document pairs. Compare the assigned class for each document and answer: Do all similar documents belong to the same class? Why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxP87-WycSEU"
      },
      "source": [
        "def top_n(cosine_matrix,n):\n",
        "  # converting all elements in lower triangular matrix to -1, so that same document is not cosidered twice (once in upper and once in lower)\n",
        "  # converting all diagonal elements to -1, so similarity between document and itself is not calculated\n",
        "  for i in range(len(cosine_matrix)):\n",
        "    for j in range(len(cosine_matrix[0])):\n",
        "      if(i>=j):\n",
        "        cosine_matrix[i][j] = -1\n",
        "  \n",
        "  index = cosine_matrix.flatten().argsort()[-(n):] # gives index of top 50 values in 1D array\n",
        "  x_cordinates, y_cordinates = np.unravel_index(index, cosine_matrix.shape) # gives list of x and y coordinates\n",
        "  \n",
        "  top_n_similar = [] # list consists of top 50 similar documents\n",
        "  for x,y in zip(x_cordinates,y_cordinates):\n",
        "    top_n_similar.append((list_of_documents[x],list_of_documents[y],cosine_matrix[x,y]))\n",
        "  \n",
        "  top_n_similar.reverse() # converting the list to descending order\n",
        "  return top_n_similar "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OWehtcnDvYJ"
      },
      "source": [
        "top_50_similar = top_n(cosine_matrix,50)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oE3_PtS6OOC2",
        "outputId": "a52b5e2d-1413-4e7a-dd03-73976f477cbb"
      },
      "source": [
        "top_50_similar"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('10330_1.txt', '279_1.txt', 1.0000004),\n",
              " ('5583_4.txt', '2716_4.txt', 1.0000004),\n",
              " ('4102_4.txt', '985_4.txt', 1.0000002),\n",
              " ('4983_2.txt', '7869_2.txt', 1.0000002),\n",
              " ('5550_4.txt', '5952_4.txt', 1.0000002),\n",
              " ('9319_8.txt', '6069_8.txt', 1.0000002),\n",
              " ('11974_4.txt', '5952_4.txt', 1.0000002),\n",
              " ('9664_10.txt', '3315_10.txt', 1.0000002),\n",
              " ('8278_10.txt', '8273_10.txt', 1.0000002),\n",
              " ('10329_1.txt', '278_1.txt', 1.0000002),\n",
              " ('5550_4.txt', '11974_4.txt', 1.0000002),\n",
              " ('996_9.txt', '995_9.txt', 1.0000002),\n",
              " ('972_9.txt', '973_9.txt', 1.0000002),\n",
              " ('3704_3.txt', '3705_3.txt', 1.0000001),\n",
              " ('5580_2.txt', '2713_2.txt', 1.0000001),\n",
              " ('7871_2.txt', '4985_2.txt', 1.0000001),\n",
              " ('4986_2.txt', '7872_2.txt', 1.0000001),\n",
              " ('8371_10.txt', '8370_10.txt', 1.0000001),\n",
              " ('11469_10.txt', '11470_10.txt', 1.0000001),\n",
              " ('5984_4.txt', '5983_4.txt', 1.0000001),\n",
              " ('6645_1.txt', '5088_1.txt', 1.0000001),\n",
              " ('11922_10.txt', '11923_10.txt', 1.0000001),\n",
              " ('4104_4.txt', '987_4.txt', 1.0000001),\n",
              " ('7729_7.txt', '7728_7.txt', 1.0000001),\n",
              " ('5578_1.txt', '2711_1.txt', 1.0000001),\n",
              " ('744_1.txt', '743_1.txt', 1.0000001),\n",
              " ('6639_1.txt', '5082_1.txt', 1.0000001),\n",
              " ('2156_1.txt', '11575_1.txt', 1.0000001),\n",
              " ('646_9.txt', '644_9.txt', 1.0000001),\n",
              " ('6769_9.txt', '12455_9.txt', 1.0000001),\n",
              " ('10180_1.txt', '10179_1.txt', 1.0),\n",
              " ('9662_10.txt', '3313_10.txt', 1.0),\n",
              " ('6828_2.txt', '7646_2.txt', 1.0),\n",
              " ('3127_9.txt', '3135_9.txt', 1.0),\n",
              " ('552_1.txt', '11934_1.txt', 1.0),\n",
              " ('5552_1.txt', '5954_1.txt', 1.0),\n",
              " ('12393_4.txt', '12394_4.txt', 1.0),\n",
              " ('5954_1.txt', '11976_1.txt', 1.0),\n",
              " ('4901_4.txt', '9423_4.txt', 1.0),\n",
              " ('11975_1.txt', '5953_1.txt', 1.0),\n",
              " ('7286_2.txt', '7287_2.txt', 1.0),\n",
              " ('5551_1.txt', '5953_1.txt', 1.0),\n",
              " ('1327_9.txt', '1330_9.txt', 1.0),\n",
              " ('12395_4.txt', '12394_4.txt', 1.0),\n",
              " ('2155_3.txt', '11574_3.txt', 1.0),\n",
              " ('6642_1.txt', '5085_1.txt', 1.0),\n",
              " ('5733_7.txt', '5737_7.txt', 1.0),\n",
              " ('9318_9.txt', '6068_9.txt', 1.0),\n",
              " ('7870_1.txt', '4984_1.txt', 1.0),\n",
              " ('7875_3.txt', '4989_3.txt', 1.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FaJPMifHk-Y"
      },
      "source": [
        "# calculating if similar documents belog to similar class\n",
        "same_class = 0\n",
        "different_class = 0\n",
        "for pair in top_50_similar:\n",
        "  print(list_of_documents.index(pair[0]),list_of_documents.index(pair[1]))\n",
        "  if((list_of_documents.index(pair[0]) < len(positive_data) and list_of_documents.index(pair[1]) < len(positive_data)) or\n",
        "     (list_of_documents.index(pair[0]) > len(positive_data) and list_of_documents.index(pair[1]) > len(positive_data))):\n",
        "    same_class += 1\n",
        "  else:\n",
        "    different_class += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wggZSaB5OBDy",
        "outputId": "7cda0c9c-2e65-46b1-c5a3-aff6d388602b"
      },
      "source": [
        "print('Number of similar pairs with same class are ',same_class,' and number of similar pairs with different class are ', different_class)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of similar pairs with same class are  50  and number of similar pairs with different class are  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlVBByM_O1R1"
      },
      "source": [
        "The cosine similarity has provided very good results and as expected the similarity score between documents of same class are higher than the similarity scores between documents of different class.\n",
        "\n",
        "According to the above metrics all similiar documents belong to same class. This is because our cosine similarity is able to capture the difference between positive and negative reviews. Since the cosine similarity depends on TFIDF, the model is able to differentiate between keywords present in both the classes. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbMy-tnWdU45"
      },
      "source": [
        "**Question 7)​ ​(20 points)​** Using Spacy’s part of speech tagger, process all sentences (hint: don’t forget to split the reviews) and count how many NOUN and VERB tags are found in all the movies review (TRAINING folder) separating them by label. In other words, how many NOUN and VERB tags are found in positive reviews, and how many NOUN and VERB tags are found in negative reviews. ​Answer the following question: When comparing both, do you see any differences? Why do you think about the differences? Or lack of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84oUhj18dVas"
      },
      "source": [
        "# loading spacy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHWwh049kwwz"
      },
      "source": [
        "noun_count_positive_reviews = 0\n",
        "verb_count_positive_reviews = 0\n",
        "punct_count_positive_reviews = 0\n",
        "\n",
        "noun_count_negative_reviews = 0\n",
        "verb_count_negative_reviews = 0\n",
        "punct_count_negative_reviews = 0\n",
        "\n",
        "punct_dict = {}\n",
        "\n",
        "for review in positive_data:\n",
        "  doc = nlp(review)\n",
        "\n",
        "  for d in doc:\n",
        "    if(d.pos_ == 'NOUN'):\n",
        "      noun_count_positive_reviews += 1\n",
        "    elif(d.pos_ == 'VERB'):\n",
        "      verb_count_positive_reviews += 1\n",
        "    elif(d.pos_ == 'PUNCT'):\n",
        "      if(d.text in punct_dict):\n",
        "        punct_dict[d.text] += 1\n",
        "      else:\n",
        "        punct_dict[d.text] = 1\n",
        "      punct_count_positive_reviews += 1\n",
        "      \n",
        "\n",
        "for review in negative_data:\n",
        "  doc = nlp(review)\n",
        "\n",
        "  for d in doc:\n",
        "    if(d.pos_ == 'NOUN'):\n",
        "      noun_count_negative_reviews += 1\n",
        "    elif(d.pos_ == 'VERB'):\n",
        "      verb_count_negative_reviews += 1\n",
        "    elif(d.pos_ == 'PUNCT'):\n",
        "      if(d.text in punct_dict):\n",
        "        punct_dict[d.text] += 1\n",
        "      else:\n",
        "        punct_dict[d.text] = 1\n",
        "      punct_count_negative_reviews += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tx8ImNKRyabM",
        "outputId": "289dd72d-2dcb-4623-c93c-691b4d020e86"
      },
      "source": [
        "print('Number of Noun tags in Positive reviews are ',noun_count_positive_reviews,' and number of Verb tags in Positive reviews are ',verb_count_positive_reviews)\n",
        "print('Number of Noun tags in Negative reviews are ',noun_count_negative_reviews,' and number of Verb tags in Negative reviews are ',verb_count_negative_reviews)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Noun tags in Positive reviews are  542978  and number of Verb tags in Positive reviews are  342125\n",
            "Number of Noun tags in Negative reviews are  528475  and number of Verb tags in Negative reviews are  355559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQP36Ewq3_E_"
      },
      "source": [
        "The number of words in Negative reviews are more than the number of words in Positive reviews. This shows that reviewers usually use more verbs to express their dissatisfaction when compared to senario where they are satisfied with a product. \n",
        "\n",
        "Similarly, number of nouns used are more in positve reviews when compared to negative ones. \n",
        "\n",
        "On the other hand, we can also see that the number of Nouns are greater than the number of verbs in reviews. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FO8STy62yrky",
        "outputId": "f53ef7cf-0467-42f8-9497-1479ca98b9e0"
      },
      "source": [
        "print(len(punct_dict.keys()))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_brvVN8NdWWN"
      },
      "source": [
        "**Question 8)​ ​(20 points)​** Using the results from the PoS process in question 7, count how many different PUNCT tags are found and their respective counts from the full dataset provided (both negative and positives together). Using regex, write a set of regular expressions that generate the same counts from the dataset without using NLTK or Spacy, just regex. ​Can you get the same counts? If not, why do you think this is?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0I5GT2kzdYmm",
        "outputId": "afd824cf-2563-4181-9984-cd23b6d817fe"
      },
      "source": [
        "print('Using spacy the number of different PUNCT tags found are: ', len(punct_dict.keys()))\n",
        "print('Different PUNCT tags and their respective counts are as follows: ', punct_dict)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using spacy the number of different PUNCT tags found are:  6972\n",
            "Different PUNCT tags and their respective counts are as follows:  {',': 275296, '--': 4046, '.': 236532, '\"': 63328, '!': 21913, '?': 14797, '-': 47563, '(': 33106, ')': 32850, '/>But': 818, ';': 6521, '/><br': 7171, '/>PS': 25, ':': 9396, '/>They': 102, '/>Simply': 13, '/>Oscar': 2, '/>First': 180, '/>Neal': 1, '/>Are': 11, '...': 9726, '/>Both': 39, '/>While': 248, '/>That': 237, '.....': 314, '/>William': 16, '/>The': 6996, '/>Nice': 11, '/>This': 1993, '....': 1148, 'himself.<br': 2, '/>All': 406, '/>After': 185, '/>Watch': 82, '/>A': 279, '/>Ray': 3, '/>If': 918, '/>Allen': 7, '/>Toni': 2, '......': 125, '/>Recommend': 2, 'around.<br': 26, '/>At': 198, '/>Anyway': 161, 'drama.<br': 6, '/>Well': 193, '/>10/10': 32, \"'\": 14119, '/>There': 974, '/>but': 15, '/>xx': 2, 'acted.<br': 5, '/>One': 337, '/>Overall': 313, '/>Did': 25, \"/>I'm\": 244, '/>\"Dangerous': 1, '/>Perhaps': 74, '/>It': 1590, '/>Try': 13, '/>Had': 12, '/>Pretty': 14, '*': 5510, '/>She': 52, '/>Paul': 33, '/>Shara': 1, '\\x96': 1211, '{': 98, '/>To': 251, \"/>'The\": 15, '/>Two': 61, '/>Taking': 14, '/>My': 406, '..': 1619, '/>Ms': 11, '/>Highly': 32, '/>For': 301, '/>I': 1353, ':)': 77, '/>When': 272, '/': 197, '/>note': 1, '/>Alec': 3, '/>He': 117, '/>Other': 60, '/>Come': 8, '/>You': 199, '/>So': 513, '/>Film': 13, '/>Gracia': 1, '/>As': 690, '/>Waissbluth': 1, '/>From': 123, '/>Each': 13, '/>See': 45, '/>Top': 4, '/>Topher': 2, '/>Hyde': 3, '/>Jackie': 7, '/>Last': 20, '/>Coming': 9, '`': 647, ':()': 1, '/>Fonda': 4, '/>By': 117, '/>Club': 1, '/>Spooky': 1, '/>Purple': 1, '...........': 18, ';-)': 14, '/>Even': 195, '/>Some': 184, '/>Besides': 36, 'actors.<br': 6, '/>Obviously': 16, '/>And': 700, '/>Herr': 1, '/>Robert': 22, '/>Aside': 24, '/>Heaven': 1, '/>Heartland': 1, 'funny.<br': 22, 'entertaining.<br': 5, '/>Widmark': 3, '/>Peters': 2, '/>Thelma': 3, '/>Suddenly': 4, '/>Finally': 41, '---': 192, '/>Once': 61, '/>Zabriski': 1, 'feature.<br': 3, '/>No': 130, '/>Enjoy': 11, '/>In': 890, '/>Then': 187, '/>Another': 167, '/>With': 164, 'aftertaste.<br': 1, '/>Whatever': 17, '/>Karl': 2, '/>Rolls': 1, '/>True': 14, '/>Oh': 112, 'SteelEYE': 1, \"'Mac\": 1, '/>Yes': 116, '/>Not': 198, '/>Creative': 1, '/>Christopher': 9, '/>Now': 271, '/>J.T.': 1, '/>7/10': 50, '/>Lee': 11, '/>Stanley': 6, '/>His': 49, '/>Thankfully': 4, 'it.<br': 226, '/>Screenwriters': 2, '/>*MILD': 2, '/>Hence': 2, '/>Fagin': 1, '/>': 29, '/>Good': 55, '/>George': 11, '/>Randolph': 5, '/>Cleveland': 1, '/>Note': 18, '/>Albuquerque': 1, 'to.<br': 6, '/>Still': 83, '/>Whereas': 3, '/>On': 189, '/>Early': 8, '/>Gianfranco': 1, 'overdone.<br': 2, '/>Our': 25, 'goods.<br': 1, '/>Whether': 17, '/>Jon': 6, '/>Val': 2, '/>Bill': 15, 'cinema.<br': 12, '/>Supported': 1, '/>Campy': 1, '/>James': 20, '/>12': 8, '/>9/10': 37, '-the': 9, '/>FYI': 4, '/>What': 520, '/>Paris': 5, '/>Attenborough': 2, '/>Also': 197, 'bad.<br': 39, '/>\"The': 71, '/>8/10': 56, '/>Is': 60, '/>Jamie': 5, '/>Bela': 2, '/>Rating': 41, '/>Directed': 31, 'before(the': 1, '/>Director': 103, '/>Despite': 103, '/>Gundam': 4, '/>Technically': 37, '/>Chandu': 1, '/>Would': 15, '/>Lugosi': 3, 'movie(and': 1, '/>Story': 23, '.......': 66, 'episodes.<br': 8, '/>John': 56, '/>now': 11, '/>Like': 87, '/>Only': 41, '/>anyways': 1, 'experience.<br': 21, '/>Its': 65, '/>Concerned': 1, '/>Prince': 4, '/>Thus': 13, '-a': 8, '/>Elvira': 5, '/>We': 171, '/>Martin': 4, '/>Throughout': 24, '/>Julie': 1, '/>Starring': 15, '/>Unlike': 42, '/>Deana': 1, '/>Meanwhile': 46, 'beauty.<br': 7, '/>Her': 22, '/>Lionel': 2, '/>Ironically': 5, \"/>Don't\": 170, '/>Claire': 9, '/>WHERE': 1, '/>Though': 64, '/>Andrews': 3, ':-)': 37, '/>Diana': 3, '/>Or': 27, '/>Grade': 36, '/>Before': 34, 'cartoon.<br': 7, '/>Should': 5, '/>People': 33, '/>Chamberlain': 1, '/>Brave': 1, '/>Why': 104, 'attractive.<br': 1, '/>Dr': 19, '/>Making': 6, '/>Brutal': 1, '/>Hazel': 3, 'xx': 1, '/>\"Mr': 8, '/>Grant': 3, 'dead.<br': 6, '/>Kudos': 15, 'B+': 3, '/>Just': 98, '/>Apart': 27, '/>1': 125, 'recommended.<br': 2, '........': 40, '/>About': 30, '/>Later': 32, '/>Too': 26, '/>*SOME': 1, 'SPOILERS*<br': 4, 'said.<br': 4, '/>Ling': 4, '/>Tsing': 2, 'reincarnation.<br': 2, '/>Sure': 47, 'it-': 4, '/>Here': 81, 'levels(you': 1, 'title(the': 1, '/>Needless': 12, '/>\"A': 8, '/>An': 67, '/>Back': 18, '/>Along': 21, '/>Otto': 3, '/>Tom': 31, '/>8': 33, 'better.<br': 54, '/>Ritter': 1, '/>Katey': 1, 'is.<br': 31, '/>Amy': 4, '/>David': 41, '--spy': 1, '^_^': 2, '^_~': 2, '/>Apparently': 13, '/>Exciting': 2, '/>Joseph': 7, 'compassion.<br': 1, 'blast.<br': 1, '/>Donna': 2, 'here\"!!!<br': 1, '/>Penny': 1, '/>Sirk': 4, '/>Therefore': 8, '/>Written': 15, '/>Right': 13, '/>Where': 44, 'characters.<br': 45, '/>2': 131, '/>3': 117, '/>4': 97, '/>Please': 66, '/>Thi': 1, '/>Excellent': 16, '/>Paperhouse': 3, '/>Several': 3, 'captivating.<br': 1, 'women.<br': 4, '/>Celie': 1, '/>Speilberg': 1, '/>Sudden': 3, '/>Clint': 5, 'either.<br': 49, '/>Carlos': 3, '/>Theresa': 1, '/>Precode': 1, 'jerk.<br': 1, '/>Jessica': 7, '/>Beautiful': 9, '/>Remember': 11, '\"<br': 93, '/>FYM': 1, '/>Sidney': 12, '₤250,000': 1, 'assassin.<br': 2, '/>Gallindo': 1, '/>Trampa': 1, 'humour.<br': 1, '/>Stallone': 3, '/>Although': 154, 'day.<br': 5, '/>Of': 20, 'revolutionary.<br': 1, '/>\"La': 2, '/>Lukas': 2, '/>Jack': 20, '/>Davis': 3, 'cast.<br': 4, '/>Adding': 7, '/>Coulouris': 1, '/>Lucile': 1, '/>Buttgereit': 1, '/>Episode': 3, '/>if': 15, '/>still': 1, 'escapes.<br': 1, '/>Cut': 8, '/>Judging': 5, 'chance.<br': 16, \"/>'A\": 1, '/>Regardless': 10, 'mania.<br': 1, '/>Diverting': 1, '/>7,5/10': 1, '/>Great': 36, '/>Sixteen': 1, '~2005': 1, '/>(*One': 1, '/>Philip': 5, '/>Ben': 13, '/>Peter': 20, 'cuddle.<br': 1, '/>Again': 24, '/>Dana': 7, \"'<br\": 28, '/>Using': 7, '/>Preminger': 4, '/>Fido': 6, '/>Timmy': 1, '/>Quite': 12, '/>IMDB': 2, '/>How': 78, '/>jf': 1, '/>ENDING': 2, '/>Shock': 2, '/>Robin': 5, '/>Do': 74, '/>Large': 1, '/>thank': 4, '/>Dropping': 1, '/>Enter': 10, '/>Insignificance': 1, '/>Realism': 2, '/>Edie': 4, 'iceberg.<br': 2, '/>Familiar': 1, '/>Comedic': 2, '/>\"Dan': 3, '/>Wonderfully': 1, '--the': 2, 'Beery.<br': 1, '/>Keaton': 8, '/>Uh': 2, '/>Such': 23, '/>Hermione': 1, '/>\"Witches': 1, 'Queenie.<br': 1, '/>Gillian': 3, '/>the': 113, '/>INTERESTED': 1, '/>Much': 45, 'much.<br': 1, '/>Whenever': 5, '/>\"Arms': 1, '/>Bow': 1, '/>Three': 22, 'excellent.<br': 15, '/>Easily': 5, '/>Looking': 16, 'action.<br': 19, '/>Mobile': 2, '/>Sometimes': 17, '/>Walter': 7, '/>Lush': 1, '/>\"Lost': 1, '/>Mel': 1, '/>Sounds': 9, '/>Brosnan': 4, 'ruin.<br': 1, '/>Check': 14, '/>Thomas': 3, '/>Tony': 15, '/>Paulie': 6, 'choice.<br': 7, '/>Sternberg': 1, '/>Margaret': 3, '/>(9/10': 1, '/>Bourne': 3, '/>Luchino': 1, '/>Branagh': 12, 'welcome.<br': 5, '/>\"Anjos': 1, '/>Title': 65, '/>Borzage': 2, '.The': 20, '.<br': 90, '/>Adapted': 2, '/>Matt': 8, 'feeling.<br': 3, '/>Richard': 38, '/>Vic': 1, \"/>I've\": 40, 'tragic.<br': 1, '/>Michael': 30, 'suffering.<br': 1, '/>Rosenstrasse': 1, '/>Standing': 2, '/>Recently': 3, '/>Charlton': 4, '/>Their': 8, '/>\\x84The': 1, '/>Captain': 2, '/>Janeway': 1, '/>Manufactured': 1, '/>7': 42, '/>Love': 8, '/>Many': 61, '/>Evidence': 1, '/>and': 48, '/>taken': 1, '/>to': 5, '/>flaws': 1, '/>Brando': 5, '/>Simmons': 1, '/>Sinatra': 8, \"blood'n'guts\": 1, '/>(No': 1, '/>Gameplay': 2, \"/>You'd\": 7, '/>Playing': 3, '/>Time': 6, '/>Add': 24, '/>Missed': 1, 'setting.<br': 3, '/>Complex': 1, '/>Culp': 1, 'impression.<br': 3, 'murders.<br': 1, '/>Originally': 6, 'unnecessary.<br': 2, '=': 30, '/>Dirty': 2, '/>Artisticly': 1, '/>Performance': 2, '/>Gilliam': 2, '/>Soylent': 1, '/>Timothy': 2, '/>Jane': 6, '/>Anyhow': 6, '[': 87, ']': 87, 'bottle.<br': 1, '/>Old': 11, '/>Recommended': 15, '/>Scott': 9, '/>Rating:9': 1, '/>Sean': 8, \"/>DON'T\": 3, '/>Short': 4, '/>BEFORE': 1, '/>Text': 1, '/>Point': 5, 'again.<br': 53, '/>Rhidian': 1, '/>4.5/5': 2, 'beware.<br': 1, '/>ps': 5, '/>Pacino': 5, 'defensiveness.<br': 1, '/>Eva': 4, '/>Commenters': 1, 'symbolism.<br': 3, '/>Otherwise': 14, '/>Dodgerdude': 1, '}': 93, '\"--Emperor': 1, '/>Teck': 1, '/>Lucille': 1, '/>Part': 16, '/>Hard': 4, '/>Winchester': 3, '/>Very': 61, '/>Stewart': 4, 'further.<br': 1, '/>Hidden': 4, '/>Leopold': 1, '/>Methaphor': 1, '/>Williams': 6, '/>Best': 40, 'everywhere.<br': 2, '~': 66, '/>Trevor': 1, '/>Most': 89, 'score.<br': 3, '\"The': 4, '/>Yet': 49, '/>-': 152, '/>El': 1, 'rhapsody.<br': 1, '/>Fans': 21, '/>Ed': 5, '/>Slick': 1, '/>Warning': 2, 'roofs.<br': 1, '/>\"': 4, '/>Sufice': 1, '/>Seeing': 15, '/>Diane': 7, '/>\"Red': 3, '/>Certainly': 8, '/>CD': 1, 'Rogers.<br': 1, '/>Mood': 1, '/>Plot': 33, '/>Cinema': 3, '/>FX': 1, '/>Acting': 22, '/>Dialogue': 2, 'dialogue.<br': 1, '/>Score': 10, '/>Ending': 1, '/>Total': 3, '/>Particular': 1, '/>Anne': 10, '/>Since': 48, '/>Oshii': 2, '/>Visually': 10, '/>Beware': 2, '/>Tachiguishi': 1, '/>Poor': 21, '/>Bette': 3, '/>Personally': 7, '/>Nonetheless': 14, 'appropriate.<br': 1, '/>Everything': 24, '/>Morgan': 10, '/>Lawyer': 1, 'violence.<br': 3, '/>Cypher': 5, 'beautiful.<br': 9, '/>Movies': 12, '/>Ten': 11, '/>Ethan': 3, '/>Colorful': 1, '/>Rather': 11, '/>Manasota': 1, '/>05': 1, '/>Emma': 5, 'romances.<br': 1, '/>\"Emma': 2, 'wife.<br': 9, '/>after': 5, '/>Iago': 1, '/>i': 67, '/>Kazan': 3, '/>Panic': 2, 'angel.<br': 3, '/>Thematically': 2, '/>Rachel': 6, 'assassination.<br': 1, \"/>You're\": 5, 'kicked.<br': 1, '/>Wu': 1, '/>9': 23, '..........': 15, '/>Set': 19, 'enemies.<br': 2, '/>Through': 15, '/>Burns': 7, 'crap.<br': 10, '/>Black': 6, '/>Anyone': 30, '/>Those': 37, '/>\"Rise': 1, 'combination!.<br': 1, '/>Frida': 1, '/>Regarding': 6, 'viewing.<br': 7, 'standards.<br': 8, '/>Lansbury': 1, '/>Full': 11, '/>lasts': 1, '/>are': 2, '/>short': 1, '/>today': 2, '/>overwhelms': 1, \"/>i've\": 2, '/>rating:9': 2, '/>Stylish': 2, '/>Third': 10, 'SPOILERS**<br': 1, '/>Clark': 6, '«': 4, '»': 9, '/>Polanski': 3, '/>Trelkovsky': 2, '/>Towards': 4, 'in.<br': 3, '/>Amanda': 3, '/>Don': 10, 'behind.<br': 6, '/>OLD': 1, 'involved.<br': 4, '/>Shortly': 4, '/>Maybe': 87, '/>Welles': 11, '/>Structurally': 3, '/>Surely': 6, '/>Martha': 3, 'Baseball.<br': 1, '/>Likewise': 3, '/>Having': 65, '/>Billy': 7, 'friends.<br': 3, '/>Alexandre': 2, '.........': 23, ':))': 2, 'skies(with': 1, '/>Absorbing': 1, '/>A+': 1, '/>*End': 2, 'gore.<br': 6, '/>Whoopie': 1, '/>Steve': 12, 'thee': 1, '/>TRANSFER': 2, '/>EXTRAS': 1, '/>Recovering': 1, '/>***SPOILER': 3, 'work.<br': 6, '/not/': 1, '/>Something': 7, '/>-Zafoid': 1, '/>Comments': 11, '/>Mario': 2, 'intrusive.<br': 1, '/>Brilliantly': 2, '/>Take': 29, '/>Spanky': 2, '/>Minor': 3, '/>Camera': 7, '/>Cast': 7, '/>SPOILER': 15, '/>Blake': 3, '/>Brooks': 1, '/>Absolutely': 8, '/>Enterprise': 3, '/>Eastwood': 2, '/>Sondra': 1, '/>Cry': 3, '/>Trust': 9, '/>\"When': 3, 'break.<br': 4, '/>Often': 11, '/>However': 42, 'queen.<br': 2, '/>Times': 1, '/>Victor': 8, '/>Does': 13, '/>Humour': 3, '/>Give': 20, '“': 26, '”': 27, '/>“B': 1, '’': 11, 'roles.<br': 18, \"/>I'd\": 53, 'clear.<br': 3, '/>Edward': 7, '/>Because': 45, '/>Dominick': 3, '/>Chiba': 1, '/>Let': 78, '/>Nanavati': 1, '/>Parkey': 1, 'AitO': 1, 'released.<br': 2, 'spine.<br': 2, '/>Le': 2, 'comment.<br': 1, '/>TRAVIS': 4, 'awesome.<br': 6, '/>ANNETTE': 4, '/>Told': 3, '/>Shocked': 1, '/>Overnight': 1, '/>Was': 20, '/>Which': 27, '/>Thank': 20, '/>Dan': 9, '/>(7/10': 2, '/>Des': 1, '/>Eddie': 5, '/>GREAT': 2, '/>my': 12, '/>Louise': 2, '/>Shot': 10, '/>Tess': 3, '/>Grey': 1, 'into.<br': 1, '/>According': 16, '/>Never': 11, '/>Kubricks': 1, '/>Shakespeare': 2, '/>-Odin-': 1, 'vampire.<br': 2, \"/>We've\": 5, '/>Instead': 31, '/>OK': 10, '/>Torrent': 1, '/>Mattox': 1, '/>Blasco': 1, 'itself.<br': 5, '/>Social': 1, 'despair.<br': 1, '-and': 17, '-who': 4, '/>Except': 13, '/>ROB': 1, '/>\"Bake': 1, '/>Jim': 16, 'wannabe.<br': 1, '/>Jennifer': 3, '--with': 1, '/>Based': 23, '/>THE': 30, \"/>Isn't\": 4, '/>Really': 17, '--Eric': 1, '/>Sexy': 1, '/>Lots': 18, 'exceptional.<br': 3, '/>Gershwin': 1, '/>Spin': 1, 'team(you': 1, '/>More': 27, '/>Initially': 3, '/>Saving': 4, '/>Earl': 1, '-or': 3, '/>*****SPOILER': 7, '/>Frank': 8, '/>Fire': 2, '/>Unfortunately': 55, '/>so': 14, \"/>You've\": 5, 'situation.<br': 9, '/>Item': 6, 'sex.<br': 2, '/>Parsifal': 1, '/>Wagner': 1, '/>Considering': 11, '/>Syberberg': 1, '/>Armin': 1, '/>Following': 10, '/>Writer': 19, '/>Arlon': 1, '/>Rebar': 1, 'part.<br': 7, '/>Ustinov': 3, '/>Slaughter': 1, '/>JLH': 1, 'reality.<br': 3, 'natural.<br': 2, '/>Ted': 4, '/>Unless': 20, 'about.<br': 7, 'injustice.<br': 3, '/>Karishma': 1, 'imagined.<br': 3, 'down.<br': 3, '/>D.W.': 1, '/>Elizabeth': 4, '/>Alain': 2, '/>Probably': 4, 'presentation.<br': 2, '/>Madhur': 2, '/>Parker': 7, '/>Fay': 3, '/>Hal': 2, '/>Sebastien': 1, 'nearby.<br': 1, '/>Jeremie': 1, 'it?-': 1, '/>Genie': 1, 'yet.<br': 6, '/>Contrary': 7, 'done.<br': 18, '/>Hopefully': 11, '/>Sorry': 29, '/>Joan': 7, '/>Underrated': 2, '/>Cross': 1, '/>Anybody': 4, '/>Powerful': 2, '/>Highjly': 1, '\")': 3, '.Like': 1, '/>Lorne': 1, '/>Kelly': 9, 'candidate.<br': 1, '/>Eventually': 12, 'seven.<br': 13, '/>Without': 12, '/>7.4': 3, '/>Mollà': 1, '/>SEE': 2, '/>Diagnosis': 1, '/>further': 2, '/>people': 3, 'cameos.<br': 1, '/>Gene': 11, '/>Less': 3, '/>Scriptwriter': 1, '/>Lessons': 1, '/>Unknown': 1, '/>Dave': 4, '/>Gulfax': 2, '/>Guy': 4, '/>Berkeley': 1, 'version.i': 1, 'Yourself.)This': 1, '/>Vanilla': 2, 'forever.<br': 10, '/>Sauron': 1, '/>Carla': 5, '/>Devos': 1, '/>Dumbland': 1, 'intruder.<br': 1, '/>BOTTOM': 2, '/>Sandra': 3, '/>PS-': 3, '/>GO': 1, 'ditto.<br': 1, '/>Thats': 4, '/>Opinion': 2, '/>Khouri': 1, '/>Supermen': 1, '/>Seems': 3, '/>Izumo': 3, '/>Keifer': 1, 'budget.<br': 14, 'succeeded.<br': 1, '/>Desmond': 1, '/>Canadian': 2, '/>Eric': 11, '/>Jan': 4, 'Allen.<br': 1, '/>Fun': 7, 'Really!!<br': 1, '/>Gertrude': 1, '/>Charles': 9, '/>Pilger': 1, '/>Shintaro': 3, '/>Actually': 6, '/>Music': 11, '/>Stars': 4, '/>Mother': 3, '/>http://en.wikipedia.org': 1, '/>Colin': 2, '/>FIVE': 1, '/>Frankly': 5, 'role.<br': 3, 'did.<br': 20, '/>Lucy': 5, '/>Jeremy': 6, '/>Disorganized': 2, '.thank': 2, '/>\"Rosenstrasse': 1, '05/31/05': 1, '/>\"Wilder': 1, '/>Wilder': 1, '/>Wallace': 2, '/>Think': 17, '/>Essentially': 8, '/>thanks': 3, '/>Lois': 2, \"that'a\": 1, 'mentioned.in': 1, '8/10,which': 1, '/>These': 29, '/>Yoshiyuki': 1, 'clone.<br': 1, '/>Memo': 1, '/>Esther': 2, '/>Ralph': 4, 'enough.<br': 33, '/>Wilona': 1, '/>Hey': 13, '/>Definitely': 18, '/>Oddly': 10, '/>Clocking': 3, '/>Keeping': 3, '/>Made': 8, '/>Flynn': 4, '/>Kubrick': 6, 'intended.<br': 2, '/>(1)Do': 1, 'versatile.<br': 1, '/>while': 4, '/>unique': 1, \"''\": 9, '/>aka': 1, '/>Mixing': 1, '/>Far': 7, '/>Cheadles': 1, '/>Jerry': 4, '/>Teen': 1, '/>DeNiro': 2, '/>(spoilers': 7, 'underrated.<br': 1, '/>Almost': 8, '/>Zelah': 4, '/>Tagge': 1, '/>Mickey': 2, '/>Conspiracy': 2, '/>Redford': 2, '/>Delightful': 2, 'enjoyable.<br': 4, '/>Pure': 6, '/>Soon': 11, 'celebrations.<br': 1, '.or': 1, 'considered.<br': 1, '/>Seachd': 2, '/>Hollywood': 12, \"/>can't\": 1, '/>Bottom': 49, '/>Kids': 9, '/>Similar': 4, '/>Rest': 4, '/>Sara': 2, 'rare.<br': 1, '/>Mr': 22, 'thick.<br': 1, '/>Guiness': 1, '/>Smith': 2, 'suck\\'s!\"': 1, \"/>I'll\": 5, '/>p.s': 5, '/>Meena': 2, '/>Pakeezah': 2, '/>Naushads': 1, '/>Bouzaglo': 2, 'conflict.<br': 2, '-but': 5, '-no': 4, 'watch.<br': 2, '/>\"Descent': 1, '/>love': 1, 'alive.<br': 10, '/>Vance': 1, 'upon.<br': 1, '/>Typically': 2, 'good.<br': 34, '/>Harlow': 2, '/>Gable': 3, '/>Whilst': 12, '/>Zero': 3, 'daft(which': 1, 'priceless.<br': 2, 'ending.<br': 40, 'band.<br': 5, '/>Somewhat': 2, '/>Leslie': 4, 'perfectly.<br': 4, '/>Rick': 3, '/>Charlie': 11, 'afterall.<br': 1, '/>Took': 1, '/>Hanging': 1, 'not.<br': 1, '/>\"Deliverance': 3, '/>Every': 15, '/>Lastly': 12, 'darkness.<br': 1, '/>Othello': 3, '/>Woohoo': 2, 'expect.<br': 1, '/>Opening': 3, '/>Tigerland': 1, '/>Tremayne': 1, '/>Lindy': 2, '/>Fred': 3, '/>Schepisi': 2, '/>Saturday': 2, '/>Amid': 1, '/>Meryl': 5, '/>Editing': 1, '/>Sunday': 3, '/>MILD': 2, 'other.<br': 5, 'apartheid.<br': 1, '/>Denzel': 6, '/>\"Cry': 1, '/>Wing': 1, '/>Deathscythe': 1, '/>Trowa': 1, '/>Quatre': 1, '/>Relena': 1, '/>Zechs': 1, '/>MY': 4, '----': 4, '/>Liked': 1, '/>Pleases': 1, '/>Hitchcockian': 1, '/>Truly': 11, \"-Manson's-\": 1, 'hunter.<br': 1, '/>W.': 2, '/>None': 30, '/>Lovely': 1, 'moments.<br': 17, \"BETAAB','HERO\": 1, '/>SmithaPatel': 1, '/>Can': 16, '/>Casting': 2, '/>\"Sudden': 2, '.44': 1, '/>FIDO': 3, '/>---where': 1, '/>Four': 10, '/>NOTE': 12, '/>Claustrophobic': 1, 'tear)<br': 1, '/>Clearly': 11, '/>THIS': 7, '/>Donald': 6, '/>Boyer': 1, 'general.<br': 11, 'power.<br': 1, '/>Emily': 6, '/>Victoria': 1, '/>Miranda': 1, '/>Upon': 8, 'subtitles.<br': 1, '/>WHAT': 7, '/>Key': 1, '/>OVERALL': 5, '/>/Medusa': 1, '/>Certain': 7, '/>Corny': 1, '/>Mantegna': 2, '/>Favorite': 8, '/>(It': 4, '/>~Virginia': 1, '/>Antwone': 5, '/>Fisher': 1, 'brutality.<br': 1, '/>Films': 4, 'great.<br': 11, 'reveres.<br': 1, '/>Bridget': 4, '/>Gosh': 2, '/>Older': 1, '/>Sydney': 1, '/>Okay': 37, '~DANIELLE~': 1, '/>Tallinn': 1, '/>(OK': 2, '/>Musically': 2, '/>\"Never': 1, '/>Viva': 1, '/>Olivia': 1, '/>Alas': 10, '/>Consider': 7, '/>Rate': 2, 'film(the': 1, '/>SPOILERS': 13, '/>Elkaim': 1, 'live.<br': 1, '/>\"Bait': 2, '/>for': 7, '/>Ty.<br': 1, '/>Granted': 14, '/>(music': 1, '/>\"Hollow': 1, '/>**1/2': 1, '/>Standout': 3, '/>Occasionally': 3, 'experiment.<br': 5, '/>Examples': 5, '/>\"I': 12, '/>Jacob': 1, 'acting.<br': 4, '/>Equally': 8, '/>Polly': 3, '/>#1-Rush': 1, ':(': 18, '/>Special': 7, '/>Maury': 1, '/or': 1, 'opera!!!If': 1, 'amusing.<br': 6, '/>Karloff': 4, ').It': 1, '/>holy': 1, '/>Ratings': 5, '/>70s': 1, 'show.<br': 8, 'scene.<br': 14, '/>Juliet': 1, '/>Be': 7, 'mad?<br': 1, 'affair.<br': 7, 'odds.<br': 4, '/>Skeet': 1, '/>Put': 8, '/>\"Things': 3, '/>Nina': 3, '/>Way': 6, '/>Angels': 1, 'situations.<br': 6, 'beneath.<br': 1, '/>Young': 12, '/>Seeking': 2, 'compare.<br': 1, '/>Freddy': 10, '/>Who': 35, 'movie(Before': 1, 'started)': 1, '/>DO': 11, '/>\"Scoop': 5, '/>Years': 3, '/>Congratulations': 4, '/>BUT': 11, 'September.<br': 1, '/>Watching': 28, '/>Corbin': 3, '/>Foree': 1, 'spotted.<br': 1, '/>Country': 2, '/>Movie': 16, '/>Mary': 13, '/>Red': 8, ':D': 19, '/>\"Så': 1, 'correctly.<br': 2, '/>Deserving': 1, '/>Louis': 5, '/>DEATHTRAP': 3, 'along.<br': 19, '/>Gary': 11, '/>well': 7, '/>Any': 18, '/>plot': 3, '/>Kane': 2, '/>WWE': 2, '/>United': 1, '/>Santa': 3, '/>Batista': 2, '/>Being': 25, '/>Am': 8, '/>Done': 6, '/>Make': 9, '/>Out': 5, '/>Silberling': 3, \"/>'Scoop\": 2, 'room}is': 1, 'engrossing.<br': 1, '-box': 1, '/>Bad': 22, 'shooter(not': 1, 'individual.<br': 4, '/>at': 1, '/>Holmes': 1, '/>Father': 1, '/>Beatty': 1, '/>\"Dick': 2, '/>Tracy': 3, '/>Next': 37, '/>Shawn': 1, '/>Irwin': 1, '/>Andy': 12, 'worse.<br': 3, '/>Coupled': 1, '-I': 2, '/>Mala': 1, '/>Waking': 1, '/>Could': 5, '/>Scalise': 1, '/>Ana': 1, '/>Featuring': 3, 'viewers.<br': 5, '/>Brilliant': 5, '/>Will': 14, '/>Accompanied': 2, '/>Nasty': 2, '/>Tarzan': 3, 'fine.<br': 2, '/>Cahill': 1, '/>he': 6, '/>Jonah': 1, '/>Goudry': 1, 'prevalent.<br': 1, '/>Anchors': 1, '/>\"Return': 1, '/>Choosing': 1, 'needlessly.<br': 1, '/>Stephen': 10, 'goes.<br': 2, '/>Farnsworth': 2, '/>Stretch': 1, '/>P.S.': 9, '/>Spiers': 1, '/>Marvin': 1, '/>Guinea': 2, '/>Glenn': 5, '/>Ioan': 1, 'surprised.<br': 2, '/>Gerard': 5, '/>Tim': 8, '/>Oscars': 1, '/>Animation': 8, '/>Errol': 5, 'serious.<br': 3, '/>\"THE': 1, '/>Indians': 1, '/>Twists': 1, '/>Disney': 10, '/>Together': 5, 'progressing.<br': 1, 'moving.<br': 2, '/>5': 47, '/>Wow': 13, '\"Suffer!\"<br': 1, '/>Ironies': 1, '/>Idrissa': 1, '/>Fighting': 2, 'public.<br': 1, '/>CITIZEN': 1, '/>Universal': 3, '/>\"Grey': 1, '/>Thanks': 15, 'Illinois.<br': 1, '/>actors': 1, '/>Salaryman': 1, '/>who': 5, '/>into': 1, '/>Veteran': 5, 'heart.<br': 9, '/>Magnifique': 1, 'instead.<br': 7, '/>Crew': 1, 'free.<br': 1, 'fantastic.<br': 4, 'dying.<br': 2, '/>ThatWasJunk': 1, '/>Brashear': 1, '/>Men': 1, '/>\"Written': 2, '/>Ann': 5, '/>\"Where': 4, '/>\"Hoods': 1, '/>Near': 4, '/>(One': 1, '/>Long': 11, '/>Bouncing': 1, '/>Daniel': 11, 'ease.<br': 1, '/>Shivam': 1, '/>Larissa': 1, '/>Toby': 4, '.But': 4, '/>Turn': 7, '/>society': 2, '/>Forget': 17, '/>Wendigo': 4, '/>\"Foxes': 1, '/>Blanks': 1, '/>Carmen': 1, '/>Brenda': 3, '/>MIDNIGHT': 1, '/>Basically': 26, '/>Antionioni': 2, '/>Indeed': 12, 'goal.<br': 3, '/>Search': 1, '/>Seen': 6, 'Numspa.<br': 1, '/>Cashing': 1, '/>Cheers': 6, '/>Notice': 3, 'empty.<br': 2, '/>Dick': 9, '/>Perry': 2, '/>Nancy': 6, '/>\"There': 7, '/>Fascinating': 2, '/>Kung': 1, '/>Find': 4, '/>Until': 4, '/>Noble': 1, '/>Stay': 7, 'arrived.<br': 2, '/>Atlantis': 1, '/>Spirit': 4, '/>Therein': 1, '/>Actors': 9, 'movie\",it': 1, '/>Benjamin': 3, '/>Matthau': 5, '/>Trentin': 1, '-And': 3, '/>-Oh': 1, '/>Fuller': 3, 'A+': 9, '/>Soap': 1, '/>Gandhi': 5, '/>\"Garrison': 1, 'could.<br': 2, 'exciting.<br': 1, '/>Things': 27, '/>Ostensibly': 2, '/>Go': 6, '/>Have': 9, 'today.<br': 1, '/>Get': 12, '..............': 7, '/>Got': 5, 'claptrap.<br': 2, '/>Tara': 4, '·': 14, '/>Sargent': 1, '/>Dud': 1, '/>Dedee': 2, '/>Seventeen': 1, '/>Nothing': 29, '/>Gentleman': 1, '/>\"Ossessione': 3, '/>Rob': 11, '/>Further': 9, 'guessing.<br': 1, 'do.<br': 4, '---is': 1, 'disease.<br': 2, '/>Olivier': 2, 'anymore.<br': 12, '/>Lena': 1, 'reason.<br': 31, '/>Suffice': 5, '/>Lest': 5, 'men?<br': 1, '/>Me': 1, 'described.<br': 1, 'reservations.<br': 1, 'shot.<br': 8, '/>Cindy': 1, 'bathroom.<br': 3, '/>Sophie': 2, 'Infamous.<br': 1, 'good!<br': 1, '/>actually': 1, '/>\"and': 1, '/>peace': 3, '/>-a': 1, '/>-well': 1, '/>-lots': 1, '/>-old': 1, '/>Checking': 1, '/>(Beware': 1, '/>Carface': 3, '/>Terry': 3, '/>Strangler': 1, 'spoilers)<br': 3, '/>Loved': 8, '/>Quality': 4, '/>Entertainment': 2, '/>Replayable': 2, '/>Alfred': 3, '/>Western': 2, '/>Technology': 1, '/>Dramatic': 1, '/>Downside:<br': 1, '/>Forces': 1, '/>Contains': 1, '/>Broken': 1, '/>Fortunately': 9, '/>Audio': 1, 'default.<br': 1, '/>Extras': 2, '/>Spoiler': 10, '/>Complicating': 2, '/>Carpenter': 2, '/>Going': 2, 'intentions.<br': 3, '/>-------------------------------------------------------------<br': 1, '/>Zane': 1, '/>Scarlett': 1, '/>Drew': 5, '/>Fallon': 3, '/>Yesterday': 3, '/>Digging': 1, 'ensemble.<br': 1, '/>\"Forgotten': 1, '/>Jackson': 2, '/>--PolarisDiB': 10, '/>Bernard': 2, '/>HIGHLY': 1, 'anime.<br': 1, 'refrain.<br': 1, 'stones.<br': 1, 'gone!\"?).<br': 1, '/>Doc': 2, '/>\"Dressed': 1, 'heightens.<br': 1, 'desired.<br': 4, '/>Emotions': 2, '/>Jean': 13, '/>Filmed': 10, '/>Act': 4, '/>Streisand': 3, '/>Joe': 8, '/>Dolman': 1, 'dilemmas.<br': 1, '/>Feroz': 2, 'cinema\\x97a': 1, '/>Knowing': 6, '/>Shall': 2, 'character`s': 1, '/>Bond2a': 1, '/>Jordi': 1, '/>Matador': 1, 'deformed.<br': 1, 'performances(the': 1, 'deserves!<br': 1, 'Shakespeare.<br': 4, '/>Chabat': 1, '/>too': 1, 'movement\"of': 1, '/>was': 6, '/>NC-17': 1, '/>in': 11, '/>parody': 1, '/>scenes': 1, '/>cunnilingus': 1, '/>interview': 1, '/>excerpts': 1, '/>by': 4, '/>pivotal': 1, '/>see': 5, '/>Cary': 5, '/>Def': 1, '/>Given': 30, '/>Kalifornia': 2, '/>Fate': 1, '/>Slavoj': 2, 'request.<br': 2, 'catalyst.<br': 1, 'shines.<br': 3, '/>Christina': 2, '/>Lili': 1, '/>Evil': 2, '/>NB': 3, 'committed.<br': 1, '/>Ok': 2, '/>Luckily': 5, 'elements.<br': 4, '/>S~': 1, '/>Become': 1, '/>Craven': 1, '/>DreamWorks': 1, '--and': 3, '/>Santamarina': 1, '/>Ariel': 2, 'him.<br': 1, '/>\"Esperando': 1, '/>Dudley': 4, '/>Caution': 1, '/>Angel': 1, '/>15/10': 1, '/>Alan': 7, \"/>We're\": 11, '/>Harry': 7, '/>Edison': 3, '/>Particularly': 3, '/>Rex': 1, '/>THREE': 2, 'book)<br': 1, 'angst.<br': 3, '/>Toward': 2, '/>you': 11, '/>Adapting': 1, 'o': 1, 'apologies.<br': 1, \"/>'Xizhao\": 1, '/>Woody': 5, '/>\"Ladies': 1, '/>SOME': 3, '/>\"Thank': 2, '/>\"But': 3, '/>\"For': 1, '/>\"It': 9, '/>Alexandra': 5, '/>Nikolaj': 1, '/>Monty': 1, '/>Notable': 6, '/>Shahid': 2, '/>Amazing!!I': 1, '/>Thirdly': 3, '/>\"Breathtaking': 1, '/>Henry': 7, 'magestic*cough': 1, '/>Stir': 1, '/>Vanessa': 4, '/>Natasha': 2, '/>Mamie': 1, '/>Chick': 1, '/>-Surprise': 1, '-Duh': 1, '/>European': 3, '/>Van': 3, '/>Presenting': 2, 'finale.<br': 15, '/>Marking': 1, '/>HK': 1, '/>Clothes': 1, '/>Jodie': 3, '/>Utlimately': 1, '/>when': 6, '/>Reign': 4, 'claim.<br': 2, '/>Revolving': 1, '/>Robyn': 1, '/>Eight': 2, '/>greets': 1, '/>\"Sniper': 1, '/>\"Fearful': 1, 'counts.<br': 1, '/>\"If': 4, 'circle.<br': 1, '/>Screw': 2, 'inspirational.<br': 1, '/>Liza': 1, \"/>Your're\": 1, '/>THEN': 2, '/>Anthony': 7, '/>Randall': 1, '/>Mike': 5, '/>Solo': 1, '/>Powell': 4, '/>Busby': 2, '/>Benny': 2, '/>Impressive': 2, '/>Susannah': 1, '/>Super': 2, 'latest(and': 1, 'dull(since': 1, 'fans(like': 2, 'Colbert.<br': 1, 'ASAP.Thank': 1, '^^': 2, '/>Maeder': 1, '/>Buds': 1, '/>\"You': 7, '/>Sissy': 3, 'impossible.<br': 2, '/>Q': 1, '/>-Lyndsay': 1, '/>Buster': 3, \"/>Haven't\": 1, '/>Rivers': 1, '/>Barbara': 6, ':P': 3, '/>Ronald': 2, '/>Busy': 3, '/>Spoilers': 8, '/>End': 5, '/>Al': 13, '2k': 1, '/>Nowadays': 2, '/>Fear': 2, '/>Always': 6, '/>Contrasting': 2, '/>Anyways': 14, '/>Funny': 2, '/>Alicia': 3, '/>\"True': 2, '/>Stack': 1, '/>Dorothy': 3, '/>Lubitsch': 1, '/>Georges': 1, '/>Montand': 2, '/>Gojoe': 1, '/>Sad': 8, '/>Derek': 2, '/>Today': 10, '/>Death': 1, '/>Borowczyk': 1, '/>Derived': 1, '/>Aardman': 2, '/>Produced': 5, '/>Alive': 1, '/>Rent': 12, 'bull*beep': 1, \"/>Can't\": 7, 'Jeremy!<br': 1, \"/>'Aimee\": 1, '/>Jiri': 1, '/>Ivan': 2, 'boredom.<br': 1, '/>Nathan': 1, '/>Anime': 1, 'replicate.<br': 1, '.He': 1, '/>Graphics': 3, 'actions.<br': 5, '/>Keanu': 1, '/>BOGUS': 1, '/>5/5': 1, '/>Literacy': 1, '/>Nevertheless': 7, '/>Decent': 2, '/>Yeti': 2, '/>\"Yeti': 2, '/>Pasqual': 1, '/>Among': 9, '/>Stein': 1, '/>Jenny': 1, '/>Wladyslaw': 1, '/>Dialogues': 3, 'blame.<br': 2, '-Stewart-': 1, '/>\"Shop': 1, '/>Chavez': 1, '/>\"Before': 2, '/>Id': 1, '/>\"Your': 2, '/>San': 4, '/>Hancock': 2, '/>some': 1, '/>overall': 9, '/>Shallow': 1, '/>Zizek': 7, '/>Rohmer': 3, 'now.<br': 4, '/>(Note': 4, '/>DVD': 19, '/>Eye': 32, '/>Characters': 10, 'wave.<br': 1, '@': 2, '/>Altho': 1, 'remarry.<br': 1, '/>Timone': 1, '/>Taylor': 3, '/>Strangely': 9, '/>Malone': 2, '/>\"We': 2, 'Life\").<br': 1, '/>Look': 25, 'it?<br': 2, '/>\"Dominick': 1, 'ignored.<br': 2, 'happens.<br': 1, '/>Dark': 4, '/>Final': 10, '/>Says': 1, '/>Mirage': 1, '/>Camp': 1, '/>Holes': 3, '/>Suffering': 2, '/>Kim': 6, 'we`ve': 1, 'jarring.<br': 1, 'followers.<br': 2, '/>Susan': 6, 'interpretations.<br': 1, 'hearts.<br': 1, '/>Amitabh': 13, '/>Govinda': 3, '/>Viju': 1, '/>Election': 2, 'flicks.<br': 1, '/>RATING': 7, '/>Work': 1, '/>\"Read': 1, '/>Nobody': 9, '/>Shemp': 1, '/>Nikko': 1, '/>Plenty': 2, 'laughter.<br': 1, '/>\"Method': 3, '/>\"Waxworks': 2, '/>\"Sweets': 2, '/>Video': 2, '/>Detective': 5, '/>\"Winchester': 2, '/>Photographed': 1, '/>FOOTNOTE': 1, 'ratings.<br': 2, '/>Everyone': 21, '/>Stacy': 1, '/>[Possible': 1, '/>[/Spoilers]<br': 1, 'brilliant.<br': 11, 'expecting.<br': 3, 'anything.<br': 7, '/>Surprising': 1, '/>Footlight': 2, '/>Bon': 2, '/>Laurent': 1, '/>Hitchcock': 1, '/>Greatness': 1, 'following.<br': 3, '/>Descent': 2, '/>Pitching': 1, '/>Garde': 1, '/>Keep': 7, '/>Jeff': 8, '8.5/10': 1, '/>Hitokiri': 1, '/>\"Creep': 1, '/>Power': 2, '/>Features-': 1, '/>Sound-': 1, '/>Pollution': 1, '/>Scenes': 2, '/>Priceless': 1, '/>\"Castle': 2, '/>Traveling': 1, '/>Rated': 10, 'killer.<br': 1, 'F#ck': 1, 'experts.<br': 1, 'best.<br': 1, '/>Jannings': 1, '/>Murphy': 2, '/>Tommy': 1, '/>Kazihiro': 1, '/>Tell': 4, 'certain.<br': 1, '/>Nic': 3, '/>RRW': 1, '/>Alvin': 3, 'G\"-rated': 1, '/>Novak': 2, '/>with': 6, '/>looks': 1, '/>do': 4, '/>likable': 1, '/>like': 4, '/>rate': 1, '/>makes': 2, '/>very': 3, '/>Celebrities': 1, '/>Relax': 2, '/>\"My': 7, '/>Life': 8, '/>20': 4, 'Webster(Riccardo': 1, '/>Fox': 1, '/>Superbly': 2, '/>Monica': 1, '/>Ps': 2, '/>Madhvi': 1, '/>Konkona': 2, 'genius.<br': 7, '/>Grand': 2, '/>movies': 1, '/>Carrey': 2, 'revealed.<br': 2, '/>\"Show': 2, '/>lineage-': 1, '/>surprises': 1, 'scene)<br': 1, '/>movement': 1, '/>unsentimental': 1, 'illusions.<br': 2, '/>Art': 3, '/>Voight': 1, '/>Midnight': 2, '/>performance': 2, '/>Underneath': 2, '/>Casper': 2, '/>Danes': 1, '/>Leonardo': 2, '/>Kate': 5, '/>Kathy': 1, '/>Frances': 1, '/>Jonathan': 3, '/>Gloria': 2, '/>Chilling': 1, '/>Winner': 1, '/>Caroline': 1, '/*****<br': 1, '/>OB101': 1, '/>Colonel': 2, '/>Altman': 1, '/>Telling': 3, '/>Filled': 1, '/>Arriving': 1, '/>Ever': 1, '/>Dickens': 3, '/>Oliver': 2, 'what!\"she': 1, '/>Neither': 6, '/>Freeman': 2, '/>Scarlet': 1, '/>Mark': 6, '/>\"Put': 1, '----------------------------------------<br': 1, '/>Say': 4, '/>Koichi': 1, '/>Thrown': 1, '/>Has': 6, 'intelligence.<br': 7, '/>Jay': 5, 'another.<br': 9, '/>Violent': 1, '/>\"Labyrinth': 1, 'game.<br': 12, '/>Amateurish': 1, '/>everyone': 2, '/>Edmund': 1, '/>Phew': 1, '/>Criticism': 1, '/>Marion': 3, '/>Dressed': 5, '/>Scary': 3, '/>Rarely': 1, '/>Beginning': 2, 'gentleman.<br': 2, '/>Others': 6, '/>***A': 1, '/>***1/2': 1, 'genre)<br': 1, '/>*1/2': 15, '/>BOMB': 1, 'language)<br': 1, '/>Pitt': 2, '/>Minus': 4, '/>www.tccandler.com': 1, '/>***STUNT': 1, '/>Zorro': 4, \"'s\": 2, '/>\"Enchanted': 1, '/>Welcome': 2, '/>Leave': 4, '/>Cristina': 1, '/>Konvitz': 1, 'imitations.<br': 1, '/>1.From': 1, '/>5.From': 1, '/>Depressed': 1, '/>Spoiling': 1, '/>Yaniss': 1, '/>it': 28, '.for': 3, '/>Executive': 5, \"anyway!'<br\": 1, '/>Chasing': 1, 'differences.<br': 2, '/>Cathryn': 1, '/>Ginty': 1, '/>Guilt': 1, 'masterful.<br': 1, '/>Ace': 2, 'fireplace.<br': 1, '/>ZORRO': 1, '/>Coburn': 2, 'Overall,\"Wendigo': 1, '/>Denise': 2, '/>Amongst': 5, 'remembered.<br': 3, 'woman(Campbell': 1, '/>Sweet': 1, '/>Lucas': 4, 'overstatement(Leslie': 1, '/>Sputnik': 1, '/>Engrossing': 1, '/>Brad': 8, 'inconceivable.<br': 1, 'interest.<br': 5, '/>Harmann': 1, '/>Problems': 1, '/>Travolta': 2, '/>Bud': 4, '/>Simon': 5, '/>Italy': 2, '/>Presque': 1, '/>Sigourney': 1, '/>Man': 19, '/>\"Catscratch': 1, '/>Viggo': 2, '/>Drawing': 1, '/>Marie': 2, '/>Floriane': 1, 'Fleet.<br': 1, '/>Actor': 6, 'still.<br': 1, '/>Encounting': 1, '/>Ginger': 1, '-blindfolded-': 1, '/>McBain': 4, 'laugh.<br': 2, '/>Leon': 1, '/>Imanol': 2, '/>Clara': 2, '/>Maslin': 2, '/>During': 21, 'there`s': 4, '/>DIRTY': 1, '/>Beyond': 6, '/>\"Stargate': 2, 'were.<br': 1, '/>Kay': 2, '/>Stefan': 2, '/>Silvio': 1, 'results.<br': 5, '/>Sound': 16, '/>Few': 9, '/>Moriarty': 1, '/>Jake': 3, '/>Indie': 1, 'acting(De': 1, '/>Ryan': 3, \"/>'Earth\": 1, '/>Muppeteers': 1, '.More': 1, '.Go': 1, '01/23/10': 1, '/>Yvan': 1, '/>Thumbs': 2, '/>Grable': 1, '/>Halloween': 8, \"/>'Full\": 1, '/>Campbell': 2, '/>Mystery': 1, '/>Richter': 1, '--until': 1, 'also.<br': 3, '/>Dev': 1, '/>R': 1, 'furniture\"--a': 1, '/>\"LOU': 1, '/>Furthering': 1, '/>History': 4, '/>Roeg': 3, '/>Allow': 3, 'lineup.<br': 1, '/>Wonderful': 6, '/>Ernst': 2, '/>Jimmy': 7, '/>Cherubic': 1, '/>Raising': 3, '/>Mendes': 1, '.but': 3, 'imagination.<br': 3, '/>Modern': 3, '/>Pollak': 1, '/>Puerto': 1, '/>Recognizing': 1, '/>French': 1, 'entendres(Sivan': 1, '/>Feels': 1, '/>Sly': 3, \"/>'Cliffhanger\": 2, '/>\"Knudsen': 1, 'impressed.<br': 2, '/>Astaire': 4, '/>Collections': 1, '/>Fondas': 1, '/>\"Offside': 1, 'effective.<br': 4, 'relevant.<br': 1, '/>Helena': 4, '/>Tatou': 1, '/>Bravo': 3, '/>Leonard': 1, 'Cumming(Who': 1, 'encounter.<br': 3, 'grasshoppers.<br': 1, '/>8.5/10': 3, 'embarrassing.)<br': 1, '/>Streep': 2, '-his': 2, '/>Enough': 6, '/>Trout': 1, 'imagine.<br': 3, '/>Lensed': 1, '/>Titanic': 1, '/>Cher': 2, '/>\"Zabriski': 1, '/>\"Cinderella': 3, '/>Wodehouse': 2, '.It': 8, '/>Level': 2, 'standard.<br': 2, '/>Adi': 1, '--no': 1, '/>Jur': 1, '/>August': 1, '/>Talk': 4, ':o)': 1, '/>Colman': 4, '/>Natali': 2, 'creators.<br': 3, '/>-Celluloid': 3, '/>Within': 6, '/>Rodrigo': 1, 'incredible.<br': 1, '/>Kenneth': 6, '/>Paramount': 1, \".They're\": 1, 'DVD.Billy': 1, '/>Samhain': 1, '/>Five': 9, '/>Erik': 2, '/>Golden': 1, '/>Gustad': 1, '/>8.6': 1, '/>Warren': 3, '/>Buy': 3, \"/>'Dan\": 1, '/>Rounding': 2, '/>Egan': 2, '/>Therese': 1, 'par.<br': 2, '/>Hagar': 2, '/>Aiding': 2, 'approach.<br': 5, '/>Rourke': 1, '/>Claremont': 1, '/>Cinematography': 4, '/>*You': 1, '/>Shin': 3, 'billboards.<br': 1, '/>Sarro': 1, '/>May': 10, '/>Paula': 2, 'charmer.<br': 1, '/>Cameron': 1, 'sublime.<br': 1, 'Boreanaz.<br': 1, '/>denzel': 1, 'western.<br': 1, '/>Wyoming': 1, '.it': 1, '/>Throw': 9, 'available.<br': 1, '/>Brain': 2, '/>Gregory': 4, '/>OUR': 1, '/>News': 2, '/>\"Europa': 1, '/>cons': 2, '/>Garam': 1, \"dream't\": 1, '/>Anton': 3, '/>Pete': 1, 'avail.<br': 1, 'appears.<br': 1, '/>WARNING': 4, '/>Dwight': 1, '/>Creaky': 1, '/>Ernesto': 1, '/>Riddled': 1, '/>Julia': 4, '/>Kino': 2, '/>Dog': 2, '/>Spend': 3, '/>Bye': 2, '/>Appreciation': 1, '/>\"Birthday': 2, '/>Seemingly': 5, '/>\"Gentleman': 2, '/>Biopics': 1, '/>anyhow': 1, '/>TV': 1, '/>Demonicus': 2, 'l\"s': 1, 'franchise.<br': 1, '/>\"CLIFFHANGER': 1, 'scripting.<br': 1, 'other(Jeffrey': 1, '/>Up': 6, '/>Scanners': 1, '/>\"Mystery': 1, '/>Jeaneane': 1, '/>Hank': 1, '/>Tomei': 1, '/>Lumet': 3, 'reasons.<br': 5, '/>Todd': 3, 'leadership.<br': 1, 'Hazlehurst.<br': 1, 'avoided.<br': 2, '/>----------------<br': 1, '/>------------<br': 1, '/>-------------------': 1, '/>Sven': 1, '/>Content': 1, '/>Sharon': 2, '/>Stargate': 2, '/>Question': 1, '/>\"Runaway': 1, '–': 81, '…': 5, '/>Mainly': 2, 'admirably.<br': 1, '/>-Now': 2, '/>-Ramsay': 1, 'diminish?)<br': 1, '/>Supposedly': 4, 'ourselves.<br': 2, '/>Stan': 7, '/>Pegg': 1, '/>Bridges': 1, 'edge.<br': 4, '/>Weide': 1, '/>Nolte': 5, 'diary.<br': 1, '/>Appolina': 1, '/>Dixon': 1, '/>Adam': 5, '/>Audrey': 2, '/>Over': 13, '/>IRS': 1, '/>Alex': 6, '/>Maya': 2, '/>Forgetting': 2, 'amazing.<br': 2, 'childhood.<br': 1, '/>Truth': 3, '/>Starting': 4, '/>Briefly': 3, '/>Ungar': 1, '/>Running': 2, '/>Ekin': 1, '/>Arthur': 9, '/>Bronte': 2, '/>Rochester': 2, 'central.<br': 1, '/>Helen': 6, '/>Sleeping': 1, '/>Gender': 1, '/>((SPOILERS': 1, '/>great': 2, '/>Reasons': 1, 'Nelson.<br': 1, '/>Vera': 2, '.She': 2, 'Hollywood.<br': 1, '/>Global': 1, 'lyrics.<br': 1, '/>Second': 11, '/>Cinematically': 1, '/>Main': 6, '/>Perfect': 2, '/>(Spoiler': 1, '/>\"Watch': 1, '/>Someone': 24, '/>Melvin': 1, 'afford.<br': 1, 'different.<br': 2, 'unstoppable.<br': 1, 'Adele.<br': 1, 'attitudes.<br': 2, '/>!!!YOU': 1, '/>Bendan': 1, '/>Hell': 3, \"/>Didn't\": 6, '/>BRENDAN': 1, '/>Heinlein': 1, '/>needless': 2, '/>Due': 5, '/>Voluntarily': 1, '/>EVIL': 1, '/>BLOWBACK': 1, '/>Appealing': 1, '/>De': 1, '/>Yo': 2, '/>MORE': 3, '/>Summer': 4, 'India.<br': 2, '/>Gunga': 1, '/>Signed': 2, '/>Between': 2, '-Mark': 1, \"/>'Classic\": 1, '/>Marcello': 2, '/>Soundtrack': 1, '/>\"They': 1, 'changed.<br': 1, '/>Malle': 1, '/>\"Well': 1, '/>Return': 1, '/>Fritz': 1, '/>Sonja': 1, '/>Everybody': 4, '/>Mostly': 3, '/>Shashi': 1, '/>CitizenX': 2, '/>Humans': 2, 'go.<br': 1, '/>Geoffrey': 2, 'idealism.<br': 1, '/>Joss': 1, '/>5yrs': 1, 'Bukhanovsky(Max': 1, '/>Fetisov': 1, '/>Chikatilo': 1, 'humans.<br': 2, '/>Conclusion:------------------------------------------------------------': 1, '/>Vengeance': 2, '/>watch': 4, '/>Toto': 1, '/>BEDKNOBS': 1, '/>Tulip': 1, 'countryside.<br': 4, '/>EDIT': 1, '/>\"Listening': 1, '/>\"Just': 2, '/>Rock': 4, '/>Similarly': 2, '/>Lauren': 3, '/>Carell': 3, 'rubric.<br': 1, '/>SHepherd': 1, '/>Ardolino': 1, 'price.<br': 2, \"/>Doesn't\": 2, '/>really': 1, '/>Monday': 3, 'pregnant.<br': 3, 'intertitles.<br': 1, 'sounds.<br': 2, '/>POLICE': 1, 'nausea.<br': 2, 'didn;t': 2, 'Vinnie(John': 1, 'stabs': 1, '/>Toronto': 1, '/>MovieManMenzel': 1, '/>Mol': 1, 'biopic.<br': 1, '/>Gretchen': 3, '/>Bettie': 3, 'types.<br': 1, '/>Talented': 2, '/>Scorpion': 1, 'chief(Kiefer': 1, 'agents(Martin': 1, '/>Care': 1, '/>\"Johnny': 1, '/>\"Aro': 1, '/>Buffy': 1, '/>Co': 8, '/>Damon': 1, '/>Omar': 2, '/>Kristen': 1, '/>Ice': 5, '/>\"Bleak': 1, '/>Ant': 1, '/>Hope': 7, '/>Cheadle': 2, '/>Secret': 1, '/>Working': 2, '/>Lombard': 1, '/>\"Rollin': 1, '/>Ohad': 1, '/>Steadfast': 1, 'enjoyed.<br': 1, '/>Kitty': 1, '/>interestingly': 1, 'quickly.<br': 8, '/>Ford': 2, 'experienced.<br': 1, '/>\"Halloween': 1, '/>Horror': 4, '/>MPAA': 6, '/>Technique': 1, '/>Anytime': 1, 'right.<br': 5, '/>Mann': 2, '/>Confronting': 1, 'dwarf(Angelo': 1, '/>Katryn': 1, '/>Homeward': 2, 'early-90s': 1, 'seriously.<br': 2, '/>Looks': 4, '/>Sandler': 2, '/>Worth': 22, 'ago.<br': 3, '/>Viewed': 1, 'roommates(Diana': 1, '/>Saying': 4, '/>Jeanette': 2, '/>*SPOILER': 2, 'SPOILER*<br': 1, '/>Charlotte': 3, '/>Hans': 1, '/>\"Young': 1, '/>Us': 2, '-spoiler-': 1, '/>Summary': 7, '/>\"Secret': 1, '/>Bobby': 2, '/>Inspiration': 1, '/>his': 3, '/>Mitch': 1, '/>Secrets': 1, '/>Members': 2, '/>Thoroughly': 3, '/>BTW': 1, '(for': 1, '/>India': 2, '/>Thankyou': 2, 'chaos.<br': 1, '/>Chaotic': 1, '/>Burt': 4, 'question.<br': 2, '/>Briskly': 1, 'moment.<br': 8, \"-i'm\": 1, 'ingeniously.<br': 1, '.In': 3, '/>Price': 3, '.Shot': 1, '/>Mumbai': 1, '/>Bhandarkar': 1, \"/>'Deliverance\": 1, '/>Deliverance': 2, '/>Big': 12, '/>Magnificent': 1, '/>Living': 2, '/>Clothing': 1, '/>IT': 2, '/>LOL': 1, '/>Goldsworthy': 1, '/>\"Hollywood': 1, '/>\"Haunted': 1, '/>Stanwyck': 3, 'image.<br': 1, 'requirement.<br': 1, '/>Göta': 2, '/>Straight': 3, '/>\"Nothing': 2, '/>GARDE': 2, '/>Benicio': 1, 'woman(Played': 1, '/>Viewing': 5, '/>Myazaki': 1, '/>AB': 1, '/>Better': 4, '/>Cant': 1, '/>Bhoomika': 1, '/>September': 1, '/>Gideon': 1, '/>Shown': 1, '/>Fifty': 1, '/>Nor': 4, '/>Waiting': 1, '/>Spencer': 1, 'stiffed.<br': 1, 'result.<br': 5, '/>than': 1, '/>director': 1, '/>has': 3, '/>is': 6, '/>Gone': 2, '/>Surprisingly': 2, '/>Patrick': 8, '/>Vintage': 1, '/>Offside': 1, '/>Lynch': 3, '/>Sir': 2, '---While': 1, '/>Ken': 2, 'disgrace.<br': 3, '/>Safely': 1, 'Americans.<br': 1, '/>Used': 1, '/>Twenty': 2, 'advancements.<br': 1, '/>Postscript': 1, '/>Miss': 7, '/>Marisa': 2, '--\"Hey': 1, 'competitor.<br': 1, '/>Proud': 1, '/>Noticeable': 1, \"/>'Mum\": 1, '/>Repeats': 1, '/>Emory': 1, '/>Somewhere': 7, 'unfortunately.<br': 2, '/>Budget': 3, 'lady.<br': 1, '/>IMHO': 2, '/>Worse': 12, '/>Stu': 1, '/>Larry': 7, '/>NOw': 1, '/>Ultimately': 9, '/>Everywhere': 1, '/>Pernell': 1, '/>Firefall': 1, '/>\"Without': 1, '/>Especially': 2, '/>Spock': 2, 'Albert.<br': 2, '/>Pierre': 1, '/>\"EASILY': 1, '/>YOU': 1, '/>AND': 6, '/>NOW': 1, '/>OF': 1, '/>WE': 2, '/>Sayonara': 1, '/>Joshua': 1, '/>Marlon': 2, '/>Buttons': 1, '/>Ricardo': 2, 'there.<br': 5, '/>Hudson': 1, '/>\"You\\'re': 1, '/>Nelson': 1, 'watchable.<br': 4, 'fools.<br': 1, '/>Massey': 1, '/>Wells': 1, '/>Little': 6, '/>Tough': 1, '/>Cyhper': 1, '/>\"Strangler': 1, '/>Rosemary': 1, '/>Sieben': 1, '/>Dont': 2, '/>(And': 2, '/>Elijah': 1, '/>Natalie': 2, '/>Enjoy!<br': 1, '/>Listen': 1, '/>Danny': 5, '/>Forgive': 1, '.yet.<br': 1, '/>Guevara': 1, '/>High': 2, '/>Restored': 1, 'sassy.i': 1, '/>its': 6, 'movie.i': 3, '/>again': 1, '/>War': 2, '/>Mandy': 3, 'develop.<br': 1, '/>\"Bustin': 1, '/>Racism': 2, '/>Racist': 1, '/>Debut': 1, '/>Captured': 1, '/>PROS': 2, '/>-Jon': 1, '/>-Not': 2, '/>CONS': 2, '/>-For': 1, 'restrooms.<br': 1, '-cut': 1, '/>Homicide': 1, '/>Vote': 5, '/>Drug': 1, '/>Conclusion': 13, 'easy.<br': 5, '/>Alison': 4, '/>Waqt': 1, '/>Eureka': 1, \"/>'Waqt\": 1, '/>Trivia-': 1, '/>22nd': 1, '/>Immortel': 1, 'charming.<br': 2, '/>Continuing': 3, '/>Close': 1, '/>Roman': 1, '/>Michelle': 7, '/>Pecker': 1, '/>Comedians': 1, '/>\"Man': 3, '/>Landscapes': 1, 'Shirley,\"Murder': 1, '/>Scorcese': 2, '/>Generally': 5, '/>SAPS': 2, 'works!<br': 1, '/>Producer': 10, 'street.<br': 5, '/>Widowed': 1, '/>Highlight': 1, '/>Blethyn': 1, '/>Carol': 1, '/>God': 9, 'subtle.<br': 1, '/>Beside': 5, 'impressive.<br': 1, '/>Theology': 1, '/>Home': 2, '/>SHOW': 2, '/>Davies': 4, '/>Jason': 10, 'inside.<br': 3, '/>\"Of': 1, '/>Hanna': 2, '/>Uniqueness': 1, 'richer.)<br': 1, '/>Seven': 6, '.etc': 1, '/>\"Kansas': 1, '/>===========': 1, 'subdued.<br': 1, '/>Ahmad': 1, '/>Duprez': 1, '/>\"Thief': 1, '/>Terrific': 3, '/>Harriet': 1, '/>Rogers': 1, '/>6.5/10': 1, '/>(The': 3, '/>Must': 3, 'ridiculous.<br': 11, '/>Lifshitz': 1, '/>\"War': 1, '/>Couple': 1, '/>---<br': 1, '/>Forgot': 1, '-all': 1, '/>Sid': 1, '/>Washington': 3, 'manner.<br': 3, '/>Pierce': 1, '/>Dietrich': 1, '/>Pleasence': 1, '/>perhaps': 3, '/>death': 1, '>': 6, '/>Lead': 3, '/>\"Reign': 1, '/>\"Creature': 1, '/>Funnier': 1, '-By': 1, '/>Gere': 2, 'wood.<br': 1, '/>--': 7, 'efforts.<br': 3, '/>Sit': 1, '/>Need': 2, 'gloriously!--to': 1, '/>Rains': 1, 'represents.<br': 2, '/>Sam': 4, '/>Falk': 2, '/>\\x91Waxworks': 1, '/>Einstein': 1, '/>Compared': 3, '/>live': 1, '/>Busey': 1, '/>T.L.': 1, '/>\"Bulletproof': 1, '/>Florida': 1, '/>Jet': 3, '/>Hoo': 1, '/>Chalk': 3, '/>Sidenote': 1, '/>A-': 1, 'rental.<br': 1, 'projections.<br': 1, \"'cos\": 3, '/>Theo': 1, '/>Serious': 1, '/>Fraggle': 1, '/>Cassavetes': 2, 'performed-': 1, '/>Kevin': 8, 'Jr.(Alfred).<br': 1, '/>Villains': 1, '/>Stop': 2, '/>Seeming': 1, '/>Talking': 3, 'exaggerated.<br': 2, '/>Siobhan': 2, '/>Katie': 1, '/>anyway': 4, '/>Actuelly': 1, '!<br': 2, '/>Treat': 3, '/>Yep': 4, '/>Lithgow': 2, '/>Ahh': 3, '/>Vive': 1, '/>-AP3-': 2, '/>Makes': 2, '/>from': 3, '/>all': 12, '/>Runtime:106min': 1, '/>Fast': 8, '/>\"Grand': 1, '/>(since': 1, '/>publicists': 1, '/>Loretta': 6, '/>Judge': 1, '/>American': 3, 'gory),a': 1, '/>New': 5, '.At': 2, 'disappoint.<br': 1, '/>Matches.<br': 1, '/>WWF': 4, '/>Taka': 2, '/5': 3, '/>Triple': 1, '/>4/5': 1, '/>Mixed': 1, '/>Dumpster': 1, '/>Catcus': 1, '/>HBK|C|': 1, '/10': 2, ':-(': 5, '/>Herbert': 2, '/>Collete': 1, '/>Creamtor': 1, '/>F.': 2, '-of': 1, '-one': 3, 'slavery.<br': 2, '-not': 3, '/>Kyle': 3, '/>Douglas': 4, '/>Cunningham': 3, 'evil.<br': 2, '/>Aonghas': 1, '/>Miller': 4, \"'coz\": 1, '/>Onstage': 3, '/>Gauri': 1, '/>\"Vuxna': 1, '/>Baiscally': 1, '/>Suspenseful': 1, '/>Trnka': 1, '/>\"Der': 1, '/Lars': 1, 'accent.<br': 1, 'perfection.<br': 1, 'begin.<br': 2, 'Smith.<br': 1, '/>Ashley': 1, '/>Incridible': 1, '/>Synopsis': 3, '/>www.softfordigging.com': 1, 'reunion.<br': 2, '/>one': 2, 'chuckle.<br': 1, '/>Johnny': 3, 'above.<br': 3, 'Robby.<br': 1, '/>Forbidden': 1, '/>Diamond': 2, '/>Master': 1, '/>Capote': 1, 'imaginings.<br': 1, '/>WARNING!DON`T': 1, '/>7\\\\10': 1, '/>Racy': 1, '/>\"Carmen': 1, '/>Corky': 3, 'repertory.<br': 1, '/>Nathalie': 1, 'anniversaries?': 1, '\"Big': 1, '/>Skip': 10, '/>C+': 1, '/>Extra': 2, '/>Against': 2, '/>\"Bug': 1, 'quibble.<br': 1, '/>Ron': 3, 'project.<br': 7, '/>Gordon': 1, '/>Brian': 6, '/>Glenda': 2, '/>Mao': 1, '/>Sadly': 2, '/>CRAIG': 1, 'Signalman.<br': 1, '/>Page': 2, 'research(and': 1, 'anime)<br': 1, 'way.(I': 1, '/>Production': 4, '/>Phantom': 3, '/>Franchot': 1, 'alarming.<br': 2, '/>Respect': 2, '/>(As': 1, '/>Riding': 1, '/>Genre': 2, '/>Volckman': 2, '/>-8/10': 1, '/>Mikael': 1, '/>THANK': 1, '/>Joining': 1, '/>Present': 1, '/>Cage': 4, '/>Allison': 1, '/>\"Pick': 2, '/>Hot': 1, '/>\"Meatball': 2, \"/>i'm\": 5, 'irritating.<br': 7, '/>Amazing': 2, 'to?I': 1, '/>\"Fido': 2, 'directing.<br': 1, '/>Accomplished': 1, '/>\"Hamlet': 1, 'I.e.': 2, '/>Brooke': 1, '/>Rosie': 1, '/>Celeste': 1, \"-You'll\": 1, '/>Gena': 3, 'covered.<br': 1, '/>Growing': 2, '/>Weir': 1, '/>\"Losing': 1, '/>Surronding': 1, '/>Screenwrtier': 1, '/>Creasy': 1, '/>Norm': 1, '/>Encouraging': 1, 'encouraged.<br': 1, '/>Sammo': 2, '/>Durbin': 1, 'apartment.<br': 8, '/>Lemmon': 1, '/>Summing': 10, \"/>'Where\": 1, '/>Farrell': 1, '/>Aditya': 1, '/>Clear': 1, '/>Anu': 1, '/>Boman': 1, '/>Shefali': 1, '/>Tolkien': 1, '/>Denis': 1, 'hubris.<br': 1, '/>\"Homicide': 1, '/>Obs': 1, '/>Nick': 5, '/>Feel': 3, '/>***Possible': 2, '-in': 3, '/>Loaded': 1, '/>Usually': 8, '/>Domino': 2, '/>Moving': 4, '/>Stuff': 3, '/>Enjoyable': 1, '/>Helps': 1, '/>Stardust': 1, '/>Earth': 1, \"/>'Assi\": 1, '/>Higher': 2, '.initially': 1, '/>(Minor': 3, 'officers.<br': 2, 'appreciation.<br': 2, '/>Highpoints': 2, '/>Crosby': 1, '/>Basil': 2, '/>Hi': 1, '/>Von': 3, '/>Sullavan': 1, '/>\"Manufactured': 1, '/>Patric': 1, '/>Brother': 3, '/>Rabbit': 2, '/>FINAL': 7, 'insignificant.<br': 1, '/>Above': 2, '/>Specifically': 1, '/>Hallen': 1, '/>-Keep': 1, '/>-One': 2, '/>\"After': 1, '/>Lino': 1, '/>Michel': 1, '/>\"House': 2, '-\"Killer': 1, '/>Truman': 2, '\"In': 1, 'victims.<br': 4, '/>Bob': 2, '/>Candice': 1, '/>Grab': 2, '/>Darkly': 1, 'responsibility.<br': 3, '/>Cacoyannis': 1, '/>\"Contra': 2, '/>\"Husbands': 2, '/>Ignore': 3, '/>(PS': 1, '/>ZIV': 1, 'even.<br': 1, '/>Moroder': 1, 'crowd.<br': 3, '/>Mafia': 1, '/>CABAL': 2, '/>Disregard': 1, '/>Interestingly': 5, '/>Colm': 1, 'witnessed.<br': 2, '/>Luise': 3, '/>Muni': 2, '/>Till': 2, '/>\"Gung': 2, '/>Kazuhiro': 1, '/>Poison': 1, '/>Direction': 19, '/>*****SPOILERS': 3, 'collector.<br': 1, 'haven´t': 1, 'don´t': 2, '/>Open': 5, \"/>'Alan\": 1, '/>Sarah': 4, '/>strong': 2, '/>11-year': 1, '/>\"Paperhouse': 1, '/>Met': 1, 'institutionalized.<br': 1, '/>laughed': 1, '/>ACTING': 6, '/>STUNTS': 1, '/>HOW': 2, '/>Pic': 1, '/>Seldom': 3, 'dynamics.<br': 4, '/>Scarface': 1, '/>Review': 6, 'stars(Chuck': 1, 'inspired.<br': 2, '/>Day': 1, '/>Visit': 1, '/>EXCELLENT': 1, '/>\"Will': 2, '/>Interested': 1, '/>Devil': 3, 'AC(aka': 1, '/>Optimum': 1, 'intense.<br': 3, '/>Vivian': 3, '/>Darren': 2, \"/>i'd\": 1, '/>Juliette': 2, '/>Kamal': 2, 'terrific(Denis': 1, '/>Barring': 1, '/>Documentarians': 1, '/>Penelope': 3, '-is-': 1, '-was-': 1, '/>Ossie': 3, '/>Akshay': 10, '/>6.5': 1, '/>Nicolas': 5, '/>J.': 1, '/>Boyle': 2, 'too(Badder': 1, 'this?)and': 1, '/>Drawbacks': 1, '/>nice': 1, 'nice.<br': 1, '/>Hailing': 1, 'insightful.<br': 2, '/>Moreover': 3, '.Joan': 1, 'colonel(Montagu': 1, '/>long': 3, '-(Alexis': 1, '/>-Erica': 1, '/>Angela': 3, 'naturally.<br': 1, '/>MUCH': 1, 'sweet)<br': 1, 'for.<br': 1, 'endeavors.<br': 1, '/>Morris': 2, '/>\"Atlantis': 1, 'adults.<br': 1, '/>deplicted': 1, 'infected.<br': 1, '/>7ish': 1, '/>Sally': 1, 'slumber.<br': 1, 'sorrows.<br': 1, 'readers.<br': 1, '/>Plus': 11, '/>Examining': 1, '/>Lt': 1, '/>Columbo': 2, 'safe.<br': 1, '/>Bogus': 1, '/>Police': 1, '/>Les': 4, '\"Men': 1, '/>Mostel': 1, '/>Belafonte': 2, '/>Mecha': 1, '/>Thnks': 1, '/>Reed': 1, '/>Turner': 2, '/>Suspense': 2, 'exposure.<br': 1, '/>Anywhozitz': 1, 'field.<br': 2, 'preferred.<br': 1, '/>Shows': 2, '/>Foxes': 1, '/>\"Evening': 1, '/>Raul': 2, '/>-R.': 1, '/>\"Burning': 1, '/>Iberia': 1, '/>Saura': 1, '/>Ala': 1, 'consideration.<br': 2, '---Q': 1, '/>---': 9, '/>Stories': 1, '/>Spielberg': 1, '/>Whoopi': 2, '/>Feast': 1, 'G.I.s': 1, 'deliver.<br': 1, 'endings.<br': 1, '/>Criterion': 1, '/>Focusing': 1, '/>Feyder': 1, '/>Garbo': 1, 'infectious.<br': 2, '/>film': 2, '/>us': 1, '/>!!!SPOILERS!!!<br': 1, '/>Cole': 1, '/>PLOT': 3, '/>Sword': 1, '/>RUSSAIN': 1, '/>Kurt': 4, '/>Katsu': 1, '/>Laputa': 2, 'vision.<br': 1, '/>Miyazaki': 1, '/>Dominic': 1, '/>Introduce': 1, '/>*This': 2, 'pace.<br': 1, '/>Joanna': 2, '/>Spanish': 1, 'humor.<br': 1, '/>Roger': 2, '/>\"El': 2, '/>(Marlon': 1, '/>run': 1, '/>Brown': 3, '/>Broadway': 1, 'productions.<br': 1, '/>Elinore': 1, '/>Nicely': 2, 'explained.<br': 6, '/>Lorenzo': 2, '/>Superman': 5, 'Spoilers!<br': 2, '/>Added': 3, '/>Lanisha': 1, 'Incredible.<br': 1, '/>Incredible!<br': 1, '/>Stunningly': 1, '/>Antonioni': 3, '/>Warner': 2, '/>Lying': 1, '..........................................': 1, '.....................': 2, 'supported.<br': 1, '/>Brokedown': 2, '/>Picking': 3, '/>Outspoken': 1, 'friend(who': 2, '/>Molly': 2, '/>Seek': 3, '/>Dennis': 3, '/>Heavy': 1, 'alot.<br': 1, '/>(Do': 1, 'd.v.d.<br': 1, '/>Steven': 12, 'scene!!<br': 1, '/>Beery': 2, '/>Getting': 2, '/>Lindsay': 4, '/>House': 3, '/>\"Lady': 1, '/>\"Shanghai': 2, '-so': 1, '/>Gino': 1, '/>Erika': 3, '/>Pedicab': 1, '/>Admittedly': 9, '/>(sorry': 4, 'Sleepwalkers.<br': 1, '/>\"Earth': 2, '/>Via': 1, '/>\"Wendigo': 1, '/>Miles': 1, '/>Crosseyed': 2, '/>Talespin': 1, '/>Schwarzenegger': 1, 'humour?)<br': 1, '/>Jesse': 3, '/>Lars': 1, '/>Cervi': 1, '/>Republic': 1, '/>\"Stories': 1, '/>(Regarding': 1, '/>Zabriskie': 1, '/>Screenwriter': 1, '/>Kureishi': 1, '/>Gritty': 1, '(not': 1, 'gangs.<br': 1, '/>FANFAN': 1, '/>9/11': 1, '/>Pinjar': 1, 'flourish.<br': 1, 'remains.<br': 1, 'combined.<br': 2, 'revolution.<br': 1, 'considerably.<br': 1, '/>FUN': 1, '/>Writers': 2, '/>as': 4, '/>Quaid': 3, ':-P': 2, '/>Btw': 2, 'connection.<br': 1, '/>Artemisia': 1, 'grip.<br': 1, 'Benton(Tom': 1, 'taken(the': 1, '/>Timberlake': 5, '/>\\x91The': 1, '/>Jena': 1, '/>Liev': 1, 'emotion.<br': 2, '/>Wayne': 3, 'arms.<br': 1, '/>Marc': 3, '/>Younger': 1, '/>Albert': 5, '/>Hickory': 1, '/>Bleak': 1, '/>Sergeant': 1, '/>Ada': 1, '/>Mrs': 2, '/>Tulkinhorn': 1, 'opaque.<br': 1, 'vanished.<br': 2, '/>JUST': 2, '/>Caine': 2, '/>Barrie': 2, '/>Remarkably': 1, '/>British': 3, '/>Somehow': 13, 'roots.<br': 2, '/>Subtlety': 2, '/>Norman': 1, '/>RF': 1, '/>------': 2, '/>Callan': 1, '/>Stuck': 1, 'greatly.<br': 1, '/>Queen': 1, '/>Andrea': 2, '/>Giullia': 1, '/>Dead': 3, '/>Family': 1, 'castle.<br': 2, '............': 7, '/>===================': 1, '/>Shrouded': 1, '.I': 7, '.............': 11, '/>Lincoln': 1, 'kids.<br': 13, '/>Bedknobs': 1, '/>Former': 2, 'reactionism.<br': 1, '/>there': 3, '/>pretty': 1, '/>Amrita': 1, '/>BLISS': 1, '/>Bruce': 5, '/>Gret': 1, 'guilty.<br': 1, '.45': 1, '/>Judas': 1, 'coach(Dennis': 1, '/>akshay': 1, '/>Debating': 1, '/>Sinnui': 1, '/>Flavia': 1, '/>Head': 2, '/>Miriam': 1, 'film(and': 1, '/>Bret': 3, '/>July': 1, '/>Wonderland': 1, '/>Fawcett': 1, '/>Returning': 2, '/>Color': 1, 'murder.<br': 1, '/>-LD': 1, 'http://www.angelfire.com/ny5/jbc33/': 1, '/>Milverton': 1, 'regretful.<br': 1, '/>Outstanding': 3, '/>*The': 7, '-A': 2, '/>-Plus': 1, '/>-Overall': 1, '/>Maude': 1, '/>Bobbing': 1, '/>Pros': 11, '/>Cons': 12, 'Iturbi.<br': 1, '/>-Ben': 1, 'backgrounds.<br': 2, '/>Pinky': 1, '/>Under': 5, '/>-This': 1, '/>-It': 2, '/>-If': 1, '/>Snobbery': 1, '/>Wait': 6, '/>***7/10***<br': 1, '/>Foch': 1, 'preordained.<br': 1, '.However': 1, 'listening?).<br': 1, 'call.<br': 1, '/>SN': 1, 'Ankylosaurus.<br': 1, '/>Russ': 1, '/>Pressing': 1, '/>WORLD': 1, '/>Pimlico': 1, '/>Flawed': 1, '/>\"Whipped': 2, '/>WuMaster': 1, 'hit.<br': 1, '/>Stubby': 1, 'sense.<br': 1, '/>Matiss': 1, '/>Haunting': 1, '/>ENTERPRISE': 1, 'confession.<br': 1, 'more.<br': 7, '/>\"Piedras': 1, '/>CAT': 1, '/>Dylan': 1, '/>Yaara': 1, '/>Inevitably': 1, '/>Noteworthy': 1, '/>TEARS': 1, '3.5/5': 3, '/>Emil': 2, '/>Cruella': 2, '/>Guinness': 4, '0)when': 1, '/>~*~CupidGrl~*~': 1, '/>\"All': 1, '/>Bring': 2, 'comics.<br': 1, '/>Hickock': 2, '/>Calamity': 1, '/>Aware': 1, 'series.<br': 1, '/>Combine': 1, '/>Recent': 1, '/>Undoubtedly': 2, '/>BLOG': 1, '/>PARDON': 1, 'realistic.<br': 1, '/>about': 4, '/>Chocolat': 1, '/>René': 1, '/>Mencia': 1, '/>Wang': 3, '/>Rukh': 2, '/>\"Good': 2, 'genre(David': 1, '/>Fatty': 1, '/>Beats': 1, '/>Bus': 1, '/>Soccer': 1, 'everybody.<br': 3, '/>Renaissance': 2, '/>Pixar': 2, '/>or': 2, '/>saying': 1, '/>Rayvyn': 1, 'previews(HBO': 1, 'wall.<br': 4, '/>IF': 3, '/>rating': 2, '!!!and': 1, 'ambition.<br': 1, '/>\"Artemisia': 1, '/>Valentina': 1, '/>Star': 3, '/>McCoy-': 1, 'horrors.<br': 1, '/>Nicole': 1, '/>6/10': 3, 'apparent.<br': 1, '/>Ratso': 1, '/>Flash': 1, '/>Damion': 1, '/>Imagine': 12, 'scenery.<br': 2, '/>(This': 3, '/>Molden': 1, 'Queen.<br': 1, 'regent.<br': 1, '/>King': 4, 'blank.<br': 1, '/>Deserves': 2, '/>P.s': 3, '/>Incubus': 1, '/>Moonstruck': 1, '/>Anddd': 1, '/>Dreamworks': 1, '/>Th': 1, '/>Bend': 1, '/>http://blog.myspace.com': 1, 'way?<br': 1, '.hmmmm': 1, 'cultivate.<br': 1, '/>Superb': 1, '/>Alejandro': 1, 'anecdote.<br': 1, '/>\"Extremities': 1, '/>Party': 1, '/>\"Tell': 1, '/>Women': 5, '/>Sex': 1, '/>Fastward': 1, 'http://www.johntopping.com/Harvey%20Perr/War%20Widow/war_widow.html': 1, 'sigh.<br': 1, '/>\"Pandora': 1, '/>Violence': 3, '/>~Ashley~': 1, '/>Rugged': 1, '/>Lily': 2, '/>Streets': 2, '/>Easy': 1, '/>Cons:<br': 1, '/>Vastly': 1, '/>Lack': 3, '/>\"Erendira': 1, ':-D': 5, 'Eternity.)<br': 1, 'benefit.<br': 1, '/>Robby': 1, '/>Classicists': 1, '/>Happy': 4, '/>enjoy!<br': 1, '/>Dona': 1, '/>Lucien': 1, 'interesting?)<br': 1, '/>Melvyn': 2, '/>Raymond': 4, '/>Alice': 11, '/>EUROPA': 3, '/>Maria': 3, '/>Fairly': 1, '/>Normally': 7, 'players.<br': 1, 'Pickford.<br': 1, '/>Pickford': 2, '/>Sort': 2, '/>Montague': 1, 'status.<br': 1, '/>Marvelous': 1, '/>BRAVO': 1, '/>Salman': 2, '/>Ellen': 3, '/>Greetings': 1, '/>Greg': 1, '/>Thiessen': 1, '11/21/01': 1, '/>-Kish': 1, '/>Gossip': 1, 'Martin.<br': 1, '/>Match': 9, '/>Announcement': 1, '/>Andrew': 2, 'plato.it': 1, 'brief.<br': 1, '/>Schizophreniac': 1, '/>\"Coonskin': 2, 'obviously.<br': 2, '/>Bakshi': 3, 'hand.<br': 1, '/>Number': 2, '/>Credit': 3, '/>Somerset': 1, '/>Pauline': 1, '/>Adele': 1, '/>Moonwalker': 1, '/>Hooray': 1, 'postscript.<br': 1, '/>Vietnam': 1, '/>Betty': 2, 'emotions.<br': 2, '/>\"Stardust': 3, 'youth.<br': 2, '/>Complicated': 2, '/>Tristain': 1, '/>Kari': 1, '/>Pre': 2, '/>Gotta': 2, '/>BOA': 1, '/>Lacking': 1, '/>Hella': 1, '/>Storywise': 2, '/>Concern': 1, '/>Cameras': 1, '/>Restricted': 1, '/>Computer': 1, '/>Jailing': 1, '/>Flagging': 1, '~must~': 1, 'AnaR': 1, '/>Honest': 1, '/>Yeoman': 1, '/>RETURNING': 1, '/>IN': 2, 'dejectedly.<br': 1, '/>UNDOUBETLY': 1, '/>POODLE': 1, '/>Meantime': 1, '/>Revisiting': 1, '/>FIRST': 1, '/>FIFTH': 1, '/>SIXTH': 1, '/>EIGHT': 1, '/>Show': 5, '/>Afrika': 1, '/>Bravi': 1, '/>Martino': 1, '/>Kenny': 1, '/>Blues': 2, '/>Denied': 3, '/>Losing': 1, '/>Imaginative': 1, '/<br': 1, '/>Gunbuster': 1, '/>***/': 2, '/>TEN': 1, '/>Claude': 1, '/>---SPOILERS---<br': 1, '/>Johansson': 1, '/>Del': 1, '/>Couched': 1, '/>Performances': 7, '/>Ably': 1, '/>Rosario': 2, '/>Ah': 4, 'techniques(even': 1, '/>Least': 1, 'lighting.<br': 1, '/>Honestly': 12, '/>Type': 3, 'erupting.<br': 1, 'employees.<br': 1, '/>Suleiman': 1, '/>Judy': 1, ')gives': 1, '/>Altogether': 4, '/>Liam': 3, 'Antwerp.<br': 1, '/>Macy': 1, 'first.<br': 1, \"was'nt\": 1, '/>BASIC': 1, '/>THEME': 1, '/>Quartier': 3, '/>Quatier': 1, '/>Quais': 1, '/>Tour': 2, '/>Tuileries': 2, '/>Bastille': 1, '/>Pére': 1, '/>Parc': 2, '/>Porte': 1, '/>Pigalle': 1, '/>14th': 2, '/>Montmartre': 2, '/>Loin': 2, '/>Place': 2, '/>Faubourg': 1, '/>regards': 1, '/>Danish': 1, '/>China': 1, 'genres.<br': 1, '/>tim': 1, 'words.<br': 1, '/>DAN': 1, '/>Fanfan': 1, 'parents.<br': 2, '/>Vesna': 1, '/>Petr': 1, '/>\"Arzenta': 1, '/>\"Tess': 1, '/>Media': 1, 'guess(the': 1, '/>City': 3, '/>Hmm': 5, 'anyway.<br': 2, '/>Grizzled': 1, '\\x91cause': 1, '/>\"Krisana': 2, 'adventures(In': 1, '/>Geoff': 1, 'conceals.<br': 1, 'resignation.<br': 1, '/>\"What': 2, '/>Idealistic': 1, \".I'd\": 1, '.Underwater': 1, 'It.<br': 1, 'powers.<br': 3, '/>Torn': 1, '/>6': 9, '/>Troubles': 1, '/>Kristofferson': 1, '/>Magnus': 1, '/>Bonus': 2, \"/>'12\": 1, '/>Danni': 1, 'friends(Danni': 1, '/>Court': 1, '/>Peck': 2, '/>Funnily': 1, '/>Guys': 4, '/>Waterman': 1, '/>Scoop': 2, '/>Children': 3, '/>Gung': 1, '/>Brought': 2, '/>Wendy': 4, '/>Tracking': 1, '/>Sweets': 1, '/>Jules': 1, '/>Fujiko': 1, '/>Chaulk': 1, '/>Lionsgate': 1, 'high.<br': 1, '/>Possible': 1, '/>Hawn': 2, 'surprise\\x97through': 1, '/>edward': 1, '/>\"edward': 1, '/>Lieutenant': 1, '/>Kabei': 1, '/>Peoples': 4, '/>Incredible': 2, '/>Gwyneth': 2, '/>Leno': 1, '/>CONCEPT': 1, \"/>'Carter\": 1, 'raft.<br': 1, '/>Grace': 1, '/>Nigel': 1, '/>Whats': 4, 'interesting.<br': 7, '/>#####SPOILERS': 1, 'foiled.<br': 1, 'pretentious.<br': 1, 'owner.<br': 1, '/>STEPHEN': 1, '/>Oops': 1, 'that???<br': 1, 'equipment.<br': 2, '/>Warmly': 1, 'C-3PO': 1, '/>Bing': 2, '/>Cute': 1, 'Moreno);<br': 1, '/>Perennial': 1, '/>Adultery': 1, 'post-911': 1, '/>Samantha': 1, '/>*****JUST': 1, \"/>'Soapdish\": 1, 'granted.<br': 1, 'together.<br': 2, '/>Unlikely.<br': 1, '/>Anna': 4, '/>Gradually': 1, 'crime.<br': 3, '/>Broinowski': 1, 'images.<br': 1, '/>Favourite': 4, '/>BABY': 1, '/>***Good': 1, '/>**Fair': 1, '/>*Poor': 1, '/>`Go': 1, '/>Heath': 4, '/>Vincent': 3, '/>LE': 1, \"Shoot'em'up\": 1, '/>Robot': 1, '/>Marilyn': 1, '(but': 1, '-two': 1, '/>P.P.-': 1, '/>Drawings': 1, '/>Addendum': 1, '/>Bille': 1, '/>Unforgettable': 1, '/>TARZAN': 1, '/>Comedy': 2, '/>Expect': 1, '/>Borden': 1, 'hideous.<br': 1, '/>look': 2, '/>brood': 1, '/>have': 2, '/>Fellini': 1, '/>almost': 2, '/>headdress': 1, '/>that': 2, '/>even': 3, '/>along': 1, '/>model': 1, '/>find': 1, '/>full': 2, '/>bliss': 1, '/>Highlights': 6, '/>since': 1, '/>Anger': 1, '/>worth': 1, '/>Kei': 1, '/>Nearly': 3, 'together.(in': 1, '/>Laced': 1, '/>Criticisms': 2, '/>Paxinou': 1, '/>Lance': 1, '/>cheers': 2, '/>Underscored': 1, 'rescue.<br': 2, '/>Donovan': 1, '/>Average': 1, 'SWs': 1, 'http://imdb.com/mymovies/list?l=21849890': 1, '-as': 1, '/>Pity': 2, '/>\"HealtH': 1, 'supporter.<br': 1, 'does.<br': 2, '/>Honey': 1, '/>\"Prison': 1, 'anger.<br': 1, '/>Kind': 6, 'visited.<br': 1, '/>Howard': 2, 'institute.<br': 1, '/>Ricky': 1, '/>Zombie': 6, '/>Contribution': 1, '/>Whoever': 7, '.and': 2, '/>Resnais': 1, '/>V': 1, '.................': 1, '/>PARTIAL': 1, '/>THERE': 1, '/>Ealing': 2, '/>-Chris': 3, '/>Hergé': 1, '/>Ups': 4, '/>Downs': 4, 'ebay.<br': 1, 'develops.<br': 1, '/>Cooper': 1, 'partner(Asian': 1, ':-(<br': 1, '/>Murdering': 1, '/>Light': 1, '/>Pushing': 1, '/>Pia': 2, '/>Runtime:88min': 1, 'remember.<br': 1, '/>Binder': 1, '/>Lot': 1, '/>*************************WARNING': 1, '/>RIP-': 1, 'hangouts.<br': 1, '/>\"Gunga': 2, 'battle.<br': 2, 'business.<br': 1, '/>Myrna': 2, 'confident.<br': 1, '/>(My': 1, '/>JON': 1, '/>Airwolf': 2, '/>Casevettes': 1, '/>Justine': 1, 'ages.<br': 1, '/>McGavin': 1, '/>Recognized': 1, '/>Somebody': 3, '/>\"Community': 1, '/>Majkowski': 1, '-it': 1, '/>Rita': 1, '/>Ferrell': 1, '/>Nostalgia': 1, '/>Willy': 1, '/>\"Hello': 1, 'replies.<br': 1, '/>Joey': 3, '/>Jacqueline': 1, '/>Crashing': 1, '/>Skywalker': 1, '/>ROTJ': 1, '-_-': 2, '/>Marcus': 1, '/>\"Hot': 1, '/>Ahah': 1, '/>Marsha': 1, '/>Walt': 2, '/>Moon': 1, '/>Townsend': 1, '/>Craig': 1, '/>Millar': 1, '/>Sniper': 1, '/>\"Panic': 3, '/>Misc': 1, '/>Urmila': 1, '/>Sandhali': 1, '.Who': 1, 'killer?.The': 1, '/>Regards': 1, 'comedy)-': 1, '/>\"Prepare': 1, 'adversary.<br': 1, '/>Tobey': 1, '/>Jeffrey': 2, '/>**out': 1, '/>Attention': 1, '/>Completely': 3, '/>Castle': 2, 'layman.<br': 1, '/>Fiennes': 1, 'care.<br': 7, '/>Joy': 1, '/>Novella': 1, '/>Paraminder': 1, '/>Pleasant': 2, 'moan.<br': 1, '/>Smackdown': 1, '/>Teddy': 2, '/>Mercury': 1, '/>Chris': 10, '/>Helms': 1, 'sooner.<br': 1, '/>Rea': 2, '/>\"Zatôichi': 1, 'Shushui)--a': 1, '/>Months': 1, '/>Pluses': 1, 'retort.<br': 1, '/>Lets': 7, '/>Amrish': 1, '/>Sharply': 1, '/>Shatner': 1, '/>Cheers.<br': 1, '/>Sick': 2, '/>Kathryn': 3, '/>Gérard': 1, 'answer.<br': 1, 'redneck.<br': 1, '/>Li': 1, '/>\"Hickory': 1, '/>Franck': 1, '/>Trudi': 1, '/>Vincente': 1, '/>Minnelli': 1, '/>Irene': 1, '/>Greta': 1, '.Li': 1, '.Francoise': 1, '/>MEATBALL': 1, '/>Welling': 1, '/>Revenge': 2, \"Bergman';s\": 1, '/>Deathtrap': 1, '/>Clever': 2, 'class.<br': 2, '/>~~~Rube': 1, 'etc).<br': 1, '/>8.9/10': 1, '/>Preston': 2, 'emotionally.<br': 2, '/>Honorable': 1, '4EVA': 1, '/>\"Why': 4, 'arrive)<br': 1, '/>\"Lord': 1, '/>\"Does': 1, '/>Twelve': 1, '/>Peace': 2, '/>Clyde': 1, '/>Abetted': 1, '/>Released': 4, '/>-R': 1, '/>EPISODE': 13, '/>TRICK': 1, '/>Glen': 1, '/>Doug': 2, '/>Intelligent': 1, '/>DANIEL': 1, '/>BRENDA': 1, '/>Richly': 1, '/>Biko': 1, '/>though': 1, 'methods.)<br': 1, '/>SHUT': 1, 'rouge!but': 1, '/IS/': 1, '-R.': 1, '/>Billed': 1, '/>Beautifully': 3, '---If': 1, '/>\"Enter': 1, '/>Tick': 1, '\"If': 1, '/>Tip': 2, '/>Grady': 3, ',Trading': 1, '/>\"Live': 2, '/>Moderately': 1, 'rain.<br': 1, '/>Sonny': 2, '/>Grisby': 1, '/>Relative': 2, '/>Bianca': 1, 'shows.<br': 3, '/>Characterizing': 1, '/>Kathleen': 2, 'TAS.(Two': 1, 'skin.<br': 1, 'cast(the': 1, 'has!)are': 1, '/>Chip': 1, 'interested.<br': 2, '/>Kal': 1, '/>L.L.Cool': 1, '/>Justin': 2, '/>Tender': 1, '/>xxx': 2, '/>Folks': 1, '/>3/': 1, '/>RIP': 1, '/>Carrie': 1, '/>Johnson': 1, '/>Butterflies': 1, '/>Creep': 3, '/>excellent': 1, \"s'est\": 1, '/>“The': 1, '‘': 7, '/>Stowe': 1, '/>Closing': 1, '/>Scatman': 1, '/>Shelley': 1, '/>*Me': 1, \"/>'How\": 1, '/>\"Tarzan': 1, '/>Showing': 1, '’S': 1, 'forget.<br': 1, \":'(\": 2, '/>Repeat': 1, 'shelf.<br': 1, '/>Across': 2, '’s': 7, 'cleverness.<br': 1, 'annoyed.<br': 2, '/>Mankiewicz': 1, '/>Scorsese': 1, '/>Superficially': 1, '/>Quincy': 1, '/>Wednesday': 1, '/>Bacall': 1, '/>Katina': 1, 'conclusion.<br': 6, '/>Maltin': 1, '/>\"Pickup': 1, '/>Audiard': 1, '/>Critique': 1, '/>Feverishly': 1, '/>Rose': 3, '/>Jo': 2, '/>Barely': 1, \"cont'd\": 1, '/>Miramax': 1, '/>Dad': 1, 'captured.<br': 1, '/>Faced': 1, '/>KEVIN': 2, '/>DOUG': 2, '/>Improvisation': 1, '/>Om': 1, '/>Indian': 1, 'ready.<br': 2, 'champions.<br': 1, '/>Maradona': 1, '/>England': 1, '/>Burruchaga': 1, '/>Vambo': 1, '/>\"Yes': 1, '/>Reda': 2, '/>\"Como': 1, '/>Conrad': 1, '/>Allan': 1, '/>Born': 1, 'divorce.<br': 1, '/>84/100': 1, 'state.<br': 1, '/>Antonio': 1, '/>Guerrilla': 1, '/>Soderbergh': 2, '/>(title': 1, '/>(another': 1, '/>(while': 1, '/>what': 4, '/>this': 1, '/>simply': 1, 'preview.<br': 2, '/>Leesville': 1, '/>Alastair': 1, '/>Delmer': 1, '--all': 1, '/>HYDE': 1, '/>Jeon': 1, '/>good': 2, '/>Lowpoint': 1, '/>Observation': 1, '/>Buddy': 2, 'dominating(and': 1, 'Gandalf(William': 1, 'characters(all': 1, '/>Biggest': 2, '/>General': 2, 'time(with': 1, '-King': 1, '/>-because': 1, '-Gollum': 1, '-Hobbits': 1, '/>Lord': 2, '/>Dance': 1, '/>movie': 4, '/>\"People': 1, '/>HEMO': 1, 'movies(North': 1, '/>Wyatt': 1, '/>Joel': 2, '.on': 1, 'expected.<br': 4, '/>Entertaining': 1, '/>Italians': 1, '/>Wildside': 1, '/>AAN': 1, '/>Konkana': 1, '/>Lost': 2, '/>Rightfully': 1, '/>Kolchak': 1, '/>Akane': 1, '/>Cuba': 4, '/>HUSBANDS': 1, '/>Ernie': 1, 'ones\\x97with': 1, '/>CONTENT': 1, '/>Claudia': 1, '--you': 1, '/>Trouble': 2, '/>Fassbinder': 1, '/>Livia': 1, '/>GALAXY': 1, '/>\"Angels': 1, 'it!!!!!<br': 1, '/>Recommendation': 1, '/>Parminder': 1, '/>Rimi': 1, 'way.<br': 1, 'relative.<br': 1, '/>Orphan': 1, 'robberies.<br': 1, '/>“Oliver': 1, '/>Foxx': 1, '/>Meeker': 1, '/>JEOPARDY': 1, '/>Cagney': 1, '/>Seduction': 1, 'rubbish.<br': 3, '/>Wally': 1, 'highlights.<br': 1, '/>\"Let': 1, '/>Loren': 1, '/>York': 2, '/>Forgiveness': 1, '/>Jaques': 1, '/>Lucifer': 1, 'repertoire?).There': 1, 'stage.<br': 1, '/>Theron': 1, 'wife(Cathrine': 1, '/>Randy': 1, 'Marie(Pauline': 1, '/>Floraine': 1, '/>Teenaged': 1, '/>\"Tenchu': 1, '/>Downbeat': 1, 'mother(Diane': 1, 'sons(Michael': 1, '/>Jackman': 1, '/>Definite': 1, '/>Raoul': 1, '/>Correctly': 1, '/>Europe': 1, '/>Nicholson': 1, '/>Irvine': 1, 'DOUBLED.Back': 1, '/>~Nancy': 1, 'spoilers?)<br': 1, '/>however': 2, 'sore.<br': 1, '/>Rupert': 3, 'policemen.<br': 1, '/>MAN': 3, 'don¡': 2, '§': 4, 'it,¡¨': 1, 'crazy¡¨': 1, '/>\"Fanny': 1, \"/>don't\": 7, '/>Rating:-': 2, 'correctly.)<br': 1, '/>Catch': 1, '/>Dear': 3, 'validated.<br': 1, '/>Sending': 1, '/>Hayward': 1, '/>(Tenchu': 1, 'soccer)-themed': 1, '/>Interesting': 5, 'antihero.<br': 1, '/>Hanzo': 1, \"/>'American\": 1, \"/>'An\": 1, '/>named': 1, '/>Lovitz': 1, '/>highly': 1, '/>Marlene': 2, 'themes)': 1, '---a': 1, '/>Support': 1, '/>Rating:7': 1, '/>Pabst': 1, '/>Viren': 1, '/>Behind': 2, '/>Jud': 1, '/>http://www.replaydvd.co.uk': 1, 'antagonist.<br': 2, '/>Contaminated': 1, '/>FDR': 1, 'monumental.<br': 1, ':3': 1, '/>Moment': 1, '/>*sigh': 2, '/>Doubtless': 1, '/>Stone': 1, '/>Barky': 1, '/>Calling': 1, 'Freeman.<br': 1, 'afterwards.<br': 3, '/>Angelopoulos': 1, '--<br': 1, '/>G': 2, '/>Opposing': 1, '/>\"This': 2, '/>-DirrTy': 1, 'curves.<br': 1, '/>Rory': 1, '/>Ella': 1, 'Koaho(Jay': 1, '/>edit': 2, 'walkers.<br': 1, '/>Griffith': 1, '/>Sister': 2, '/>Nunsploitation': 1, '/>Searching': 1, '/>Objectively': 1, '/>Subjectively': 1, '/>Curly': 1, '/>Tristan': 1, '/>Followed': 2, '/>Lindsey': 1, '/>Fever': 1, 'spree.<br': 2, 'Blake.<br': 1, '/>JOHN': 2, '/>Josephine': 1, '/>Moe': 2, '/>Mathieu': 2, '/>Furthermore': 5, '/>Inside': 2, 'against.<br': 1, '/>Anchoring': 1, 'laid.<br': 1, '/>-Thanks': 1, \"(I've\": 1, 'challenging.<br': 1, '/>like(For': 1, '/>may': 1, 'painted.<br': 1, 'movie.<br': 5, \"/>'Gung\": 1, 'in.\\\\<br': 1, '-Just': 1, '/>Overlooking': 1, 'death.<br': 2, '/>Cool': 2, '/>destruction': 1, '/>Underground': 1, '/>whether': 1, '/>sure': 2, '/-': 3, 'rolling.<br': 2, '/>Hollow': 3, '/>cue': 1, '/>\"Something': 1, '/>\"Justice': 1, '/>CHACHO': 1, 'McIntire(as': 1, 'herself(his': 1, '/>--The': 7, 'Blank.<br': 1, 'bang.<br': 1, 'out!This': 1, '................': 3, '/>1-': 2, '/>2-': 1, '/>3-': 3, '/>4-': 1, '/>5-': 1, '/>6-': 1, '/>7-': 1, '/>8-': 1, '/>Samurai': 1, '/>Ian': 3, 'factor.<br': 1, '/>Boy': 9, 'stubborn.<br': 1, 'novel.<br': 2, '/>Josie': 1, 'weapon.<br': 1, 'dream.<br': 1, '/>Everytown': 1, '/>Concerning': 1, 'slightly.<br': 1, '/>CB': 1, '/>Characterization': 1, '/>Gwizdo': 1, '/>Weird': 2, '/>Ned': 2, '/>Shame': 9, '/>Romance': 1, '/>Luke': 3, 'performance.<br': 1, 'sensational.<br': 1, 'with.<br': 5, 'blockbusters(Jumanji': 1, 'continues.<br': 2, 'Lis)': 1, '/>Baron': 1, 'instrumental.<br': 1, '/>\"Scarface': 1, '/>Solid': 1, '/>Someday': 3, 'repeated.<br': 1, '.the': 4, '.a': 1, '.sooo': 1, '/>Siodmak': 2, 'Raines.<br': 1, '/>Fact': 1, '/>Caprica': 2, '/>\"Fanfan': 1, '.Henri': 1, '.Antimilitarism': 1, '/>Christian': 2, '/>Remake': 1, 'contrast.<br': 1, '/>QUAIS': 1, '/>LES': 1, '/>TUILERIES': 1, '/>LOIN': 1, '/>PARC': 1, 'cry.<br': 1, '/>QUARTIER': 2, '/>FAUBOURG': 1, '/>Missi': 1, '/>Curtis': 1, '/>Glad': 3, '/>Fine': 2, '/>Hayworth': 1, '/>Everett': 1, '/>EXTREME': 1, '/>\"Happenstance': 2, '/>Call': 3, '/>October': 1, '/>***SPOILERS': 2, '/>Taken': 3, '/>\"Mask': 1, 'batgirl.<br': 1, '?<br': 5, 'can´t': 3, '/>Hillary': 1, '/>Paralelling': 1, '/>Comparisons': 1, '/>Neil': 5, 'Park)how': 1, '/>Eighteen': 1, '/>Quirky': 1, '/>Classic': 2, '/>Around': 2, '/>Beaver': 1, '/>Liz': 1, '/>\"Kriemhild': 1, 'earthbound.<br': 1, '/>Kriemhild': 1, '/>Cain': 1, '/>Ossessione': 1, '/>Were': 1, '/>Leo': 2, \"/>Carrère's(Gérald\": 1, '/>\"Spirit': 1, '/>Release': 1, '/>Adamson': 1, '/>Harel': 1, '/>GET': 1, '/>Paxton': 1, '/>JEAN': 1, '/>THELMA': 1, '/>Fourth': 2, '/>Fifth': 2, '/>Clytemnestra': 1, '/>girl': 2, '/>Notes': 2, '/>Real': 3, '/>Chaplin': 2, '/>Gypo': 2, '/>\"October': 1, '/>Reading': 2, 'stars(Connery': 1, '/>\"Walterman': 1, '/>Amusingly': 2, '.i': 1, '/>Nota': 1, '/>29th': 1, '/>Carey': 1, '/>Available': 1, 'XP.But': 1, '/>1.Billy': 1, '/>2.Billy': 1, '/>Nine': 1, '/>starring': 2, '/>Madhavi': 1, 'decently.<br': 1, '/>Cinderella': 1, '/>Virginia': 1, 'icon.<br': 1, '/>Swing': 1, '/>Haven': 1, '/>Elsewhere': 2, '/>Curious': 1, '/>S': 2, '/>-\"Rob': 1, '/>\"Rob': 1, ':)))': 2, '/>Bravo.<br': 1, 'betters.<br': 1, '/>Arletty': 1, 'important(and': 1, '/>Ewan': 1, '/>Human': 2, 'Regards.<br': 1, '/>Heston': 2, '/>Wisely': 1, '/>Into': 1, '/>Hugely': 1, '/>Bernhard': 1, '/>Bernhards': 1, '/>Zombies': 1, '01/30/07': 1, '/>--MB': 1, '/>Babaganoosh': 1, '-you': 1, '/>ACT': 2, 'song,(at': 1, '/>\"Fever': 1, '/>Shameful': 1, 'Center.<br': 1, '/>Code': 3, '-Juan': 1, '/>(*This': 1, '/>Peruvian': 1, 'precise.<br': 1, '/>Luna': 1, '/>\"Ha': 1, 'altogether.<br': 2, 'untrue.<br': 1, '/>Cliffhanger': 1, '/>Mention': 1, 'kicking.<br': 2, '/>Holds': 1, '-m': 1, '/>Water': 1, '/>Francine': 1, '/>Moronic': 1, '/>\"Wish': 1, '-The': 4, 'personages.<br': 1, 'back.<br': 1, 'F**K': 1, '/>Shirley': 3, '/>Quote': 1, '/>Vampire': 1, '/>\"Night': 1, '/>Trick': 2, '/>Figure': 1, '/>1/10': 34, '/>*******spoiler*****<br': 1, '/>why': 3, '/>Splatter': 1, '/>Military': 1, \"/>I'M\": 1, '/>SYMPATHY': 1, '/>Compare': 2, 'incarnation.<br': 1, 'adequate.<br': 1, 'engaging.<br': 2, '/>#3': 4, '/>Critics': 1, '/>Stigmata': 1, '/>Trojans': 1, '/>Trojan': 2, '/>Achilles': 1, '/>Greek': 3, '/>Troy': 1, 'means.<br': 1, '/>I´m': 1, '/>**spoiler**<br': 1, '/>Doubt': 2, '/>Newsflash': 1, '/>Hallmark': 1, 'co': 1, '/>WINTER': 1, 'second.<br': 1, '/>Continuity': 1, '/>Fair': 3, '/>spoilers': 2, 'grates.<br': 1, '/>rent': 1, 'Eidos.<br': 1, 'dunno.<br': 1, '/>Burr': 1, '/>(Singing': 1, '/>(TOM': 1, '/>HE': 3, '/>(JOEL': 1, '/>SOMEBODY': 1, '/>THAT': 1, 'Indonesia.<br': 1, '/>Debbie': 1, '/>Pyramid': 1, '/>BLAH': 1, '/>Greenlight': 1, 'explain.<br': 2, '/>Lousy': 2, '/>Delighted': 1, '/>Wesley': 1, '/>Solar': 2, ':o': 1, '/>Song': 1, '/>3/10': 43, 'whatsoever.<br': 9, '/>Steer': 6, 'fear.<br': 1, '/>\"Loaded': 1, 'underworld.<br': 1, '/>La': 4, '/>Roddy': 1, '/>Erm': 1, '/>Complete': 3, \"/>'Should\": 1, '/>Jude': 1, '/>Giovanni': 1, '/>Props': 1, 'incomprehensible.<br': 1, '/>Saw': 1, '/>Directors': 3, '/>Endless': 1, '/>Low': 6, '/>*Note': 1, '/>0/10': 9, '/>PLEASE': 2, '/>Tells': 1, '/>-plot': 1, '/>Condon': 1, \"/>'West\": 1, '/>Derivative': 1, '/>Alien': 1, '/>Fooey.<br': 1, '/>Native': 1, 'movements.<br': 1, 'script.<br': 1, '/>STAY': 2, 'concept.<br': 1, 'abounds(not': 1, 'INCLUDED*<br': 1, '/>Comment': 1, '/>Browsing': 1, 'anytime.<br': 1, '/>music': 1, '/>ASIN': 1, 'video(the': 1, '/>Cartoon': 1, 'rift.<br': 1, 'useless.<br': 2, '/>Disjointed': 1, 'time(and': 1, 'Sweden.<br': 1, '/>Seriously': 8, '/>Avoid': 65, \"/>Shouldn't\": 1, '/>Bah': 2, 'leads)-': 1, '/>Read': 3, \"/>Teal'c\": 1, 'conversion.<br': 1, '/>Explanations': 1, '/>PROTOCOL': 1, '/>Cohen': 1, 'role(the': 1, 'socks.<br': 1, '/>Wrong': 1, 'contacts?)<br': 1, 'enlightenment.<br': 1, 'weak.<br': 1, 'army.<br': 1, '3\"!<br': 1, '/>--Amazingly': 1, 'movie\\x97even': 1, '/>--Sounds': 1, '/>--Terrible': 1, '/>--Standard': 1, '/>--Nowhere': 1, '/>Memorable': 3, '/>Cheesiness': 2, '/>www': 1, '/>\"Weapons': 1, 'here.<br': 1, '-SAS': 1, '/>-Too': 1, '/>AVOID': 5, '/>Fifteen': 1, '/>Raffles': 1, '/>http://thevillagevideot.blogspot.com/': 1, '/>http://skeptico.blogs.com': 1, '/>Believe': 6, '/>Blah': 3, '/>-------------': 1, '/>\"How': 4, 'sob\".<br': 1, ',etc': 1, '/>\"Hubiriffic': 1, '/>Adrift': 1, 'bored.<br': 2, '/>avoid': 3, '/>Annie': 1, 'extremities(how': 1, \"did'nt\": 1, '/>Tons': 1, 'same.<br': 3, '/>Penguin': 2, 'episode)<br': 1, 'strength?)<br': 1, '/>Killer': 1, '/>Meteor': 2, '/>Wayno': 1, 'digress.)<br': 1, '/>poor': 1, '--à': 1, '/>2/10': 31, '/>Geisha': 1, '/>sick': 1, 'sweet.<br': 4, \"aren't\": 1, '/>Madonna': 3, '/>\"Swept': 1, '/>Seagal': 4, '/>Rutina': 1, '/>National': 3, 'sucked(I': 1, '/>Ask': 3, '/>Intriguing.<br': 1, '/>Book': 1, 'exploded.<br': 1, '/>\"G.I.': 1, '/>Fiona': 1, 'draft(and': 1, 'Feet.<br': 1, '/>Laura': 2, '/>Loony': 1, '/>Stick': 3, '/>Lighting': 1, '/>Alone': 4, '/>Responses': 1, '/>Yeah': 15, '/>Spike': 1, '/>Empty': 2, 'indeed.<br': 1, '/>\"Evangelion': 1, 'ambiance.<br': 1, '/>Che': 2, '/>Damaris': 1, '/>Oedipus': 1, '/>TWO': 1, '/>Schneebaum': 1, 'cares?)<br': 1, '/>Schya': 1, '/>Um.<br': 1, 'nonsense?)<br': 1, '/>Aspect': 12, '/>Reverent': 1, '/>Rooney': 2, '/>Psychic': 1, '/>mask': 1, '/>stud': 1, '/>because': 2, '/>before': 2, '/>Fulci': 2, '/>smoke': 1, '/>crave': 1, '/>spent': 1, '/>wounds': 1, '/>job': 1, '/>Swayzee': 1, 'spawn.<br': 1, 'Halloween.<br': 2, '/>NATIVE': 1, '/>Clichés': 1, '/>Wicker': 1, '/>-person': 2, '/>-sound': 1, '/>-cut': 1, 'inconsistent.<br': 2, '/>Problem': 3, '/>Husband': 1, '/>Vidhu': 1, '/>Bollywood': 1, '/>disturbed': 1, '-(the': 1, 'on!),and': 1, '-oh': 1, '..............................................': 1, '/>Fernando': 1, '/>4/10': 60, '/>Judges': 1, 'spent.<br': 2, '/>FLIGHT': 1, '/>Words': 2, '/>Driving': 1, '/>Munchies': 2, '/>Lion': 2, '/>Want': 4, '/>(x': 4, '/materials': 1, '/moon': 1, '/poet/': 1, '/grand': 1, '/>Sunshine': 2, '/>Thing': 2, '/>*/': 2, 'fashion.<br': 1, '/>Dean': 4, '/>(WHAT': 1, '/>SPOILER:<br': 1, '/>BRIEF': 1, 'remake.<br': 2, '/>Routh': 1, '/>Reeve': 1, '/>Singer': 2, '-0-': 1, '/>Mira': 3, '/>Jillian': 1, '/>SIDE': 2, '/>K.': 1, '/>then': 2, '/>Superwonderscope': 1, '/>Hybrid': 1, 'awful.<br': 1, 'developments.<br': 1, '/>Same': 1, '/>Assuming': 1, '/>Exodus': 1, 'outing.<br': 1, '/>Genuinely': 1, '/>incoherrent': 1, '/>issues': 1, '/>past': 1, '/>raunchy': 1, '/>yourself': 1, '/>superior': 1, '/>Cabin': 1, '/>ZERO': 1, '/>Pasolini': 1, 'Stensgaard),the': 1, 'sh*#t': 1, 'allow.<br': 1, 'this!So': 1, '/>Munchie': 2, '/>\"First': 1, '/>Terminator': 1, ':p': 1, 'debacle.<br': 2, '/>Small': 1, 'well\\x97known': 1, 'denier': 1, '/>Croatians': 1, '/>Zoe': 1, '/>THe': 1, '/>Stale': 2, '2005).<br': 1, '/>Audience': 1, '/>Hugh': 5, 'flat.<br': 1, 'Asian.<br': 2, '/>Holden': 1, 'sexy.<br': 1, '/>Ugh': 6, '/>\"Steve': 1, '/>\"ARggh': 1, '/>also': 1, '/>Worst': 8, '/>Megatron': 1, 'crocodile.<br': 2, '/>Matthew': 2, 'squibs.<br': 1, 'wrote.<br': 1, \"/>'Well\": 1, \"/>'We\": 1, 'adds.<br': 1, \"/>'But\": 1, \"/>'Then\": 1, \"/>'Puuurfect\": 1, '3/4th': 1, '/>lets': 2, '/>thirdly': 1, '/>Loyal': 1, '.There': 1, 'Morty(Jon': 1, '.5': 2, '\")--the': 1, 'choirs.<br': 1, 'vacuum.<br': 1, '/>Cult': 2, '/>**Spoiler': 1, '/>Amalric': 1, 'cameo.<br': 1, '/>STUPID': 1, '/>Affleck': 2, 'worthwhile.<br': 4, '/>Russel': 1, '/>Tyrannosaurus': 2, 'prior.<br': 1, '/>Rudolf': 1, '/>Remakes': 1, 'Harris.<br': 1, 'racist(for': 1, 'activities(upon': 1, '/>Sigh': 2, '/>Absolute': 1, '/>\"Deathrow': 1, '...............': 1, '..................': 2, '/>Hedeen': 1, '/>PIERRE': 1, '/>SCRATCHER': 1, '/>Parinda': 2, '/>Anil': 6, '/>\"Inspector': 2, '/>Gadget': 2, '/>Claw': 1, 'thinking???<br': 1, 'pathetic.<br': 6, '/>\"Gregory': 1, 'embarrassing.<br': 4, '/>Nacho': 2, '/>Gwen': 1, 'woods.<br': 1, '/>HEDY': 1, '/>Alexander': 3, '-Mike': 1, '/>Late': 1, '/>{Grade': 1, '/>Gorgeous': 1, '/>Employed': 1, '/>Franco': 1, 'eyeballs.<br': 1, '/>\"X': 1, '/>Idiotically': 1, '/>Really?<br': 1, '/>Cyclops': 1, '/>Boring': 3, '/>Creating': 1, '/>Supporting': 1, '/>Hunky': 2, '/>Blood': 3, '/>Maka': 1, '/>Canned': 1, '/>Might': 3, '/>Cara': 1, '/>Checkout': 1, '/>ALWAYS': 1, 'Rambo.<br': 1, 'failure.<br': 1, 'obvious.<br': 5, 'aspects.<br': 1, '/>Sleazy': 1, '/>Save': 16, '/>P.S': 4, 'cycle.<br': 2, \"/>Wouldn't\": 3, '/>Keira': 1, '/>Help': 2, '/>Prof': 1, '/>Tips': 1, '/>\"Surviving': 1, '/>Painful': 1, 'elements(for': 1, '/>Events': 1, '/>Watcheable': 1, '/>Guess': 3, '/>TECHNICAL': 1, '/>Signing': 1, 'Republican=': 1, '/>Heads': 1, 'imitating.<br': 1, '/>Flay': 1, '\"Joe': 1, '/>Neha': 1, 'easily.<br': 1, '\\x95': 3, '-----ok': 1, '/>\"Alive': 1, '/>SOCIAL': 1, '/>MORAL': 1, '/>*SPOILERS': 3, '/>Ladies': 1, '/>Niamh': 1, '/>Uwe': 3, 'reviewers.<br': 1, '/>Plot-': 1, '/>Characters-': 1, '/>1.5/10': 2, '/>MYRA': 1, 'Genius.<br': 1, 'slaughtered.<br': 1, '/>\"Final': 1, '/>\"On': 1, '/>Episodes': 1, '/>Wes': 1, '/>Utter': 4, '/>Lately': 1, '/>Gina': 1, '/>Trifling': 1, '/>Exterminators': 1, '/>Seem': 1, '/>Gray': 1, '/>Sellers': 2, '/>Strange': 1, '/>Saban': 1, '/>Coherence.<br': 1, '/>whats': 1, '/>FART': 1, 'drowns.<br': 1, '/>Hello': 1, '/>Subtle': 1, '/>Flo': 1, '/>JJ': 1, '/>Grandpa': 2, '/>Stevie': 1, 'adult.<br': 1, '/>Danielle': 1, '\"they\\'re': 1, '/>Your': 4, '/>Dress': 1, '/>Unless.<br': 1, '/>**MAY': 1, '/>Retromedia': 1, '/>Hands': 1, '/>\"Cyborg': 1, '/>Gentlemen': 1, 'porno.<br': 1, 'company.<br': 3, '/>Wills': 1, '/>RIPLEY': 1, 'soulless.<br': 1, 'slow.<br': 3, '/>\"Magnolia': 1, '0': 10, '/>Assorted': 1, 'race.<br': 2, '/>Jonathon': 1, '/>SPOILERS--': 1, '/>Lon': 1, '/>Turhan': 1, '/>Elyse': 1, \"/>How'd\": 1, 'faster.<br': 1, 'zone.<br': 1, '/>Rental': 2, 'amused.<br': 2, '/>***3': 1, 'A.T.u': 1, '/>LL': 2, '/>Annik': 1, '/>Dressler': 1, '/>Reeves': 1, '--or': 1, '/>Lever': 1, '/>*******SPOILERS': 1, '/>Deneuve': 1, '/>(Or': 1, '/>Lynda': 1, '/>Rona': 1, 'puke.<br': 1, '/>Deathstalker': 2, 'especially.<br': 1, '/>Avoiding': 1, '/>+s': 3, '/>total': 1, '/>Caan': 1, '!.<br': 1, '/>Count': 2, \"/>There'a\": 1, '/>Cheetor-': 1, \"dosen't\": 2, 'chase)<br': 1, '/>Turning': 1, '/>Salvage': 1, '/>(Then': 1, 'surgery.<br': 1, 'insulting.<br': 4, '.See': 2, '/>Spinal': 1, '/>Possibly': 3, '/>Disappearance': 2, '/>Kali': 1, '0/1,000': 1, '/>Logan': 1, 'reporter(Racheal': 1, 'escort(Patrick': 1, 'flow.<br': 2, '/>Massacre': 2, 'Time).<br': 1, 'void.<br': 1, '/>\"Hey': 1, '/>Neo': 2, 'reminder.<br': 1, '/>Matrix': 1, '/>Undeniably.<br': 1, '/>Aggravating': 1, '/>Ye': 1, '/>how': 3, '/>enjoying': 1, '/>Easter': 1, '/>The\"film': 1, \".They'll\": 1, '/>Morteval': 1, '/>ZZZZZZZZzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz': 1, '/>Ooops': 1, 'imitation.<br': 1, '/>Plagiarism': 1, 'action(ish': 1, 'birds?)<br': 1, 'Higginson(Slaughterhouse)and': 1, '/>Quinn': 1, '/>ACS': 1, 'tried(the': 1, '/>\"Sympathy': 1, \"/>'Bought\": 1, '/>Damn': 2, '/>BURN': 1, '/>Awful': 14, '/>Bleek': 1, '/>Comparing': 2, '/>\"To': 1, '/>Edel': 1, '-again-': 1, '/>Chloe': 1, 'things.<br': 1, '/>Tension': 1, '/>Moral': 2, 'quality.<br': 1, '/>Falling': 1, '/>Horrible': 3, 'actor(George': 1, '/>Piper': 1, '/>Region': 1, 'penance.<br': 1, '\")<br': 5, 'soon\",or': 1, '/>Side': 5, '/>Kareena': 4, '/>Spawned': 1, '/>OBVIOUS': 1, '0/5.0': 1, '/>Tong': 1, '/>Detention': 1, 'nothing.<br': 1, '/>***<br': 1, '/>Filmgoers': 1, '/>#2': 3, 'incursions.<br': 1, '/>#4': 1, '/>#5': 1, '/>Cory': 1, 'horror.<br': 1, '/>Suspension': 2, '/>Omen': 2, 'etc.<br': 1, '/>-Z': 2, 'ashamed.<br': 2, 'wife(Peggy': 1, '................................': 1, 'consumed.<br': 1, '/>Thunderbirds': 1, 'centuries.<br': 1, '/>Theaters': 1, '/>Ooh': 1, '/>Catherine': 2, '/>Heres': 4, '/>\"User': 1, '/>\"Voyna': 1, 'then.<br': 1, '/>they': 3, '/>Spare': 4, 'scars.<br': 1, 'have.<br': 1, '/>\"Watching': 1, '/>BloodyMonday': 1, '/>**SPOILER**<br': 1, '/>Harvey': 2, '/>Charis': 1, '/>Zenia': 1, 'everyday.<br': 1, '/>Pfieffer': 1, '/>Plain': 2, \"/>'Tashan\": 1, '--after': 1, '--I': 1, 'faces.<br': 1, '/>Girl': 1, '/>Bonesetter': 1, '/>Expressed': 1, '/>\"Disappearance': 1, '/>okay': 1, '/>Bland': 1, '/>Calvin-': 1, '/>Scrappy': 1, '/>Cheap': 4, '/>Songs': 1, '/>\"Ned': 1, 'thrilling.<br': 1, '/>Cleopatra': 2, '/>Stiller': 3, '/>Snipes': 2, '/>a': 4, 'ground)<br': 1, 'Hmm.<br': 2, '/>Saif': 3, '/>Madea': 1, '/>Heeey': 1, '/>NO': 1, '/>Enlightenment': 1, '/>Jürgen': 1, '/>Hitler': 2, 'hours.<br': 1, '/>Melodrama': 1, 'died.<br': 2, '/>Lewton': 1, '/>\"Dragon': 1, '/>Pavarotti': 1, '/>Started': 1, \"/>'so\": 1, \"/>'i'm\": 1, \"/>'but\": 1, '/>Yuk': 1, '/>Valentine': 4, '/>Cube': 1, '/>Edge': 2, '/>Taji': 1, '/>Immunity': 1, '/>Hardy': 1, '/>\"New': 1, '/>Fist': 1, 'breakdown.<br': 2, \"/>'One\": 1, '-----': 1, '/>1940s': 1, '/>1960s': 1, '/>Applause': 1, '/>no': 3, '/>Moore': 1, 'apathy.<br': 1, 'explosions.<br': 1, '/>\"Modern': 1, '/>Sammy': 1, '/>Sohail': 2, '/>Priyanka': 3, 'overlooked.<br': 2, '/>DarkWolf': 1, '/>\"Coming': 1, '/>Dee': 1, '/>Deep': 1, 'fixing.<br': 1, \"/>'So\": 1, '/>pesci': 2, 'forgettable.<br': 2, '/>anyone': 2, '/>stay': 2, '/>Scrubs': 1, 'corn.<br': 1, '/>*spoiler': 2, 'direction.<br': 3, 'Arrrrgh.<br': 1, 'enlighten.<br': 1, '/>Word': 1, '/>\"Casanova': 1, '/>Casanova': 1, '/>Funky': 1, 'segments.<br': 2, '/>-When': 1, '-Your': 1, '-=contains': 1, '/>Beverly': 1, '/>Irritation': 1, '/>Berlin': 1, 'theater.<br': 1, '/>\"Logan': 1, '/>Surprise': 3, '/>Oh-': 1, 'emerged.<br': 1, '/>(On': 4, '/>\"Giù': 1, 'something.<br': 2, '/>(1': 2, '/>(2': 2, '/>(3': 2, '/>(4': 1, '/>(***SPOILER': 1, '/>Marky': 1, 'Film\"<br': 1, '/>Mansfield': 1, 'That´s': 1, '/>Seagall': 1, '/>Fitz': 1, '/>Ebert': 1, 'either}).<br': 1, '/>Writing': 2, '/>Wolfe': 2, '/>Sherman': 2, '/>Chase': 1, '/>vote': 1, 'abysmal.<br': 2, '/>Listening': 1, '/>Courtney': 1, '/>Karen': 2, '/>Nicholas': 6, '/>Leelee': 1, 'resemblance.<br': 1, '/>Wentworth': 1, '/>Elvis': 1, '/>on': 3, 'film(not': 1, 'explanation.<br': 1, 'release.<br': 2, '/>Orlando': 1, '/>Lasse': 1, '/>Dig': 1, '/>Hmmm': 1, 'incoherent.<br': 2, '/>Maggie': 1, '/>Biehn': 1, '/>MST3': 2, '/>Benfer': 1, 'embarrassment.<br': 1, \"didn't.it\": 1, '/>Positives': 2, '/>Barsi': 1, '/>Half': 5, '/>Pick': 2, '(stay': 1, 'salesman(Robert': 1, 'slugger(Wesley': 1, '/>Yech': 1, 'designer.<br': 1, '/>--jimbo': 1, 'girl(who': 1, '/>rating:0.3': 1, '/>4.3': 1, '/>Negatives': 1, 'Khan-(Whoever': 1, '/>Doctor': 1, '/>Sitting': 2, '/>Hear': 1, '/>*************SPOILER': 1, '/>tl;dr': 1, 'disorder.<br': 2, \"/>'Flushed\": 1, 'recently)<br': 1, '/>4.5': 1, 'Awesome.<br': 1, 'offer.<br': 5, '/>Plucked': 1, 'seppuka)': 1, '/>Inserting': 1, '/>Fat': 2, '/>\"Thinner': 2, '/>Illiterate': 1, 'aside.<br': 1, '/>Successful': 1, '/>\"Ringmaster': 1, '/>VIOLENCE': 4, '/>STORY': 4, '/>Sci': 1, 'spice.<br': 1, '.there': 1, '.Above': 1, '/>Robotech': 1, 'dire.i': 1, 'granddaughter.<br': 1, '/>Bronson': 3, '/>\"In': 1, \"/>WE'RE\": 1, '/>Storyline': 3, '/>LM': 1, '/>Japanese': 5, 'individuals.<br': 2, '/>#1': 2, 'coming.<br': 1, '/>Altered': 1, '/>Professional': 2, '/>Guard': 1, '/>Editor': 1, '/>WAIT': 1, '/>\"Dead': 2, 'setting?(this': 1, '/>fade': 1, '/>WARNNING': 1, '/>(Black': 2, '/>Argh.<br': 1, 'stability.<br': 1, '/>Stupid': 9, '/>Replacing': 1, '/>Shalom': 1, '/>Operator': 1, '/>Haha': 1, '/>####Major': 1, '/>Aya': 1, '/>of': 4, 'Hello!<br': 1, '-infinity/10': 1, '/>Pitch': 1, 'draw.<br': 1, '/>Beyonce': 2, '/>LAME': 1, '/>Aniston': 1, '/>Screenplay': 2, '/>Jesus': 3, 'similarities-': 1, '/>*Due': 1, '/>*Saruman': 1, '/>*Sam': 1, '/>*Despite': 1, '/>*Some': 1, '/>*As': 1, '/>Robi': 1, '/>\"Robot': 1, '--as': 1, '/>Darryl': 1, '/>\"Wow': 1, '/>\"I\\'ve': 1, '/>\"Uh': 1, '/>\"Is': 3, '/>\"UGH.\"<br': 1, '/>(If': 1, 'announcements.<br': 1, '/>Vidor': 1, '/>A.': 3, '/>(Movie': 2, '/>Sheesh.<br': 1, '/>Christmas': 2, '/>Simple': 1, '/>Lou': 1, '/>3.the': 1, '/>\"Superchick': 1, 'superficiality.<br': 1, '/>Practically': 1, 'US-/Japanese': 1, '/>Effective': 1, '/>Nesbitt': 1, '/>Entire': 1, '/>loved': 1, '(So': 1, '/>\"Cabin': 2, '/>Bert': 2, '/>Deputy': 1, '/>Dina': 1, '/>waitress': 1, '/>photog': 1, '/>through': 2, '/>scene': 1, '/>ride': 1, '/>story': 2, '/>suspense': 1, '/>Estes': 1, '/>Pauly': 1, '/>out': 1, '/>Celebrity': 1, '/>recommend': 1, '/>sexual': 1, 'handbook.<br': 1, '/>Barney': 1, '-she': 2, '/>Ninety': 1, '/>Boston': 1, '/>Flocker': 1, '/>Banks': 1, '/>Ghost': 1, '/>Wlaschiha': 1, '/>characters': 1, '/>put': 1, 'legally.<br': 1, 'respectively.<br': 2, 'cleaned.<br': 1, 'costuming.<br': 1, 'inspector-\"Can': 1, '/>Goofs': 1, 'about),': 1, '/>Burn': 1, '/>Grotesquely': 1, '/>Replaces': 1, 'interminable.<br': 2, '/>Rating:2': 1, '/>Additional': 1, 'off.<br': 1, '/>Needing': 1, '/>Hepburn': 1, '/>Images': 1, '/>Wanna': 3, '/>Im': 4, '--written': 1, '/>PAT': 1, '/>RAIN': 1, '/>UMA': 1, '/>Starr': 1, '/>up).<br': 1, '/>spends': 1, '/>Tongue': 1, '/>background': 1, '/>vampire': 1, '/>Nifty': 1, '/>\"Martin': 1, '/>Picture': 2, '/>LIBERAL': 1, '/>Example': 4, '.......................................': 1, '......................................................': 1, '/>Role': 1, '........................': 1, '/>Character': 2, '.this': 1, '/Rick': 1, 'asleep.<br': 4, '/>tasteless': 1, '/>only': 1, '/>Bo': 2, '/>\"Valentine': 2, '/>Blondie': 1, 'effects(the': 2, '/>Brinke': 1, '/>\"Spring': 1, '/>Marshall': 1, '/>Zeta': 2, '/>Roberts': 1, 'forgivable.<br': 1, '/>3.2/10': 1, '/>Night': 1, '/>Ajay': 3, '/>Dolph': 3, 'existed(and': 1, 'cook(you': 1, '/>Beowulf': 1, '/>\"ZOMBI': 1, '/>Male': 1, 'b*****ds': 1, '/>\"Kissing': 1, '/>Yoon': 1, '/>{This': 1, '/>Revolver': 3, 'exists.<br': 1, '/>2)He': 1, '/>3.5/10': 1, '/>{SPOILER}<br': 1, '/>Gail': 1, \"/>We'll\": 2, '/>Bear': 1, '/>0': 6, '/>-Let': 1, '/>Romeo': 1, '/>Umney': 1, '/>Crouch': 1, 'Manichaean.<br': 1, '/>TIM': 1, '/>Amazingly': 1, '/>Serum': 1, '/>Combs': 1, '/>based': 1, \"/>didn't\": 2, '/>Skullduggery': 1, '/>take': 3, '/>expect': 1, '/>Leaving': 1, '/>Ruining': 1, '/>Newbern': 1, 'completely.<br': 2, '/>Led': 1, '/>Bottomline': 3, 'place.<br': 2, '/>BEST': 1, '/>Gore': 3, 'satire.<br': 1, 'babies.<br': 1, 'dentistry.<br': 1, '/>Ahem': 1, 'story-': 1, 'Exactly.<br': 1, '/>Rambo': 3, 'personnel.<br': 1, '/>(Major': 1, '/>Realistic': 1, ',rather': 1, '/>Tori': 1, '/>PROBLEM': 1, ',or': 1, '/>SUPERMAN': 3, '/>\"Serum': 1, '/>Photowise': 1, '/>Melina': 1, '/>ECW': 1, 'away)': 1, 'explored.<br': 2, '/>Parabens': 1, 'condition.<br': 1, '/>Iliad': 1, '/>Oprah': 3, '/>DEATHSTALKER': 1, 'emergency.<br': 1, 'boy.<br': 1, '...................': 2, '/>Quickly': 2, '/>Wall': 1, '/>EVEN': 1, '/>GOOD': 3, '/>Jims': 1, '/>IMO': 1, \"/>'Two\": 1, '/>Use': 2, '/>Léo': 3, '/>Il': 1, '/>Severely': 1, 'arguments.<br': 1, '/>Gag': 1, '/>Unrated': 1, '/>Freaked': 1, '/>Obscure': 1, \"/>They're\": 1, '/>Fantastic': 2, 'apparently.<br': 1, 'advertisements.<br': 1, 'authentic.<br': 1, '\"can': 1, '/>Approach': 1, '/>\"Shoot': 1, '/>-Anonymous': 1, 'glass.<br': 1, '/>17-year': 1, '/>Larsen': 1, '/>-adam': 1, 'bickering.<br': 2, '/>I’m': 1, 'Nobody.<br': 1, '/>Afterwards': 1, '/>DH': 1, 'perspective.<br': 1, '.50': 1, '/>Him': 1, '/>Her-': 1, '-\"I': 1, '/>(Not': 1, '/>VERY': 1, '~80': 1, \"/>'Land\": 1, '/>Brett': 1, 'genuine.<br': 1, 'predictability.<br': 1, 'Steel.<br': 1, '/>Lommel': 2, 'ride.<br': 2, 'looking.<br': 1, '/>Bachelor': 1, 'showing.<br': 1, '/>Epic': 1, '/>Part2': 1, '/>Austin': 1, '/>Bigelow': 1, 'extremes.<br': 1, '/>Begin': 1, '/>Emraan': 2, 'movies)<br': 1, 'EVER!</3': 1, 'end).The': 1, '/>SUSAN': 1, '/>Greenaway': 5, '/>Nikkhil': 1, '.please': 1, '/>Barrymore': 1, 'dizzy.<br': 1, '/>\"Hellborn': 2, '/>Greydon': 1, '/>Abbu': 1, '/>\"Its': 1, '/>Mask': 1, '/>Subzero': 1, '/>Crystal': 1, '/>SPONTANEOUS': 1, '/>including': 1, '/>quick': 1, 'offerings.<br': 1, '/>Boll': 4, '/>Churchill': 1, 'poor.<br': 2, '/>Nazi': 1, '/>Sin': 1, '/>Koyla': 1, '/>Jhoom': 1, \"Jane?'<br\": 1, '/>Ferguson': 1, '/>Tashan': 2, '/>Cheoreography': 1, '/>Revealing': 1, '/>Mulan': 2, '/>Forced': 1, '/>Pay': 1, '/>Metamorphosis': 2, '/>YOu': 1, '/>Absurd': 1, '/>Summersisle': 1, '/>Crucial': 1, '/>Heather': 3, '/>Magnesium': 1, 'Brennan.<br': 1, '/>\"Up': 1, '/>{in': 1, '/>\"Then': 1, '/>\"Because': 1, '/>\"When?\"<br': 1, '/>\"There\\'ll': 1, '/>SOLDIER': 1, '/>Realizing': 2, '.among': 1, '.he': 1, '/>Oy.<br': 1, '/>Unrestrained': 1, '/>\"Savage': 1, '/>Believed': 1, '/>Wright': 1, 'crazy.<br': 1, '/>Screwball': 1, '/>Safe': 1, '/>Hai': 1, '0/10': 2, '/>ahhh': 1, '/>Amidst': 5, '/>\\x95': 7, '/>Case': 1, 'easy!It': 1, '/>Cruel': 1, '/>Rome': 1, '/>Raquel': 2, \"/>-I'm\": 1, '/>-Even': 1, '/>-High': 1, '/>-Note': 1, '/>-Dear': 1, '/>-Okay': 1, '/>Isabelle': 2, 'generated.<br': 1, '/>\"Kinjite': 1, '/>Harris': 2, '-=': 1, '/>MMPR': 1, '.Apparently': 1, '/>Bullock': 1, '/>\"Murder': 2, '/>*If': 1, '/>Action': 3, '/>slow': 1, '/>Moss': 1, '/>Hugo': 1, '/>Thought': 2, '/>KOKO': 1, 'smoothly.<br': 1, '/>Bell': 1, '/>Crash': 1, '/>(Later': 1, '/>Basket': 4, '/>Tree': 2, '/>(In': 2, '/>Sensually': 1, '/>Willow': 1, '/>(At': 3, '/>(Back': 1, '/>Innocent': 1, '/>Repeated': 1, '/>Credits': 1, \"/>Couldn't\": 2, '/>CHECK': 1, '/>WET': 1, '/>GAPE': 1, 'you.<br': 1, '/>P.S.S.': 1, 'forget!<br': 1, '/>Hanks': 1, '/>Burgundy': 1, '/>RstJ': 1, '/>Rubin': 1, '/>Jens': 1, '/>Ali': 1, '/>Scientists': 1, 'chase.<br': 1, 'lost.<br': 2, '/>Basic': 3, '/>Babban:-': 1, '/>Narsimha:-': 1, '/>Durga:-': 1, '/>RAMGOPALVARMA:-': 1, 'Kusturica.<br': 1, '/>\"Attack': 3, \"/>Snitch'd\": 1, '/>Keith': 1, \"shanghai'd\": 1, '/>Lewis': 1, '/>Pam': 3, '¨10.000': 1, 'voices(and': 1, '/>Overwrought': 1, 'You!\"<br': 1, '/>O.K.': 1, '/>first': 2, '/>another': 1, '/>Conquest': 1, '/>\"Blood': 1, '/>Originality': 1, '/>Tian': 2, '/>BOGART': 1, '/>CAGNEY': 1, '/>Rich': 3, '/>Terrible': 5, '/>\"K-911': 1, '/>B.': 1, '/>C.': 1, '/>Filmmakers': 1, '/>\"Tashan': 1, 'nightclub.<br': 1, '/>\"Basic': 2, '/>---Spoiler': 1, 'later!<br': 1, '/>Bassenger': 1, '/>\"Escape': 1, '/>Dorie': 1, '/>\"Private': 1, '/>wrecked': 1, '-\\\\': 1, '/>MANN': 1, '/>Carl': 1, '/>5/10': 3, '/>Jorge': 1, 'angst-\"comment': 1, '/>Panaghoy': 1, '/>quite': 1, '/>Incidents': 1, 'incessantly.<br': 1, 'absurd.<br': 1, '/>WT': 1, 'arch.<br': 1, '-Great': 2, '/>TRIVIA': 2, '/>Gandolfini': 2, '/>\"Guerrilla': 1, '/>1.Story': 1, '/>POSSIBLE': 1, '/>Cabanne': 1, '/>HOLY': 1, '/>\"step': 1, '/>SP': 1, '/>Rudolph': 1, '/>Ha': 1, '/>Journalist': 1, '/>Objectionable': 1, 'revolting.<br': 2, '/>FORGET': 1, '/>Lame': 1, '/>Situation': 1, 'cinematography.<br': 1, '/>HOWEVER': 1, '/>Caulfield': 1, '/>Nevermind': 2, '/>Toss': 2, '/>Sexual': 2, '/>please': 3, 'create.<br': 2, 'broken.<br': 1, '/>\"Growing': 1, '/>\"Success': 1, '/>\"Municipalians': 1, '/>Hero': 1, '/>ejames6342': 1, 'problem.<br': 1, 'collection.<br': 2, 'b***h': 1, 'occurred.<br': 1, '/>Idk': 1, '/>otherwise': 1, 'false.<br': 1, '/>Utterly': 1, 'retaliate.<br': 1, '/>Carmichael': 1, '/>Interminable': 1, '/>Boris': 2, '/>more': 1, '/>(there': 1, '/>deals': 1, 'garbage.<br': 1, '/>Lemme': 1, '/>Obsessed': 1, 'unpalatable.<br': 1, '/>\"4': 1, '/>Satan': 1, '/>Nope': 3, '/>Naturally': 3, '/>Vivek': 1, '/>Gilbert': 1, '/>Ramsey': 1, 'endured.<br': 1, '/>Sexo': 2, '/>Below': 1, '/>Down': 2, 'whole-(he': 1, 'it)-was': 1, '.........................................................': 1, '/>Car': 1, '/>***Spoilers': 1, '/>Watling': 1, '/>Parallel': 1, '/>HOWEVER.<br': 1, 'favourite.<br': 1, '/>Atwill': 1, '/>Balanchine': 2, '/>Reviewing': 1, '/>Repressed': 1, '/>Repulsed': 1, 'less?)<br': 1, '/>Forty': 2, '/>Development': 1, '/>Elite': 1, '/>Yeesh': 1, '/>Canada': 1, 'director.<br': 3, 'funnier.<br': 1, '--Frank': 1, '/>Trancers': 2, 'muck.<br': 1, '/>Revolt': 1, '/>Festival': 1, 'creative.<br': 1, '/>Sheehan': 1, '/>(Seen': 1, '/>Dull': 1, 'car(s': 1, 'moans.<br': 1, '/>Pass': 1, ')that': 1, 'rewrite.<br': 1, '/>Recycles': 1, '/>Marmorstein': 1, '/>\"Gas': 1, '/>Air': 2, '/>Morley': 1, 'points.<br': 2, '/>Abominable': 1, '/>Dragon': 1, '/>Rapa': 1, '/>Subject': 1, 'girlfriend.<br': 2, '/>Ioana': 1, '/>Tudor': 1, '/>Substantively': 1, '/>Hers': 1, 'walk!(If': 1, '/>Terrorist': 1, '/>Spoiled': 1, 'said\"they': 1, 'adaptation.<br': 4, '/>Noel': 2, 'range.<br': 1, '/>Gerald': 1, '/>Gothic': 1, '/>Dubbing': 3, 'bond.<br': 1, '/>Mutch': 1, '/>Burton': 1, 'teenager.<br': 1, 'talents.<br': 1, '/>Chicago': 1, 'care?)<br': 1, '/>Barry': 1, '/>Unusual': 5, 'assumption.<br': 1, '/>Corey': 1, '/>Student': 1, '/>Agreeing': 1, '/>Martial': 1, '/>Mind': 3, '/>Fault': 1, '!!!<br': 1, '/>Outside': 2, '/>where': 1, '/>Guitar': 1, 'again)--although': 1, 'venues.<br': 1, 'secret.<br': 1, 'moments(but': 1, '.Historically,\"les': 1, '/>Than': 2, '/>skip': 1, '/>Tea': 1, '/>Attack': 2, '/>Lucky': 2, '/>Lil': 1, '/>Google': 1, '/>Allegories': 1, 'adventure.<br': 1, '/>Maud': 1, '/>Forever': 1, '/>Bem': 1, '/>Brazil': 1, '/>Design': 1, '/>Geez': 1, '/>Lysette': 1, 'antics.<br': 2, '/>Spain': 1, \".don't\": 1, '/>Askey': 1, '/>Aryeman': 1, '/>Bhumika': 1, '-J.Leonard': 1, '\"Didn\\'t': 1, 'YOU!!!!!So': 1, '/>Gert': 1, '/>Dhol': 1, '/>(An': 1, 'bases.<br': 1, '/>Turiqistan': 1, '/>Nary': 1, '/>Cue': 1, 'fetched.<br': 1, '/>Forgettable': 1, 'others.<br': 1, '/>\"Find': 1, '/>(Zero': 1, '/>Award': 1, '/>Garcia': 1, '/>Reminded': 1, '/>Lungren': 1, \"film'o\": 1, '/>Sajani': 1, '/>Tulsa': 1, 'heading.<br': 1, '/>\"you': 1, '/>Spacey': 3, '/>Faye': 1, 'immensely.<br': 2, '/>Hostage': 1, '/>Thief': 1, '/>Scrip': 1, '/>Directing': 3, 'five.<br': 1, \"/>'Just\": 1, '/>-SPOILERS': 1, '/>Putting': 2, '/>pros': 1, '/>costs': 1, '/>make': 1, '^_^=)<br': 1, \"ain't!<br\": 1, 'reject.<br': 2, '/>Embarrassly': 1, '/>Excessive': 1, '?!<br': 1, '/>(SPOILERS': 1, '/>Rider': 1, '/>**SPOILER': 1, '/>**/5': 1, '/>B': 2, '/>DARK': 1, '/>Rodney': 1, '/>*****<br': 1, '/>Totally': 2, '/>Buried': 1, '/>`Black': 1, '/>Chandler': 1, '/>Crazy': 1, '/>Amateur': 1, '/>Nada': 1, '®': 2, \"D'oh\": 1, '/>\"Back': 2, '/>Pranks': 1, '/>Demi': 1, 'fiction.<br': 1, '/>Tsai': 1, '.Lets': 1, '/>Live': 1, '/>Jeez': 2, 'what?there': 1, '/>Talentless': 1, '/>Garrett': 1, 'survival.<br': 1, '0.1/10': 1, 'artifacts.<br': 1, 'species.<br': 1, 'ridden.<br': 1, '/>Cost': 1, '/>Mmmmm': 1, '/>Admirable': 1, 'three.<br': 1, '/>Grendel': 2, '/>Bmoviefreak': 1, 'catastrophe.<br': 1, '/>Immediately': 2, '/>Shaggy': 1, '/>evil': 3, '/>insert': 1, 'be?<br': 1, '-say-': 1, '/>Forrest': 1, '/>Child': 2, '/>Potential': 1, '/>Studio': 1, 'accidental.<br': 1, '/>Chief': 1, 'by.<br': 1, '/>Unbelievable': 2, '/>Gojira': 1, '/>Blonde': 1, 'addicts.<br': 1, '/>Yipe': 1, '/>(Moderate': 1, '(*1/2': 2, 'cartoons?).<br': 1, 'move\"which': 1, '/>Costumes': 1, '/>R.I.P': 1, '/>Pat': 1, '/>VIEWER': 1, '/>Dries': 1, '/>\"Journey': 2, 'intact.<br': 3, '/>Andie': 1, 'women(Sarah': 1, '/>Accolades': 1, '/>Andalusian': 1, '/>Alabama': 1, 'confusing.<br': 1, '/>Robbie': 1, '/>\"8': 1, '/>Alba': 1, '/>Hoping': 1, 'expanded.<br': 1, '/>Battle': 1, 'inescapable.<br': 1, '/>Neve': 1, '.)<br': 1, 'it!!!!<br': 1, '/>Aplogise': 1, '/>GRADE': 1, '/>Major': 1, '/>Fishburne': 1, '/>Pacing': 3, '/>Bendix': 1, '/>little': 1, '/>chance': 1, '/>saw': 1, '/>butler': 1, '/>soap': 1, '/>matriarch': 1, '/>escapes': 1, '/>airplane': 1, '/>letterboxed': 1, '/>haunts': 1, '/>script': 1, '/>occurrence': 1, '/>lines': 1, '/>Dozen': 1, '/>recomment': 1, '/>copy': 1, '/>situations': 1, '/>Blue': 1, '/>*VERY': 1, '/>Haliday': 1, '/>/hjm': 1, '.about': 1, '/>Sgt': 1, '/>buries': 1, '/>Priety': 1, '/>Rani': 1, '/>Run': 3, '/>\"Livin': 1, '/>Katherine': 1, '/>Moroni': 1, '/>Plan': 1, '/>Bjork': 1, '/>D+': 1, '/>Routine': 1, 'citizens.<br': 1, '0.5/10': 2, 'berserk.<br': 1, 'Rachelle.<br': 2, 'wills.<br': 1, '.If': 1, '/>Rishi': 1, '/>***MAJOR': 1, '/>Ignoring': 2, '/>Aimed': 1, '/>Avoid.<br': 2, '/>Start': 2, '/>\"He': 1, '/>Madsen': 1, '/>Zabalza': 1, '/>not': 4, \"/>we're\": 1, '/>judge': 1, 'endless.<br': 1, 'wife(Elizabeth': 1, 'reporter(Luana': 1, '/>Nobel': 1, 'quick.<br': 1, '/>Scarecrow': 1, '/>Bizarrely': 1, '/>Hulkamaniacs': 1, '/>Ill': 1, 'fail.<br': 1, '/>3)This': 1, '/>*½': 1, ',whatever': 1, 'b!tch': 1, '/>****MILD': 1, 'tire.<br': 1, 'inclusion.<br': 1, '/>THey': 1, '\"It': 1, 'random.<br': 1, 'terrorists(Irish': 1, '/>Carry': 1, '/>Finished': 1, 'D&D.<br': 1, '/>-------': 1, '/>Accidental': 1, '/>Stylistically': 1, '/>Cringeworthy': 1, '/>Hay': 1, '/>Obi': 1, 'Gore,<br': 1, '/>given': 1, '/>azjazz': 2, 'wannabees(Frankie': 1, 'soldiers(half': 1, 'editor.<br': 1, '/>Disappointed': 1, 'gang(Lau': 1, 'book.<br': 1, '/>Heh': 1, '/>STAR': 1, '/>Tear': 1, '/>SIDENOTES': 1, \"/>they'd\": 1, 'blackboard.<br': 1, '/>Belle': 1, '/>Severed': 1, '/>knowledge': 1, '/>Tautou': 1, '/>Firode': 1, '/>Surrealist': 1, '/>Rainbow': 1, 'onscreen.)<br': 1, '/>Costner': 1, '/>man': 1, '/>Bergman': 2, '/>Ingrid': 1, '/>Distributor': 1, 'clouds.<br': 1, 'basement.<br': 1, '.vs': 2, '/>Shark': 1, '/>(For': 1, '/>Lesley': 1, '/>Yup': 1, '/>Stereotypes': 1, 'successful\"(as': 1, '/>(Full': 1, '/>***POSSIBLE': 1, 'cheesiness.<br': 1, '/>******END': 1, 'defeated.<br': 1, '/>Shu': 1, '/>Hou': 2, '/>Suicune': 1, '/>Ash': 1, 'money(WWF': 1, 'left(WWF': 1, 'Larry(Wheres': 1, 'experiments.<br': 2, '/>Almodóvar': 1, 'heel.<br': 1, 'gangster.<br': 1, '/>SHOULD': 1, 'relationship.<br': 1, 'agenda.<br': 1, '/>Goldie': 1, '/>computer': 1, '/>reviews': 1, '/>Gorehounds': 1, '/>BOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO': 1, 'unmoving.<br': 1, '/>Emulating': 1, 'thereof.<br': 1, '/>Definatey': 1, '/>Dexter': 1, 'form.<br': 1, '/>Merrill': 1, '/>Historicaly': 1, '/>Nineties': 1, '/>LOC': 1, '/>Reviewers': 1, '/>Devon': 1, 'suspects.<br': 1, '/>Learn': 1, '/>You`d': 1, '/>Istanbul': 1, '-5': 1, 'injury.<br': 1, '/>Anchor': 1, 'shoot.<br': 1, 'that(and': 1, 'grinning.<br': 1, '/>Seann': 1, '/>guy': 2, '/>Syrupy': 1, '-----3/10': 1, 'cars.<br': 1, \"'Cause\": 1, '/>Jyotika': 1, '/>Thx': 1, '/>give': 1, 'anyone?).<br': 1, '/>Unfortunatly': 1, 'sh*t!a': 1, '\\x91Lemercier': 2, '/>RazorFriendly': 1, '/>Filth': 2, '/>Sebastian': 2, '/>Virgin': 1, '/>Melissa': 1, '/>Soul': 1, '/>Wish': 1, 'What´s': 1, '/>Ziba': 1, 'elegance.<br': 1, 'Wilder.<br': 1, '*sighs*(just': 1, '/>Name': 2, '/dim': 1, '/>Novel': 1, '/>************Contains': 1, 'away.<br': 1, 'soundtrack.<br': 1, '/>Grim': 1, 'baddie.<br': 1, '/>CONCLUSION': 1, 'scared.<br': 1, 'numbers.<br': 1, '/>Della': 1, '/>MAJOR': 1, 'house\"!?French': 1, 'editors.<br': 1, '/>Prizzi': 1, 'annoys.<br': 1, 'actual.<br': 1, '/>\"BRING': 1, '/>Howdy': 1, '\"--Mr': 1, '/>(You': 1, 'properly.<br': 2, '/>Airport': 1, 'wit.<br': 1, '/>Nonono': 1, 'celebrated.<br': 1, '/>Problematic': 1, '/>\"Titanic': 1, 'allen.<br': 1, 'drollness.<br': 1, '/>BLACK': 1, 'striptease.<br': 1, '/>WHICH': 1, '/>INSTEAD': 1, '/>SUDDENLY': 1, '/>ANIL': 1, '/>ALL': 1, '/>WHY': 1, '/>Cannot': 1, '/>+/-s': 1, '/>\"Splatter': 1, 'stable.<br': 1, '/>Cradle': 2, 'running.<br': 1, '/>yes': 1, 'NOT!<br': 1, '/>derboiler': 1, '/>Anyhoo': 1, '/>Poorly': 1, 'guys(Trouby': 1, '/>\"Oh': 2, '/>Haim': 1, 'later.<br': 1, '/>Unbeknownst': 2, \"/>'Dillinger\": 1, '/>Roving': 1, '/>Publisher': 1, '/Screenwriter': 1, '/>PASTY': 1, 'interval.<br': 1, 'Blows.<br': 1, '/>Voice': 1, '/>among': 1, '/>had': 1, '/>forget': 1, '/>SAS': 1, '/>_X': 1, '/>Presumably': 1, '/>Fanciful': 1, '/>(That': 1, '/>Irreversible': 1, 'atrocious.<br': 1, '/>Burgess': 1, '/>Willem': 2, '/>Anywayz': 1, '/>Yelling': 1, '/>Abernathy': 1, '/>Nex': 1, '/>Finale': 1, '/>Tabu': 1, '/>Evidently': 1, 'Hispanics.<br': 1, 'sunglasses.<br': 2, '/>check': 1, '/>Dour': 1, '/>Thinking': 1, '/>Eileen': 1, '/>Sixty': 1, 'satisfied.<br': 1, '/>Already': 2, '/>Opera': 1, 'banal.<br': 1, '/>Hideos': 1, '=(': 1, '/>Waldemar': 1, '/>Elmann': 1, 'dreadful.<br': 1, '/>Fudge': 1, '/>Edited': 1, 'disappointed.<br': 1, '/>Comparison': 1, 'dark.<br': 1, '/>Verhoeven': 1, 'extravaganza.<br': 1, '/>Elisabeth': 1, '/>\"Wide': 1, '/>Broderick': 1, 'demise!\".<br': 1, '/>Daniella': 1, 'unnatural.<br': 1, 'views.<br': 1, '/>-inviting': 1, '/>-->because': 1, '/>Garner': 1, '/>Known': 1, '/>Hellborn': 1, '/>1/5': 1, '/>Bryan': 1, '/>*(Charlie': 1, '/>*Anyone': 1, '/>*(Brando': 1, '/>*There': 1, '/>*For': 1, '/>*Why': 1, '/>*Martin': 1, '/>*It': 1, '/>*Name': 1, '/>Godamnawful': 1, '/>Sub': 1, '/>Hogwash': 1, '/>BTW-': 1, 'chose.<br': 1, '/>Paltrow': 1, '/>Programmers': 1, '/>Quentin': 1, '/>Gay': 1, '/>Gloriously': 1, '/>R&J': 1, '/>Marthe': 1, '/>Incidentally': 2, 'Lewis.<br': 1, '/>Compounding': 2, '/>him': 1, '/>set': 1, '/>Evans': 1, '/>teen': 1, '/>Luana': 1, '/>Exploiting': 1, '/>jokes': 1, '/>Depending': 1, '/>**After': 1, '/>**When': 2, '/>**Throughout': 1, '/>**Finally': 1, '/>(paraphrase': 1, '/>\"Really': 1, 'anywhere.<br': 1, '/>Cliché': 7, '/>\"Would': 1, 'IMDB.com': 1, '/>\"Art': 1, '/>Bullet': 1, '/>Chong': 1, '/>Starlight': 1, '/>Zantara': 1, '/>Mad': 1, '/>hes': 1, '/>~A~': 1, '/>Shaking': 1, '/>LATITUDE': 1, '/>Overlong': 1, '/>Gammera': 1, '/>\"These': 1, 'unlikely.<br': 1, '/>Translation': 1, 'canceled.<br': 1, '/>Jill': 5, '/>Hopeless': 1, '/>Nothing.<br': 1, '/>Clip': 1, '/>RGV': 1, '/>\"We\\'re': 1, '/>Marlee': 1, '/>Boss': 2, '/>Game': 1, '/>Visuals': 1, '/>Pan': 1, '/>Ireland': 1, 'beyond.<br': 1, '/>Picturesque': 1, '/>Jenna': 1, 'wanders.<br': 1, '/>Daniela': 1, '\"?': 1, ';)': 1, '/>Daddy': 2, '/>Fearless': 1, '/>(Unratable': 1, '/>Sue': 1, 'Street.<br': 1, '/>Sony': 1, '/>Oz': 1, '/>Beth': 1, '.Yes': 1, '/>Salma': 1, '.Bad': 1, 'ideas.<br': 1, '/>You`ve': 1, '/>Techniques': 1, 'aisle.<br': 1, '/>last': 1, 'cells.<br': 2, 'soul.<br': 1, '...............................................................': 1, 'extracted.<br': 1, 'Wright.<br': 1, '/>Stuart': 2, '/>½': 1, '/>Rancid': 1, '/>salesman': 1, '/>golden': 1, '/>Capshaw': 2, '/>firm': 1, '/>clients': 1, '/>involved': 1, '/>boss': 1, '/>does': 1, '/>Arquette': 2, '/>she': 1, '/>telling': 1, '/>soon': 1, '/>break': 1, '/>relies': 1, '/>choice': 1, '/>Dunsky': 1, '/>Christophe': 1, '/>schizophrenic': 1, 'appalled.<br': 1, '/>April': 1, 'eye.<br': 1, '/>*MINOR': 1, 'marketed(and': 1, 'wings.<br': 1, 'fellow.<br': 1, 'Stern.<br': 1, 'that)<br': 1, '/>Intolerable': 1, '/>Tolerable': 1, '/>Delight': 1, '/>Fret': 1, '/>Gooding': 1, '/>Delia': 1, '/>c': 1, '/>Burdened': 1, '/>\"Diary': 1, '/>ADDENDUM': 1, '/>SKIP': 1, '/>Maiden': 1, 'name.i': 1, '/>WTF': 5, '/>MAY': 1, '(?)': 1, '*goosebumps': 1, '/>Virtually': 2, '/>Frewer': 1, '/>Monkey': 1, '/>Aspiring': 1, 'sh_it!\"<br': 1, 'demanding(which': 1, '/>Either': 1, '/>Pop': 1, '/>WORST': 1, '.1': 1, 'requests.<br': 1, '/>[Not': 1, '/>Trinity': 1, 'albino.<br': 1, 'hopelessly.<br': 1, 'cringe.<br': 2, '/actresses': 1, '/>Bamboo': 2, '/>Premise-': 1, '/>Surrounding': 1, 'statements.<br': 1, '\"Now': 1, '/>follow?<br': 1, '/>heh': 1, '/>Unrelated': 1, '/>Slow': 2, '/>Stereotyped': 1, 'wallets.<br': 1, 'line,(by': 1, 'badly?)(Was': 1, '/>Lowe': 1, '/>****************SPOILERS****************************<br': 1, '/>Earlier': 1, '/>Television': 2, 'agent(Dorff': 1, '--color': 1, '/>Gave': 1, '/>Chessecake': 1, '/>Brigham': 1, '/>Mothers': 1, 'Alicia(Mia': 1, 'imaginable.<br': 1, '/>Completing': 1, 'gadgets.<br': 2, '/>Cops': 1, 'inventions.<br': 1, '.that': 1, '/>Eve': 1, 'acted(Summer': 1, '/>Beamont': 2, '/>\"Piece': 1, '/>\"Roadrunners': 1, '/>Blockbuster': 1, '/>Chuck': 2, '/>Hire': 1, '/>Apologies': 1, '/>Dermot': 1, 'BUt': 1, '/>second': 1, '/>Faat': 1, '/>\"Boom': 1, '/>Hand': 1, '/>Shoving': 1, '-lauuughed-': 1, '-were-': 1, 'resume.<br': 1, '/>Awful.<br': 1, '/>Ridiculous.<br': 1, '/>Bam': 1, '/>Wayans': 1, 'noticed.<br': 1, '/>FOR': 1, 'personal.<br': 1, '/>Chan': 1, '/>Nuff': 1, '/>Rino': 1, '/>Wife': 1, '/>Tens': 1, '/>Blame': 1, 'childish.<br': 1, '/>(Update': 1, '/>every': 1, 'robot.<br': 1, '/>Important': 1, \"/>'Best\": 1, '/>Forlorn': 1, '/>E': 1, '/>Handsome': 1, '/>Walker': 2, '/>Macaulay': 1, 'killer)<br': 1, '/>WHATEVER.<br': 1, '.Oh': 1, '/>Tall': 1, '/>http://eattheblinds.blogspot.com/': 1, '/>Haiku': 1, 'was\".<br': 1, '/>\"Traffic': 1, '/>\"Joe': 1, '/>Boycott': 1, '/>\"Extreme': 1, '/>Assemble': 1, '/>Watchable': 1, '/>Agnes': 1, 'of?<br': 1, '/>\"Die': 1, 'rancid.<br': 1, 'caricatures.<br': 1, '/>Lenny': 1, '/>Gordan': 1, '/>\"Promise': 1, '/>kick': 1, '/>your': 1, '/>try': 1, '/>Halperin': 1, '/>\"Absolute': 1, '/>Staggered': 1, '/>Arrghh': 1, 'famous.<br': 1, '/>1.Policticly': 1, '/>2.Insults': 1, '/>3.The': 1, '/>4.In': 1, '/>5.Did': 1, '/>6.In': 1, '/>7.The': 1, '/>8.\"Just': 1, '/>Crispin': 1, '/>Glover': 1, '/>Whole': 1, '/>Søren': 1, '/>Schizophrenia': 1, '/>---SPOILERS---': 1, '/>Gael': 1, '/>Rainn': 1, '/>Nonethelss': 1, '/>Registered': 1, '/>Obligatory': 1, '-are': 1, '/>(a': 1, '/>(b': 1, '/>Sheesh': 1, '/>Rise': 3, 'George(Rod': 1, '/>Juhi': 1, 'apparatus.<br': 1, '/>Hodgepodge': 1, '/>Connery': 2, 'everglades.<br': 1, '/>Glasgow': 1, '/>Zenigata': 1, '/>Yawn': 1, 'hoped.oh': 1, '/>Lundgren': 1, '/>DETENTION': 1, '/>I`ll': 1, '/>Yea': 1, '-an': 1, '/>Sterno': 2, '/>Flight': 1, '/>-Matthew': 1, '/>funny': 1, '/>Mykelti': 1, 'didn`t': 1, \"/>'Metamorphis\": 1, '/>Gasp': 1, 'Fedor8/150_worst_cases_of_nepotism/': 1, '/>summarising': 1, '/>Nastassja': 2, '/>Kris': 1, '/>\"FINALLY': 1, '/>Brady': 1, \"/>'Thunderbirds\": 1, 'slippers.<br': 2, '/>Lordi': 1, '/>Melody': 1, '/>Walmart': 1, '/>Stunts': 1, 'masks.<br': 1, '/>Asin': 1, 'children.<br': 1, '-----------------': 1, 'graves.<br': 1, '/>\"\"DEFINITE': 1, '/>Neagle': 1, \"/>You'll\": 1, '/>-Sorcia': 1, '/>Blech': 1, '/>Foreign': 1, '-Because': 1, '/>Hate': 1, '/>Flixmedia': 1, '/>Halla': 1, '/>Rajkumar': 1, '/>Arjun': 1, 'Atlantis:_The_Lost_Empire': 1, '/>somewhat': 1, '/>(hopefully': 1, '/>hypocritical': 1, '/>seems': 1, '/>Anywho': 1, '/>Update': 1, '/>Yul': 1, '/>\"Cube': 1, '/>Sent': 1, '/>Grindhouse': 1, '/>Neighbours': 1, '/>SO': 1, '/>Gaston': 1, '/>Coppola': 1, '/>Expecting': 1, '/>Raggedy': 1, '/>**POSSIBLE': 1, '/>--Um': 1, '--Very': 1, '/>--Booooooooooooring.<br': 1, '/>--All': 1, '/>Cutting': 1, '/>\"Over': 1, '/>Woeful': 1, '/>Oooooh': 1, '/>Tina': 1, '/>Baby': 1, '/>Meyers': 1, 'stupid.<br': 1, '/>Lathan': 1, '/>Choreography': 1, 'campfire.<br': 1, '/>Rajni': 1, '/>Pamela': 1, 'coffin.<br': 1, '-****1/2': 1, '/>Discussion': 1, 'island!!!Oh': 1, '/>Orca': 1, '/>ok': 1, '/>ah': 1, '\"??<br': 1, '/>#9': 1, '/>Hunh?!?<br': 1, 'neither.<br': 1, '/>Cushing': 1, '/>Fulton': 1, '/>Raptor': 1, '/>`Larry': 1, '/>Recap': 1, '/>Tops': 1, 'baffled.<br': 1, '/>NOT!<br': 1, '/>Stephanie': 1, 'convenient)': 1, '/>Cinemaphotography': 1, '/>Pepper': 1, 'whites(and': 1, 'amazing(better': 1, '-Atlantis:-The': 1, '/>Current': 1, '/>Kida': 1, '/>BANG': 1, '/>>And': 1, 'conversation.<br': 1, '/>Harold': 1, 'assault.<br': 1, 'ones(and': 1, '/>Ahhh': 1, '/>Der': 1, 'rides.<br': 1, '.This': 1, '/>Deary': 1, 'effects.<br': 1, '.Her': 1, '/>Heck': 1, '/>(According': 1, '/>Intriguing': 1, '/>\"As': 1, '/>Rajpal': 1, '/>\"Narrow': 1, '/>\"Make': 1, '-SPOILES-': 1, '/>Pfeh.<br': 1, 'Costard.<br': 1, '/>*Spoiler': 1, '/>Gambit': 1, '/>l': 1, '/>Sarsgaard': 1, '/>Foster': 1, '/>STORYLINE': 1, '/>*Chief': 1, '/>CRIMSON': 1, '/>-Rick': 1, '/>Anbody': 1, 'diatribe.<br': 1, '/>hour': 1, '/>got': 1, '/>hunky': 1, '/>attractive': 1, '/>Bluto': 1, 'world(omg': 1, '-ism': 1, '/>etc': 1, 'crap???<br': 1, '/>Debra': 1, '/>DOND': 1, 'dinner.<br': 1, \"you've\": 1, '/>Noise': 1, '/>Robbin': 1, '/>*****END': 1, 'horseshit.<br': 1, '..............................': 1, 'E.V.I.L': 1, '/>http://mcmusicnotes.blogspot.com': 1, '/>Vince': 1, '.Disaster': 1, '/>Sholay': 1, '/>hands': 1, 'developed.<br': 1, '/>***Spoiler***and': 1, '/>Model': 1, '/>Novice': 1, '/>Bart': 1, '/>argue': 1, '/>Lisa': 1, '/>Ilias': 1, '/>Robots': 1, 'Interrupted.<br': 1, '/>Dare': 1, '/>omg': 1, 'EVERYTHING???<br': 1, '/>(BTW': 1, 'Melville´s': 1, '/>Delon': 1, '/>\"Try': 1, '/>contact': 1, '/>Acting-': 1, 'eh!\"The': 1, '/>Lutz': 1, '/>Witchcraft': 1, '/>Misty': 1, '/>Downey': 1, '/>Jordan': 1, 'renting.<br': 1, '/>(Spoilers': 1, 'Keaton)leaves': 1, '/>Liv': 2, '/>Currently': 1, '/>Vikings': 1, '-C': 1, '/>SUMMER': 1, '/>Elmer': 1, '-ups': 1, '/>\"Water': 1, '/>\"Rosenstraße': 1, '/>Riemann´s': 1, 'promotion.<br': 1, '/>Tale': 1, '/>Forest': 1, 'vampires.<br': 1, \"/>'Return\": 1, \"/>'Cabin\": 1, '/>(Did': 1, '/>Dresler': 1, '/>Jammed': 1, '/>Comms': 1, '/>\"Maybe': 1, '/>Bilko': 1, 'enjoyability.<br': 1, 'Elvira.<br': 1, '/>Superchick': 1, '/>\\uf0b7': 5, '/>Jess': 1, '/>Dunno': 1, '/>entertainment': 1, '-8/10': 1, '/>Shave': 1, '1969).<br': 1, '/>Overly': 1, '.cripple': 1, 'cast\\x97among': 1, '/>Heavenly': 1, '/>Naschy': 1, 'that?).<br': 1, '/>Carole': 1, '............................': 1, '/cue': 1, 'information.<br': 1, '/>college': 1, '/>Catholic': 1, \"/>(i'm\": 1, '/>realities': 1, '/>Potala': 1, '/>Tiffany': 1, '/>Introduction': 1, '/>Dope': 1, \"/>'Speak\": 1, '/>Post': 1, '/>SCHIZOPHRENIAC': 1, '/>Sasquatch': 1, '/>nevermind': 1, 'assailant.<br': 1, '/>\"Americans': 1, 'comma': 1, '/>Wrestling': 1, '/>Closets': 1, '/>Detmers': 1, 'chick(who': 1, '/>Plotwise': 1, '/>Ang': 1, '/>Diary': 1, '/>Theonly': 1, '/>maybe': 2, '/>Antitrust': 1, '/>Rajinikanth': 1, \"/>You'l\": 1, '/>Maddy': 1, '/>Hamilton': 1, 'entrancing.<br': 1, 'Simpson.<br': 1, '/>Rats': 1, '/>*spoiler*<br': 1, '/>Igor': 1, '/>Enoch': 2, 'eligible.<br': 1, '/>Karin': 1, '/>#1-': 1, '/>#2-': 1, 'strokes.<br': 1, '/>Chabrol': 2, '/>Georgina': 1, '/>Kirk': 1, 'maker(Myles': 1, 'perp.<br': 1, '/>Parhat': 1, '/>\"And': 2, 'http://en.wikipedia.org/wiki/Dispensationalism': 1, 'crappy.<br': 1, '/>\"worse': 1, '/>Fresh': 1, '/>Frederick': 1, '/>Ernest': 1, '/>Feeling': 1, '/>Chandon': 1, '/>Sappily': 1, '/>*spoilers': 1, '/>Hackman': 1, '-Good': 1, '/>Painfully': 1, 'idea(the': 1, 'did).<br': 1, 'generous.<br': 1, '/>Celina': 1, 'repulsive.<br': 1, '/>\"Gammera': 1, '/>\"Nacho': 1, '>.<': 1, '/>Mac': 1, 'sensationalized.<br': 1, 'paycheck.<br': 1, 'of.<br': 1, '-had': 1, '/>***Update***<br': 1, '/>Bocabonita': 1, 'whale.<br': 1, '/>we': 3, '/>oh': 2, '/>theses': 1, '/>Constant': 1, '/>Paging': 1, '/>Operations': 1, '/>Rumors': 1, '/>Matarazzo': 1, '/>7/08': 1, 'I.A.?<br': 1, 'crude.<br': 1, '/>worse': 1, '/>can': 1, '/>prostitute': 1, '/>Bouchemi': 1, '/>*begin': 1, '.00015': 1, '/>Ack': 1, 'Grendel\")If': 1, '/>-jurassic': 1, 'incorrect.<br': 1, '/>GI': 1, \"/>'GI\": 1, '/>\"Hinting': 1, '/>CONSIDER': 1, '/>Kurupt': 1, '/>rubbish': 1, '/>Abroad': 1, '.And': 1, \".Don't\": 1, '/>Logic': 1, '/>Stilted': 1, \"/>'Papi\": 1, '/>Hackneyed': 1, '/>Busta': 1, '/>N': 1, '/>Nicgolas': 1, '.extortion': 1, '/>JAKE': 1, 'consumption.<br': 1, '/>Firstly': 1, '-AP3-': 1, 'button.<br': 1, '/>Vaughn': 1, '/>Vaugn': 1, 'private(Michael': 1, '/>\"Stripes': 2, '/>Yours': 1, 'Excruciating.<br': 1, '/>get': 2, '-\"Da': 1, '-It': 1, '/>Franke': 1, 'rats.<br': 1, '/>INTERVIEWEES': 1, '.Mr': 1, 'enjoys.<br': 1, 'bulb.<br': 1, 'implausible.<br': 1, '/>*sigh*<br': 1, '/>*sigh*': 1, '/>Rumor': 1, '/>Japan': 2, '/>Malden': 1, '/>(English': 1, '/>Skid': 1, '.45s': 1, '/>Duh': 1, '/>****SPOILERS': 1, '/>Brandon': 1, 'WATCH\"<br': 1, '/>save': 2, '/>Mediocre': 1, '/>Zanuck': 1, '/>Papa': 1, 'restaurants.<br': 1, 'sanitized.<br': 1, '/>Recipe': 1, '/>Mix': 1, '/>Serving': 1, '/>Hughes': 1, '/>kamal': 1, 'http://www.thenewamerican.com/tna/1996/vo12no18/vo12no18_mccarthy.htm': 1, 'bloodshed.<br': 1, '.02': 2, 'happen!\".<br': 1, '/>Boringly': 1, 'exactly.<br': 1, '/>OHHHHH': 1, 'rape.<br': 1, '/>Dinsey': 1, '/>Bonham': 1, '/>imagine': 1, 'seasoned(Miguel': 1, 'accomplished(Julie': 1, '/>Follow': 1, '/>------------------<br': 1, '/>------------------': 1, '/>White': 1, '/>Miike': 1, '/>Ya': 2, '/>Rachael': 1, '/>Cillian': 1, '-sex': 1, '/>Unnecessary': 1, '/>Syed': 1, '/>Cop': 1, '/>Vijay': 1, '/>Sans': 1, '/>Asner': 1, '/>Nadia': 1, '/>Berkhoff': 1, '/>666': 1, '/>banned': 1, '/>Malcolm': 1, 'resumes.<br': 1, \"/>'House\": 1, '/>Succinctness?<br': 1, '/>Soul?<br': 1, 'stupid?).<br': 1, '/>Ohhh': 1, '/>Distributed': 1, '/>Rajiv': 1, '/>Sunny': 1, '/>Goes': 1, '/>0.00001/10': 1, '/>\"Black': 1, '/>Ram': 2, '/>Contemptible': 1, '/>umm': 1, 'murder(and': 1, '/>Sky': 1, '/>Entrails': 1, 'else?--build': 1, 'entirely.<br': 1, '/>Dax': 1, '/>Silk': 1, '.Lorenzo': 1, 'birth.<br': 1, '/>Aaron': 1, '/>Sets': 1, '/>Independent': 1, '/>Troma': 1, '/>Spaghetti': 1, 'FEAR.net': 1, 'Hogg),the': 1, 'http://blog.myspace.com/locoformovies': 1, '/>Dreadful': 1, '/>Flora': 1, '/>Future': 1, '/>Embarrassingly': 1, '/>Pain': 1, '/>Hyped': 1, '.J': 1, '/>Morvern': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVqleH-2yVXN"
      },
      "source": [
        "punct_dict_re = {}\n",
        "\n",
        "for doc in positive_data:\n",
        "  temp = re.findall(\"[^\\w\\s]\",doc)\n",
        "  for p in temp:\n",
        "    if(p in punct_dict_re):\n",
        "      punct_dict_re[p] += 1\n",
        "    else:\n",
        "      punct_dict_re[p] = 1\n",
        "\n",
        "for doc in negative_data:\n",
        "  temp = re.findall(\"[^\\w\\s]\",doc)\n",
        "  for p in temp:\n",
        "    if(p in punct_dict_re):\n",
        "      punct_dict_re[p] += 1\n",
        "    else:\n",
        "      punct_dict_re[p] = 1"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TTWI5_lYAFCZ",
        "outputId": "0623b095-bc22-4bb4-af28-73c86873d4a4"
      },
      "source": [
        "print('Number of punctuations according to regex are: ', len(punct_dict_re.keys()))\n",
        "print('List of punctuations according to regex are as follows: \\n',punct_dict_re)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of punctuations according to regex are:  66\n",
            "List of punctuations according to regex are as follows: \n",
            " {',': 276280, '-': 67075, \"'\": 133857, '.': 327192, '\"': 65831, '!': 24560, '?': 16088, '(': 35397, ')': 36175, '<': 101971, '/': 108798, '>': 102036, ';': 6702, ':': 10192, '\\x96': 1368, '\\x97': 283, '&': 3809, '*': 7061, '{': 106, '}': 107, '@': 82, '#': 377, '%': 446, '`': 964, '$': 782, '+': 295, '=': 427, '®': 4, '´': 205, '£': 56, '^': 37, '~': 115, '₤': 2, '\\x84': 19, '[': 100, ']': 107, '«': 18, '»': 20, '\\\\': 17, '“': 29, '”': 27, '’': 125, '\\x08': 4, '\\x91': 71, '·': 14, '\\x8e': 18, '\\x9e': 18, '¨': 52, '\\x9a': 1, '¡': 39, '–': 81, '…': 5, '|': 16, '¿': 3, '¤': 1, '\\x80': 2, '°': 1, '‘': 7, '¦': 14, '§': 13, '\\xad': 1, '\\x95': 14, '\\x8d': 1, '¢': 1, '\\x10': 1, '\\uf0b7': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbbkTqJxCOv3"
      },
      "source": [
        "The count of punctuations obtained from spacy are very high when compared to the counts obtained using regex. Spacy is considering part of string as a different punctuation, for example, '/>But' and '/>They' considered as a different punctuations. Due to this the number of punctuations are very high in spacy. \n",
        "\n",
        "But Regex will perform a pattern based match and will include only punctuations without part of word. Because of which the number of punctuations according regex are 66 whereas the number of punctuations according to spacy are 6972."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiUscaQqdZQu"
      },
      "source": [
        "**Bonus Question:​ ​(40 points)​** Using the code from Class 09 - Word Embeddings, pre-tune BERT in order to classify movie reviews. You can use the full TRAINING folder for the tuning and use the UNLABELED folder for your final classification/prediction task. Do the label predictions from BERT match what your classifier from Question 4 predicted? If they don’t, are they better? Please say why. \n",
        "\n",
        "​NOTE: This is a pro-level task and while you might be tempted to copy code from the Internet, do not do it, as you will fail the class if you are plagiarizing. The code from the class can be tweaked to do the task with some adjustments. This is definitely not easy, but that is why it is worth an extra 40 points!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tybNxvUTdcRx",
        "outputId": "33c9b817-c8ad-4022-f341-ab4c17620710"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao8lgcvJWtss",
        "outputId": "6105672c-3414-4da3-baaa-1d9a43007fc3"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW5fEEnmW_5W",
        "outputId": "1eb323f5-9301-4280-d24c-4718936faf6b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uQiFgR5XDWc"
      },
      "source": [
        "sentences = X\n",
        "labels = y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy3QSPRmXQuE",
        "outputId": "7b3d3709-f903-403c-aadc-c33b554bffb2"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1K3dF6fdTft"
      },
      "source": [
        "# NOTE: Since bert has a constraint of 512 tokens, I am adding max_length as 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRKGiPWrX34O",
        "outputId": "677b7a21-0e61-438f-87f2-61e4190a8cbf"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation = True\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  The \"movie aimed at adults\" is a rare thing these days, but Moonstruck does it well, and is still a better than average movie, which is aging very well. Although it's comic moments aim lower than the rest of it, the movie has a wonderful specificity (Italians in Brooklyn) that isn't used to shortchange the characters or the viewers. (i.e. Mobsters never appear in acomplication. It never becomes grotesque like My Big Fat Greek Wedding) The secondary story lines are economically told with short scenes that allow a break from the major thread. These are the scenes that are now missing in contemporary movies where their immediate value cannot be impressed upon producers and bigwigs. I miss these scenes. It also beautifully involves older characters. The movie takes it's own slight, quiet path to a conclusion. There isn't a poorly written scene included anywhere to make some executives sphincter relax. Cage and Cher do very nice work.<br /><br />Moonstruck invokes old-school, ethnic, workaday New York much like 'Marty' except Moonstruck is way less sanctimonious.\n",
            "Token IDs: tensor([  101,  1996,  1000,  3185,  6461,  2012,  6001,  1000,  2003,  1037,\n",
            "         4678,  2518,  2122,  2420,  1010,  2021, 23377, 16344, 12722,  2515,\n",
            "         2009,  2092,  1010,  1998,  2003,  2145,  1037,  2488,  2084,  2779,\n",
            "         3185,  1010,  2029,  2003, 12520,  2200,  2092,  1012,  2348,  2009,\n",
            "         1005,  1055,  5021,  5312,  6614,  2896,  2084,  1996,  2717,  1997,\n",
            "         2009,  1010,  1996,  3185,  2038,  1037,  6919,  3563,  3012,  1006,\n",
            "        16773,  1999,  6613,  1007,  2008,  3475,  1005,  1056,  2109,  2000,\n",
            "         2460, 22305,  2063,  1996,  3494,  2030,  1996,  7193,  1012,  1006,\n",
            "         1045,  1012,  1041,  1012, 11240, 15608,  2196,  3711,  1999,  9353,\n",
            "        25377, 19341,  3508,  1012,  2009,  2196,  4150, 27707,  2066,  2026,\n",
            "         2502,  6638,  3306,  5030,  1007,  1996,  3905,  2466,  3210,  2024,\n",
            "        15318,  2409,  2007,  2460,  5019,  2008,  3499,  1037,  3338,  2013,\n",
            "         1996,  2350, 11689,  1012,  2122,  2024,  1996,  5019,  2008,  2024,\n",
            "         2085,  4394,  1999,  3824,  5691,  2073,  2037,  6234,  3643,  3685,\n",
            "         2022,  7622,  2588,  6443,  1998,  2502, 16279,  2015,  1012,  1045,\n",
            "         3335,  2122,  5019,  1012,  2009,  2036, 17950,  7336,  3080,  3494,\n",
            "         1012,  1996,  3185,  3138,  2009,  1005,  1055,  2219,  7263,  1010,\n",
            "         4251,  4130,  2000,  1037,  7091,  1012,  2045,  3475,  1005,  1056,\n",
            "         1037,  9996,  2517,  3496,  2443,  5973,  2000,  2191,  2070, 12706,\n",
            "        11867, 10606, 21162,  9483,  1012,  7980,  1998, 24188,  2079,  2200,\n",
            "         3835,  2147,  1012,  1026,  7987,  1013,  1028,  1026,  7987,  1013,\n",
            "         1028, 23377, 16344, 12722,  1999,  6767,  9681,  2214,  1011,  2082,\n",
            "         1010,  5636,  1010,  2147, 28039,  2047,  2259,  2172,  2066,  1005,\n",
            "        12578,  1005,  3272, 23377, 16344, 12722,  2003,  2126,  2625,  2624,\n",
            "         6593, 16339, 27678,  2271,  1012,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D2RuASsYDXs",
        "outputId": "e6ac2a09-f809-43f0-b94b-d726ffae99dd"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22,500 training samples\n",
            "2,500 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRb5op6mYDUt"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUZOFSAldHqf"
      },
      "source": [
        "# NOTE: Changed the batch size to 8, to handle cuda out of memory exception\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy5qSxpAY1Kg"
      },
      "source": [
        "Loading and Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ69ViWzY0qa",
        "outputId": "80e277f5-6547-4633-fc01-e139c4bd48bd"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIqbec3HYDRx"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A84UK-XgYN5J"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmpb3ZJOYN2T"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NKJMyHGZfqu"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "o8oYJHOjZg9K",
        "outputId": "b1cdfaea-b8ba-40ce-a328-ba0089f6c395"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  2,813.    Elapsed: 0:00:33.\n",
            "  Batch    80  of  2,813.    Elapsed: 0:01:07.\n",
            "  Batch   120  of  2,813.    Elapsed: 0:01:40.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-bbd984877583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# single value; the `.item()` function just returns the Python value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# from the tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# Perform a backward pass to calculate the gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA7L5P_ecxVf"
      },
      "source": [
        "# NOTE: Stopped the training in between because it is taking 4 Hours to train on Reviews dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs9H1Q2SZqnm"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvpN7pRicklR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLCiFfKAcrJN"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy6SLhDQdvKn"
      },
      "source": [
        "Evaluation on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0B-n8DbdrSK"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
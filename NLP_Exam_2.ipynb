{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Exam_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrQfnDa1B8LOwuk2STsNgN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhilkoditala/CSC-8980-NLP/blob/main/NLP_Exam_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtJ9BfMtWP2g"
      },
      "source": [
        "# Name: Nikhil Koditala\n",
        "\n",
        "# Panther ID: 002571023"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV10S8KSWFIf"
      },
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import spacy\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "from itertools import tee"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qoa8P2Tonfy"
      },
      "source": [
        "# vectorization methods\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncHfjmKBbnYs"
      },
      "source": [
        "**Question 1) (20 points) Write a function that takes a List of five words: [‘apple’, ‘house’, ‘pear’, ‘dog’, ‘doctor’] and returns a list of lists with each element being a word and a list of the top five most similar words. For this task you have to use the most suitable method of the ones we have seen in class to determine the most similar words to the original input list. You can use a pre-trained resource if you think is appropriate. After calling your function, print the most similar words to the screen.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Weso59rWWbF",
        "outputId": "0f119583-2da3-41d1-b74b-b7f4c77c6e1a"
      },
      "source": [
        "!gdown --id 0B7XkCwpI5KDYNlNUTTlSS21pQmM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "1.65GB [00:10, 153MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPUUMLy4WWYv",
        "outputId": "97db6c71-9fe3-4d3d-d7dc-3ad186d79e6b"
      },
      "source": [
        "!gunzip /content/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: /content/GoogleNews-vectors-negative300.bin.gz: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEx28oMcdB-l"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "filename = '/content/GoogleNews-vectors-negative300.bin'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzleX3JCdEbr"
      },
      "source": [
        "def most_similar(input_list):\n",
        "  res_list = []\n",
        "  for word in input_list:\n",
        "    temp = []\n",
        "    sim_words = model.most_similar(word)[:5]\n",
        "    for d in sim_words:\n",
        "      temp.append(d[0])\n",
        "    res = [word]\n",
        "    res.append(temp)\n",
        "    res_list.append(res)\n",
        "  return res_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58LiBQ5SdtLL"
      },
      "source": [
        "input_list = ['apple', 'house', 'pear', 'dog', 'doctor']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DjQaYBLefJZ",
        "outputId": "326d8673-bb81-43e9-a9e7-59f756003509"
      },
      "source": [
        "res_list = most_similar(input_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6zFWNcve5_4",
        "outputId": "67acbe1e-9e32-4bed-da06-e661cea10a7c"
      },
      "source": [
        "res_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['apple', ['apples', 'pear', 'fruit', 'berry', 'pears']],\n",
              " ['house', ['houses', 'bungalow', 'apartment', 'bedroom', 'townhouse']],\n",
              " ['pear', ['pears', 'apricot', 'apricots', 'nectarine', 'Fuji_apple']],\n",
              " ['dog', ['dogs', 'puppy', 'pit_bull', 'pooch', 'cat']],\n",
              " ['doctor', ['physician', 'doctors', 'gynecologist', 'surgeon', 'dentist']]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSbtaXnAfJbA"
      },
      "source": [
        "**Are these ‘similar’ words actually similar? If not, why not? What do you think can be improved and how - talk about it, do not necessarily implement it?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jOvhsAXEXeS"
      },
      "source": [
        "The above approach of using word2vec and finding similar words was giving good results. For each of the input word, it is able to find a related word. For example, given doctors the model returned different types of doctors.\n",
        "\n",
        "Despite the advantages, word2vec doesn't provide context sensitive embeddings which is one disadvantage. Modesl such as ELMO and BERT were able to handle context sensitivity better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP03nVG5bqWe"
      },
      "source": [
        "\n",
        "**Question 2) (30 points) Using the Homework 2 dataset, also attached in the Exam 2 files, shakespeares-works_TXT_FolgerShakespeare.zip.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4J_UpmgkBTu"
      },
      "source": [
        "!unzip '/content/shakespeares-works_TXT_FolgerShakespeare.zip' -d 'shakespeares-works_TXT_FolgerShakespeare'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP7upBlzkR2u"
      },
      "source": [
        "file_paths = os.listdir('/content/shakespeares-works_TXT_FolgerShakespeare') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97Sdx0rMkpvt"
      },
      "source": [
        "file_paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HvM5CRog6UU"
      },
      "source": [
        "a) Cosine similarity. And create a 42 x 42 heatmap of these similarities.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1BX_6ckhAo3"
      },
      "source": [
        "text = []\n",
        "for path in file_paths:\n",
        "  if(path.split('.')[-1] == 'txt'):\n",
        "    f = open(os.path.join('/content/shakespeares-works_TXT_FolgerShakespeare',path),'r') \n",
        "    text.append(f.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50XoF_SHbqFF"
      },
      "source": [
        "def build_cosine(documents):\n",
        "  tfidf = TfidfVectorizer()\n",
        "  matrix = tfidf.fit_transform(documents) \n",
        "  matrix = matrix.astype(np.float32) # converting matrix to float32 to use Google Colab RAM efficiently\n",
        "  return cosine_similarity(matrix,matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkrfL-IUoqpZ"
      },
      "source": [
        "cosine_matrix = build_cosine(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpxBnmc3zKWO",
        "outputId": "c89867a9-33e8-48ff-d7b2-d020a8731c62"
      },
      "source": [
        "cosine_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99999666, 0.4866196 , 0.49917883, ..., 0.6020113 , 0.587446  ,\n",
              "        0.4946799 ],\n",
              "       [0.4866196 , 0.9999977 , 0.47067878, ..., 0.59251404, 0.57559925,\n",
              "        0.46439424],\n",
              "       [0.49917883, 0.47067878, 0.99999815, ..., 0.58301455, 0.5659723 ,\n",
              "        0.481636  ],\n",
              "       ...,\n",
              "       [0.6020113 , 0.59251404, 0.58301455, ..., 1.0000024 , 0.843792  ,\n",
              "        0.57159185],\n",
              "       [0.587446  , 0.57559925, 0.5659723 , ..., 0.843792  , 0.99999976,\n",
              "        0.5546956 ],\n",
              "       [0.4946799 , 0.46439424, 0.481636  , ..., 0.57159185, 0.5546956 ,\n",
              "        0.99999964]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "dYLo7kZTpEf3",
        "outputId": "7770ce36-25ed-4edb-e77d-ad88ddbc552d"
      },
      "source": [
        "# Plotting a continuous heatmap\n",
        "plt.imshow(cosine_matrix, cmap='viridis')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f37ddfbc590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7c6JEd_g8Uc"
      },
      "source": [
        "b) Use Doc2Vec to create document embeddings and find the similarities between the\n",
        "documents. To visualize this, also create a 42 x 42 heatmap for this.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhC_hyMBhAVa",
        "outputId": "fec97ca3-d8a9-4e00-a603-48842458a631"
      },
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2RUkAdobqB9"
      },
      "source": [
        "model = Doc2Vec(vector_size=50, min_count=2, epochs=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAVKGASFs6D4"
      },
      "source": [
        "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou7gApHZs5-P"
      },
      "source": [
        "max_epochs = 50\n",
        "vec_size = 50\n",
        "alpha = 0.025\n",
        "\n",
        "model = Doc2Vec(size=vec_size,\n",
        "                alpha=alpha, \n",
        "                min_alpha=0.00025,\n",
        "                min_count=1,\n",
        "                dm =1)\n",
        "  \n",
        "model.build_vocab(tagged_data)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print('iteration {0}'.format(epoch))\n",
        "    model.train(tagged_data,\n",
        "                total_examples=model.corpus_count,\n",
        "                epochs=model.iter)\n",
        "    # decrease the learning rate\n",
        "    model.alpha -= 0.0002\n",
        "    # fix the learning rate, no decay\n",
        "    model.min_alpha = model.alpha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQloWHcMurUR",
        "outputId": "d83c843e-c44e-4db0-b0b8-67fd92663863"
      },
      "source": [
        "similar_doc = model.docvecs.most_similar('1',topn=42)\n",
        "print(similar_doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('16', 0.5943615436553955), ('22', 0.5071779489517212), ('8', 0.44327008724212646), ('35', 0.4279804527759552), ('24', 0.41615694761276245), ('6', 0.3888361155986786), ('41', 0.3839137554168701), ('10', 0.36380112171173096), ('23', 0.3516691327095032), ('36', 0.3426838517189026), ('4', 0.33621886372566223), ('27', 0.3330827057361603), ('29', 0.31400981545448303), ('38', 0.3123456537723541), ('13', 0.3041009306907654), ('15', 0.29997700452804565), ('7', 0.2931181788444519), ('26', 0.28913718461990356), ('17', 0.28217384219169617), ('18', 0.25904858112335205), ('14', 0.2579059600830078), ('28', 0.2569320797920227), ('34', 0.2515232563018799), ('25', 0.24071824550628662), ('40', 0.22631502151489258), ('32', 0.22534795105457306), ('11', 0.20163612067699432), ('9', 0.20004338026046753), ('12', 0.1932675987482071), ('19', 0.1811007261276245), ('39', 0.1675184667110443), ('30', 0.15248458087444305), ('20', 0.1394958794116974), ('31', 0.1368507295846939), ('2', 0.11948559433221817), ('3', 0.10222337394952774), ('33', 0.09295283257961273), ('0', 0.07578872889280319), ('5', 0.07058395445346832), ('21', 0.058475904166698456), ('37', 0.05830460041761398)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfjmU8hgzW-6"
      },
      "source": [
        "cosine_matrix_d2v = [[1 for i in range(42)] for j in range(42)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiTA4rGN75bX",
        "outputId": "cbcaa0a2-eb5d-409a-c81d-a402f858db1b"
      },
      "source": [
        "for i in range(42):\n",
        "  similar_doc = model.docvecs.most_similar(i,topn=42)\n",
        "  for sim in similar_doc:\n",
        "    cosine_matrix_d2v[i][int(sim[0])] = sim[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "eElVI79s6oVN",
        "outputId": "9102e786-c9d8-4d16-c1f7-dcebdeb2d500"
      },
      "source": [
        "# Plotting a continuous heatmap\n",
        "plt.imshow(cosine_matrix_d2v, cmap='viridis')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f37c8d82b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZCQ-iLBg-Dk"
      },
      "source": [
        "c) What are the differences you find between the two methods? Is there anything radically different? Please describe your answer in terms of the heatmap of part a and part b."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elWo5IpnFzoH"
      },
      "source": [
        "The cosine similarity matrix looks more smoother, where as the matrix built from doc2vec has a lot of discontinuity in it. The similarity of doc2vec were better than that of the ones with cosine, as there are no common patterns there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38xCER9fgsUB"
      },
      "source": [
        "Question 3) (30 points) Using the Homework 2 dataset. Use SpaCy to extract the following: \n",
        "\n",
        "a) Write a function to generate all unique bigrams from all documents in the dataset. The input of this function should be the concatenated dataset and the output should be the list of bigrams and their frequency. Display the top 10 most common bigrams and their frequency.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_Vc3xHuLIv3"
      },
      "source": [
        "import spacy\n",
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "from itertools import tee\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEMDJi9xgxVn"
      },
      "source": [
        "!unzip '/content/shakespeares-works_TXT_FolgerShakespeare.zip' -d 'shakespeares-works_TXT_FolgerShakespeare'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVX6fnl2IbTQ"
      },
      "source": [
        "file_paths = os.listdir('/content/shakespeares-works_TXT_FolgerShakespeare') "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXeZAOx1IbNM"
      },
      "source": [
        "text_q3 = ''\n",
        "for path in file_paths:\n",
        "  if(path.split('.')[-1] == 'txt'):\n",
        "    f = open(os.path.join('/content/shakespeares-works_TXT_FolgerShakespeare',path),'r') \n",
        "    text_q3 += f.read()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS-q4plumk7O"
      },
      "source": [
        "# helper functions\n",
        "def make_trigrams(iterator):\n",
        "    a, b, c = tee(iterator, 3)\n",
        "    next(b)\n",
        "    next(c)\n",
        "    next(c)\n",
        "    return zip(a, b, c)\n",
        "\n",
        "def make_bigrams(iterator):\n",
        "    a, b = tee(iterator, 2)\n",
        "    next(b)\n",
        "    return zip(a, b)\n",
        "\n",
        "def make_unigrams(iterator):\n",
        "    return iterator"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU_79AVbmjzc"
      },
      "source": [
        "def split(a, n):\n",
        "    k, m = divmod(len(a), n)\n",
        "    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))\n",
        "\n",
        "def uni_bi_tri_counter(doc):\n",
        "    # print(doc)\n",
        "    tokenized = nlp.tokenizer.pipe([doc])\n",
        "    tokenized = [t.text for d in tokenized for t in d]\n",
        "    return Counter(make_unigrams(tokenized)), Counter(make_bigrams(tokenized)), Counter(make_trigrams(tokenized))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f9EoAmdm_cM"
      },
      "source": [
        "def bigram_gen(data):\n",
        "  data_list = data.split('.')\n",
        "  data_list = split(data_list,10)\n",
        "  bigram_counter = Counter()\n",
        "\n",
        "  for cur_data in data_list:\n",
        "    cur_data += ' .'\n",
        "    cur_data = ' . '.join(cur_data)\n",
        "    cur_unigram_counter, cur_bigram_counter, cur_trigram_counter = uni_bi_tri_counter(cur_data)\n",
        "    bigram_counter += cur_bigram_counter\n",
        "  return bigram_counter"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqfBEnKOoIOE"
      },
      "source": [
        "bigram_counter = bigram_gen(text_q3)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Lb-tL2F3oepH",
        "outputId": "2728b8b3-d111-4daa-d433-555b9a6657ed"
      },
      "source": [
        "print(bigram_counter.most_common(10))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[((',', '\\n'), 23309), (('.', '\\n\\n'), 21552), (('.', ' '), 16138), (('.', '\\n'), 14622), ((',', 'and'), 7240), (('\\n', 'And'), 7145), (('.', ']'), 6767), (('=', '='), 6322), (('?', '\\n\\n'), 6044), (('\\n', 'I'), 4330)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOuBPcmfGnOe"
      },
      "source": [
        "b) Write a function to generate all unique trigrams from all documents in the dataset. The input of this function should be the concatenated dataset and the output should be the list of trigrams and their frequency. Display the top 10 most common trigrams and their frequency.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx5EC029gxNY"
      },
      "source": [
        "def trigram_gen(data):\n",
        "  data_list = data.split('.')\n",
        "  data_list = split(data_list,10)\n",
        "  trigram_counter = Counter()\n",
        "  for cur_data in data_list:\n",
        "    cur_data += ' .'\n",
        "    cur_data = ' . '.join(cur_data)\n",
        "    cur_unigram_counter, cur_bigram_counter, cur_trigram_counter = uni_bi_tri_counter(cur_data)\n",
        "    trigram_counter += cur_trigram_counter\n",
        "\n",
        "  return trigram_counter"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4FL_SGWot-p"
      },
      "source": [
        "trigram_counter = trigram_gen(text_q3)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tfqoN_1ioxwb",
        "outputId": "66eb5b9a-d981-4cf2-926f-4acdd58c69b3"
      },
      "source": [
        "print(trigram_counter.most_common(10))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(('=', '=', '='), 5309), ((',', '\\n', 'And'), 3568), (('.', ']', '\\n\\n'), 2965), (('.', '\\n', '['), 2556), (('.', ']', '\\n\\n\\n'), 2189), (('.', ' ', 'I'), 2006), (('\\n\\n', '[', 'Enter'), 1515), (('.', '\\n', 'I'), 1133), (('.', '\\n\\n', '['), 1092), (('.', ']', '\\n'), 1016)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQOBm9oQGpsc"
      },
      "source": [
        "c) Write a function to extract all unique NOUN and VERB tokens. The input of this function should be the concatenated dataset and the output should be two lists: one of the NOUN tokens and their frequency, the other list should be the VERB tokens and their counts. Display the top 10 most common NOUN and VERB tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50Tib2OAnyxU"
      },
      "source": [
        "def noun_verb_counter(doc):\n",
        "  tokenized = nlp(doc)\n",
        "  verb_tokens = [token.text for token in tokenized if token.pos_ == \"VERB\"]\n",
        "  noun_tokens = [token.text for token in tokenized if token.pos_ == \"NOUN\"]\n",
        "  return Counter(noun_tokens), Counter(verb_tokens)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4jAe5_vGpfu"
      },
      "source": [
        "def count_noun_verb(data):\n",
        "  data_list = data.split('.')\n",
        "  data_list = split(data_list,10)\n",
        "  noun_counter = Counter()\n",
        "  verb_counter = Counter()\n",
        "  for cur_data in data_list:\n",
        "    cur_data += ' .'\n",
        "    cur_data = ' . '.join(cur_data)\n",
        "    cur_noun_counter, cur_verb_counter = noun_verb_counter(cur_data)\n",
        "    noun_counter += cur_noun_counter\n",
        "    verb_counter += cur_verb_counter\n",
        "  # print(\"Top 10 Nouns:\")\n",
        "  # print(noun_counter.most_common(10))\n",
        "  # print(\"Top 10 Verbs:\")\n",
        "  # print(verb_counter.most_common(10))\n",
        "\n",
        "  return noun_counter, verb_counter\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_yh8OJWo9gw"
      },
      "source": [
        "noun_counter, verb_counter = count_noun_verb(text_q3)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oZjj4Tahpuln",
        "outputId": "2296188f-2aff-4506-dd31-cb9e579cf1a5"
      },
      "source": [
        "noun_counter.most_common(10)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('man', 2008),\n",
              " ('love', 1578),\n",
              " ('sir', 1307),\n",
              " ('t', 1179),\n",
              " ('heart', 1106),\n",
              " ('time', 1085),\n",
              " ('father', 1031),\n",
              " ('men', 976),\n",
              " ('life', 943),\n",
              " ('lord', 940)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vWl9AsSPp2Qh",
        "outputId": "91a2fff2-76fa-4902-f368-db573c7de791"
      },
      "source": [
        "verb_counter.most_common(10)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('will', 4455),\n",
              " ('shall', 3353),\n",
              " (\"'ll\", 2598),\n",
              " ('would', 2168),\n",
              " ('can', 1902),\n",
              " ('know', 1681),\n",
              " ('come', 1583),\n",
              " ('make', 1578),\n",
              " ('Enter', 1557),\n",
              " ('may', 1549)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVRuQqmAGswR"
      },
      "source": [
        "d) What do you think the most common bigrams and trigrams could be useful for? There is a particular method we have seen in this class to characterize a corpus that could benefit from having these bigrams/trigrams when the underlying text corpus can’t be shared. Please talk about this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tFxCyO1BvWE"
      },
      "source": [
        "Bigrams and trigrams are most commonly used for wide range of NLP tasks such as sentiment analysis and speech recognition.\n",
        "\n",
        "In text autofill tasks, where the model has to predict the next word based on current context bigrams and trigrams will be very useful. For every search, you don't have to parse through the entire dataset and find next word. you can just predict next word by ranking ngrams via frequency. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNxV9O9gWaQ_"
      },
      "source": [
        "Question 4) (30 points) Using the dataset: Ask0729, found in Exam files, write two functions to extract all dates found in this dataset. The input of these functions should take the dataset as input, and output a list of dates. You should use two different methods, one per function.\n",
        "\n",
        "a) First method: using SpaCy (this is a big enough hint)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezdw9AQTqejG"
      },
      "source": [
        "with open('/content/Ask0729-fixed.txt', 'r') as file:\n",
        "  data_4 = file.read()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RN_fQuKqSYp"
      },
      "source": [
        "def spacy_date_detection(data):\n",
        "  dates = []\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(data)\n",
        "\n",
        "  for ent in doc.ents:\n",
        "    if(ent.label_ == 'DATE'):\n",
        "      dates.append((ent.text, ent.start_char, ent.end_char, ent.label_))\n",
        "  \n",
        "  return dates"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n04gYo_qmnM"
      },
      "source": [
        "spacy_dates = spacy_date_detection(data_4)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-VrtIwk4r8GN",
        "outputId": "3589e17e-a8d5-4787-a12c-aa323cfb04eb"
      },
      "source": [
        "len(spacy_dates)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1033"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lek8_2nJqS0s"
      },
      "source": [
        "b) Second method: using regular expressions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6LqY8fXq77X"
      },
      "source": [
        "import re"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xevVGfe9WWWY"
      },
      "source": [
        "def regex_date_detection(s):\n",
        "  # x=re.find(\"^([1-9]|1[0-9]| 2[0-9]|3[0-1])(.|-)([1-9] |1[0-2])(.|-|)20[0-9][0-9]$\",\"hey 13-11-2017 ki\")\n",
        "  # x = re.findall(\"([1-9]|0[1-9]|1[0-9]|2[0-9]|3[0-1])(\\.|-|/)([1-9]|0[1-9]|1[0-2])(\\.|-|/)([0-9][0-9]|19[0-9][0-9]|20[0-9][0-9])$|^([0-9][0-9]|19[0-9][0-9]|20[0-9][0-9])(\\.|-|/)([1-9]|0[1-9]|1[0-2])(\\.|-|/)([1-9]|0[1-9]|1[0-9]|2[0-9]|3[0-1])\",'hey 01/01/2018')\n",
        "  # print(x.group())\n",
        "  # match = re.search(r'\\d{4}-\\d{2}-\\d{2}', \"hello 01-01-2018 01-01-2018\")\n",
        "  month_regex = \"(0?[1-9]|1[0-2])\"\n",
        "  day_regex = \"(0?[1-9]|1[0-9]|2[0-9])\"\n",
        "\n",
        "  p1 = re.findall(\"(0?[1-9]|1[0-2])-(0?[1-9]|1[0-9]|2[0-9])\",s)\n",
        "\n",
        "  p2 = re.findall(day_regex,s)\n",
        "\n",
        "  match = re.findall('\\d{4}-\\d{2}-\\d{2}', s) + re.findall('\\d{2}-\\d{2}-\\d{4}', s) + re.findall('\\d{2}/\\d{2}/\\d{4}', s) + re.findall('\\d{4}/\\d{2}/\\d{2}', s)\n",
        "  p3 = match\n",
        "\n",
        "  p4 = re.findall(r'(?:(?:31(\\/|-|\\.)(?:0?[13578]|1[02]|(?:Jan|Mar|May|Jul|Aug|Oct|Dec)))\\1|(?:(?:29|30)(\\/|-|\\.)(?:0?[1,3-9]|1[0-2]|(?:Jan|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec))\\2))(?:(?:1[6-9]|[2-9]\\d)?\\d{2})$|^(?:29(\\/|-|\\.)(?:0?2|(?:Feb))\\3(?:(?:(?:1[6-9]|[2-9]\\d)?(?:0[48]|[2468][048]|[13579][26])|(?:(?:16|[2468][048]|[3579][26])00))))$|^(?:0?[1-9]|1\\d|2[0-8])(\\/|-|\\.)(?:(?:0?[1-9]|(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep))|(?:1[0-2]|(?:Oct|Nov|Dec)))\\4(?:(?:1[6-9]|[2-9]\\d)?\\d{2})',s)\n",
        "\n",
        "  return p1 + p2 + p3 + p4"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqxAD63zrYPa"
      },
      "source": [
        "regex_dates = regex_date_detection(data_4)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "92K1WZvNr5_f",
        "outputId": "86df4464-a94f-4a74-d1ae-c035ba3a631f"
      },
      "source": [
        "len(regex_dates)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2519"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtAEew09qZuM"
      },
      "source": [
        "c) Print to screen to compare the results from the two functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d4aFNtfUqZdE",
        "outputId": "3b564417-e302-457a-9a18-4b3daf851b49"
      },
      "source": [
        "# spacy dates\n",
        "spacy_dates[:20]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('up to 5 years', 137, 150, 'DATE'),\n",
              " ('today', 184, 189, 'DATE'),\n",
              " ('today', 231, 236, 'DATE'),\n",
              " ('today', 1708, 1713, 'DATE'),\n",
              " ('one week', 1811, 1819, 'DATE'),\n",
              " ('MA 02143', 1905, 1913, 'DATE'),\n",
              " ('daily', 1993, 1998, 'DATE'),\n",
              " ('today', 2827, 2832, 'DATE'),\n",
              " ('3+ Nights & Save', 3002, 3018, 'DATE'),\n",
              " ('this week', 3106, 3115, 'DATE'),\n",
              " ('weekend', 3151, 3158, 'DATE'),\n",
              " ('this week', 3269, 3278, 'DATE'),\n",
              " ('2 Weeks', 4941, 4948, 'DATE'),\n",
              " ('the year', 6773, 6781, 'DATE'),\n",
              " ('tomorrow', 7713, 7721, 'DATE'),\n",
              " ('Wednesday', 8221, 8230, 'DATE'),\n",
              " ('Saturday', 8745, 8753, 'DATE'),\n",
              " ('the 6 year old', 8840, 8854, 'DATE'),\n",
              " ('tomorrow', 8970, 8978, 'DATE'),\n",
              " ('25 years', 9294, 9302, 'DATE')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jOHAcqHNsFAS",
        "outputId": "b35ced66-b15c-4c25-c5b0-9bdae05e9807"
      },
      "source": [
        "# regex dates\n",
        "regex_dates[:20]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('3', '9'),\n",
              " ('3', '1'),\n",
              " ('01', '8'),\n",
              " ('5', '1'),\n",
              " ('3', '6'),\n",
              " ('1', '3'),\n",
              " ('5', '2'),\n",
              " ('1', '8'),\n",
              " ('4', '05'),\n",
              " ('1', '7'),\n",
              " ('8', '8'),\n",
              " ('1', '3'),\n",
              " ('5', '2'),\n",
              " ('4', '1'),\n",
              " ('1', '2'),\n",
              " ('1', '3'),\n",
              " ('6', '4'),\n",
              " ('1', '2'),\n",
              " ('1', '3'),\n",
              " ('6', '5')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyGaW14XqcLQ"
      },
      "source": [
        "**d) Which one of the two approaches was better? Why do you think so? Would you use any of these approaches? Or a different one?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMBFLZCJsPpi"
      },
      "source": [
        "Spacy approach is better when compared to the above regex approach. The given dataset consists of dates in large number of formats and it is very difficult for a human to write regex expressions for all these formats. \n",
        "\n",
        "On the other hand spacy uses deep learning based CNN model for its NER task and the model is able to handle more date formats.\n",
        "\n",
        "Because of these reasons, I would prefer using spacy than writing regex for all date formats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JSJ0DyzWW01"
      },
      "source": [
        "Question 5) (30 points) Train an LSTM model to classify the Cornell Movie Review data using the polarity_dataset V2.0. You can use the code for class 19, but take a note that you will have to adapt some of the parameters like: Review size = 450, epochs=5. You will use 85% of the dataset for training, and 15% for testing. Once you build the model, please display the sklearn classification report. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MAQjhsmYpDr",
        "outputId": "d13fe4c6-ffe7-4404-adcf-e0e13277ea6c"
      },
      "source": [
        "!pip install numpy==1.16.2\n",
        "\n",
        "# All the imports!\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from numpy import array\n",
        "\n",
        "# Supress deprecation warnings\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.2 in /usr/local/lib/python3.7/dist-packages (1.16.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yiL8oHFWX3g"
      },
      "source": [
        "# unzipping the dataset\n",
        "!tar -xvf '/content/review_polarity.tar'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P6qb3IOWcJd"
      },
      "source": [
        "positive_file_paths = os.listdir('/content/txt_sentoken/pos') \n",
        "negative_file_paths = os.listdir('/content/txt_sentoken/neg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFJYIQfAWcG4"
      },
      "source": [
        "pos_text = []\n",
        "for path in positive_file_paths:\n",
        "  f = open(os.path.join('/content/txt_sentoken/pos',path),'r') \n",
        "  pos_text.append(f.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE4SwnMAWcEM"
      },
      "source": [
        "neg_text = []\n",
        "for path in negative_file_paths:\n",
        "  f = open(os.path.join('/content/txt_sentoken/neg',path),'r') \n",
        "  neg_text.append(f.read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j_PzubvZoxw"
      },
      "source": [
        "X = pos_text+neg_text\n",
        "y = [1 for i in range(len(pos_text))] + [0 for i in range(len(neg_text))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJY8mKmZZhix"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15,random_state=12345)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV5xlznWY3Rw"
      },
      "source": [
        "# encoding\n",
        "word_index = {}\n",
        "\n",
        "total_data = X_train + X_test\n",
        "\n",
        "i = 4\n",
        "for row in total_data:\n",
        "  for word in row.split(' '):\n",
        "    if(word not in word_index):\n",
        "      word_index[word] = i\n",
        "      i += 1\n",
        "\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNKNOWN>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADR-ISieZQ16"
      },
      "source": [
        "vocab_size = len(word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05xiIJOFZQzf"
      },
      "source": [
        "def encode_review(text):\n",
        "  lst = []\n",
        "\n",
        "  for i in text.split(' '):\n",
        "    lst.append(word_index[i])\n",
        "  \n",
        "  return lst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMwt1-WYaW69"
      },
      "source": [
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmW3-HwTaYqr"
      },
      "source": [
        "encoded_x_train = []\n",
        "\n",
        "for r in X_train:\n",
        "  encoded_x_train.append(encode_review(r))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvAOQMXHaair"
      },
      "source": [
        "encoded_x_test = []\n",
        "\n",
        "for r in X_test:\n",
        "  encoded_x_test.append(encode_review(r))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkWu5JsNacAk"
      },
      "source": [
        "X_train = encoded_x_train\n",
        "X_test = encoded_x_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7FwsuQsadgs"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JajxYEuafd2"
      },
      "source": [
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUAJZwzvag8s",
        "outputId": "adb7852e-cde8-48bb-ca21-9f8011829893"
      },
      "source": [
        "# The length of reviews\n",
        "review_length = 450\n",
        "\n",
        "# Padding / truncated our reviews\n",
        "X_train = sequence.pad_sequences(X_train, maxlen = review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen = review_length)\n",
        "\n",
        "# Check the size of our datasets. Review data for both test and training should \n",
        "# contain 25000 reviews of 500 integers. Class data should contain 25000 values, \n",
        "# one for each review. Class values are 0 or 1, indicating a negative \n",
        "# or positive review.\n",
        "print(\"Shape Training Review Data: \" + str(X_train.shape))\n",
        "print(\"Shape Training Class Data: \" + str(y_train.shape))\n",
        "print(\"Shape Test Review Data: \" + str(X_test.shape))\n",
        "print(\"Shape Test Class Data: \" + str(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape Training Review Data: (1700, 450)\n",
            "Shape Training Class Data: (1700,)\n",
            "Shape Test Review Data: (300, 450)\n",
            "Shape Test Class Data: (300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXAMxR57aovd",
        "outputId": "d72f847f-c7ea-428c-e9cf-1f08c1faf8be"
      },
      "source": [
        "# We begin by defining the a empty stack. We'll use this for building our \n",
        "# network, later by layer.\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# The Embedding Layer provides a spatial mapping (or Word Embedding) of all the \n",
        "# individual words in our training set. Words close to one another share context \n",
        "# and or meaning. This spatial mapping is learning during the training process.\n",
        "model.add(\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim = vocab_size, # The size of our vocabulary \n",
        "        output_dim = 32, # Dimensions to which each words shall be mapped\n",
        "        input_length = review_length # Length of input sequences\n",
        "    )\n",
        ")\n",
        "\n",
        "# Dropout layers fight overfitting and forces the model to learn multiple \n",
        "# representations of the same data by randomly disabling neurons in the \n",
        "# learning phase.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "# We are using a fast version of LSTM whih is optimised for GPUs. This layer \n",
        "# looks at the sequence of words in the review, along with their word embeddings\n",
        "# and uses both of these to determine to sentiment of a given review.\n",
        "model.add(\n",
        "    tf.keras.layers.LSTM(\n",
        "        units=32 # 32 LSTM units in this layer\n",
        "    )\n",
        ")\n",
        "\n",
        "# Add a second dropout layer with the same aim as the first.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "# All LSTM units are connected to a single node in the dense layer. A sigmoid \n",
        "# activation function determines the output from this node - a value \n",
        "# between 0 and 1. Closer to 0 indicates a negative review. Closer to 1 \n",
        "# indicates a positive review.\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1, # Single unit\n",
        "        activation='sigmoid' # Sigmoid activation function (output from 0 to 1)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy, # loss function\n",
        "    optimizer=tf.keras.optimizers.Adam(), # optimiser function\n",
        "    metrics=['accuracy']) # reporting metric\n",
        "\n",
        "# Display a summary of the models structure\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 450, 32)           1798496   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 450, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,806,849\n",
            "Trainable params: 1,806,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "_Y2PgsUQazPD",
        "outputId": "a9ee6aa1-6fac-4a44-8ce6-cb9670b3c872"
      },
      "source": [
        "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoqS10ONa1o1",
        "outputId": "20309920-d37b-42ee-9c09-48d00fb98c3f"
      },
      "source": [
        "# Train the LSTM on the training data\n",
        "history = model.fit(\n",
        "\n",
        "    # Training data : features (review) and classes (positive or negative)\n",
        "    X_train, y_train,\n",
        "                    \n",
        "    # Number of samples to work through before updating the \n",
        "    # internal model parameters via back propagation. The \n",
        "    # higher the batch, the more memory you need.\n",
        "    batch_size=256, \n",
        "\n",
        "    # An epoch is an iteration over the entire training data.\n",
        "    epochs=5, \n",
        "    \n",
        "    # The model will set apart his fraction of the training \n",
        "    # data, will not train on it, and will evaluate the loss\n",
        "    # and any model metrics on this data at the end of \n",
        "    # each epoch.\n",
        "    validation_split=0.2,\n",
        "    \n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "6/6 [==============================] - 6s 586ms/step - loss: 0.6932 - accuracy: 0.4789 - val_loss: 0.6931 - val_accuracy: 0.5176\n",
            "Epoch 2/5\n",
            "6/6 [==============================] - 3s 483ms/step - loss: 0.6921 - accuracy: 0.5640 - val_loss: 0.6927 - val_accuracy: 0.5147\n",
            "Epoch 3/5\n",
            "6/6 [==============================] - 3s 491ms/step - loss: 0.6908 - accuracy: 0.5342 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
            "Epoch 4/5\n",
            "6/6 [==============================] - 3s 479ms/step - loss: 0.6872 - accuracy: 0.5372 - val_loss: 0.6905 - val_accuracy: 0.5147\n",
            "Epoch 5/5\n",
            "6/6 [==============================] - 3s 479ms/step - loss: 0.6799 - accuracy: 0.5659 - val_loss: 0.6853 - val_accuracy: 0.5235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNn9hJFMbMgH",
        "outputId": "c86108b3-bf0d-4774-dd83-63cdd140ac06"
      },
      "source": [
        "# Get Model Predictions for test data\n",
        "from sklearn.metrics import classification_report\n",
        "predicted_classes = model.predict_classes(X_test)\n",
        "classification_report = classification_report(y_test, predicted_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTyH-L5ybZOD",
        "outputId": "c93f4703-017a-469f-b2c6-7de23b259799"
      },
      "source": [
        "print(classification_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.97      0.63       136\n",
            "           1       0.76      0.08      0.14       164\n",
            "\n",
            "    accuracy                           0.48       300\n",
            "   macro avg       0.62      0.52      0.39       300\n",
            "weighted avg       0.63      0.48      0.36       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOTrZh04tegJ"
      },
      "source": [
        "What are you noticing here? Anything unexpected? How does this model compare to the one built with the IMDB dataset in class? Any ideas on how to improve it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWGf0AXYtfVs"
      },
      "source": [
        "The LSTM model is displaying interesting behaviour. For most of the data in test set, it is predicting it as zeros. due to which the recall of zeros is 0.97 and the recall of ones is 0.08. The accuracy is also around 0.6, which clearly says that the model is predicting zeros for most of the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvh6sWMH8VH-"
      },
      "source": [
        "Question 6) (30 points) Use the train.txt file from the PubMed 20K RCT dataset fine-tune a BERT transformer (class 9 code). This task is a bit different as the one seen in class, here the source dataset has FIVE different classes: background, objective, method, result, and conclusion. Once the BERT model is fine-tuned, classify the: test.txt set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8AigDVe8teF"
      },
      "source": [
        "with open('/content/train.txt', 'r') as file:\n",
        "    data_6 = file.read()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5Ovrt73_PCo"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "labels = ['OBJECTIVE','RESULTS','METHODS','BACKGROUND','CONCLUSIONS']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PKzECWA8gIb"
      },
      "source": [
        "rows = data_6.split('\\n')\n",
        "for row in rows:\n",
        "  if(len(row.split('\\t')) == 2):\n",
        "    label, content = row.split('\\t')\n",
        "    if(label in labels):\n",
        "      y.append(labels.index(label))\n",
        "      X.append(content)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "brvb5LHyAeHw",
        "outputId": "f18434ec-6223-42ef-a4bb-cd8cc6ed0919"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xJTnnFDwBJom",
        "outputId": "85a89151-fe58-46ef-fcc8-d1e26898df98"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7qipn3VwBJmc",
        "outputId": "836d2805-c493-498f-9c48-65df2de72acd"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71cM8ywqCukx"
      },
      "source": [
        "sentences = X"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xq53I8uUIqUL",
        "outputId": "7b0778d7-f5e4-442a-e0d9-c2100999f25f"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.1', do_lower_case=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xxAY1HGHBJjo",
        "outputId": "57867059-ed11-4e03-c6fd-aacc6d688777"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "o_NmkbN5AeC7",
        "outputId": "a970bb4e-672e-40a4-d6a7-00907153f1da"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\n",
            "Tokenized:  ['to', 'investigate', 'the', 'efficacy', 'of', '6', 'weeks', 'of', 'daily', 'low', '-', 'dose', 'oral', 'pre', '##dn', '##is', '##olo', '##ne', 'in', 'improving', 'pain', ',', 'mobility', ',', 'and', 'systemic', 'low', '-', 'grade', 'inflammation', 'in', 'the', 'short', 'term', 'and', 'whether', 'the', 'effect', 'would', 'be', 'sustained', 'at', '12', 'weeks', 'in', 'older', 'adults', 'with', 'moderate', 'to', 'severe', 'knee', 'o', '##ste', '##oar', '##th', '##rit', '##is', '(', 'o', '##a', ')', '.']\n",
            "Token IDs:  [1106, 8242, 1103, 23891, 1104, 127, 2277, 1104, 3828, 1822, 118, 13753, 9619, 3073, 22834, 1548, 12805, 1673, 1107, 9248, 2489, 117, 16178, 117, 1105, 27410, 1822, 118, 3654, 24970, 1107, 1103, 1603, 1858, 1105, 2480, 1103, 2629, 1156, 1129, 8505, 1120, 1367, 2277, 1107, 2214, 6323, 1114, 8828, 1106, 5199, 5656, 184, 13894, 19243, 1582, 7729, 1548, 113, 184, 1161, 114, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tFDKLltObaqZ",
        "outputId": "34408483-66ee-4b1d-ca9f-67eb04e4d9f1"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True,max_length=512,truncation=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geHKeWADKqbe"
      },
      "source": [
        "max_len = 512"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzMnfE4iFZlW"
      },
      "source": [
        "labels = y"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2XXpdlhq_5FR",
        "outputId": "05761dd9-3c2e-4b61-903f-ffe1562a7332"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        truncation=True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\n",
            "Token IDs: tensor([  101,  1106,  8242,  1103, 23891,  1104,   127,  2277,  1104,  3828,\n",
            "         1822,   118, 13753,  9619,  3073, 22834,  1548, 12805,  1673,  1107,\n",
            "         9248,  2489,   117, 16178,   117,  1105, 27410,  1822,   118,  3654,\n",
            "        24970,  1107,  1103,  1603,  1858,  1105,  2480,  1103,  2629,  1156,\n",
            "         1129,  8505,  1120,  1367,  2277,  1107,  2214,  6323,  1114,  8828,\n",
            "         1106,  5199,  5656,   184, 13894, 19243,  1582,  7729,  1548,   113,\n",
            "          184,  1161,   114,   102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2VAeOcSiD9GA",
        "outputId": "ab86d168-57b8-4254-95d4-87543f3da9cc"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162,036 training samples\n",
            "18,004 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93RDvE8cEDG4"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e97rPzkEJqw"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fa9HyX7xEDzU",
        "outputId": "a1a1a3a8-0c63-499b-b7bf-f47037bbe33c"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 5, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7S9vFL4hEDwi",
        "outputId": "0f5763a5-d884-422e-c489-df9579a3561c"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (5, 768)\n",
            "classifier.bias                                                 (5,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ4clbMxERQU"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1wLunzyERNq"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0B3A4bOERLC"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er4qwblOEXvP"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dkzpDH2-EXnm",
        "outputId": "3b51e53c-9415-4079-f330-7627a91ee74e"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:14.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:28.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:00:42.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:00:56.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:01:11.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:01:26.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:01:40.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:01:55.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:02:24.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:02:38.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:02:53.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:03:07.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:03:22.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:03:36.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:03:51.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:04:06.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:04:20.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:04:35.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:04:49.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:05:04.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:05:18.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:05:33.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:05:48.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:06:02.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:06:17.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:06:31.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:06:46.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:07:00.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:07:15.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:07:29.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:07:44.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:07:58.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:08:13.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:08:27.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:08:42.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:08:57.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:09:11.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:09:26.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:09:40.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:09:55.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:10:09.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:10:24.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:10:38.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:10:53.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:11:07.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:11:22.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:11:37.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:11:51.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:12:06.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:12:20.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:12:35.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:12:49.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:13:04.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:13:18.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:13:33.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:13:48.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:14:02.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:14:17.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:14:31.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:14:46.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:15:00.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:15:15.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:15:29.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:15:44.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:15:59.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:16:13.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:16:28.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:16:42.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:16:57.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:17:11.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:17:26.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:17:40.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:17:55.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:18:09.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:18:24.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:18:38.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:18:53.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:19:08.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:19:22.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:19:37.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:19:51.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:20:06.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:20:20.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:20:35.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:20:49.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:21:04.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:21:19.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:21:33.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:21:48.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:22:02.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:22:17.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:22:31.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:22:46.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:23:00.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:23:15.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:23:29.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:23:44.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:23:59.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:24:13.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:24:28.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:24:42.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:24:57.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:25:11.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:25:26.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:25:40.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:25:55.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:26:09.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:26:24.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:26:38.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:26:53.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:27:07.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:27:22.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:27:36.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:27:51.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:28:06.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:28:20.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:28:35.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:28:49.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:29:04.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:29:18.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:29:33.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:29:47.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:30:02.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:30:16.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:30:31.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:30:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.37\n",
            "  Validation took: 0:01:08\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:15.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:29.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:00:44.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:00:58.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:01:13.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:01:27.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:01:42.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:01:56.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:02:11.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:02:25.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:02:40.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:02:55.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:03:09.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:03:24.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:03:38.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:03:53.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:04:07.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:04:22.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:04:36.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:04:51.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:05:05.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:05:20.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:05:34.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:05:49.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:06:04.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:06:18.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:06:33.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:06:47.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:07:02.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:07:16.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:07:31.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:07:45.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:08:00.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:08:14.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:08:29.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:08:43.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:08:58.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:09:13.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:09:27.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:09:42.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:09:56.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:10:11.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:10:25.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:10:40.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:10:54.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:11:09.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:11:23.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:11:38.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:11:52.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:12:07.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:12:22.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:12:36.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:12:51.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:13:05.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:13:20.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:13:34.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:13:49.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:14:03.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:14:18.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:14:32.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:14:47.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:15:01.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:15:16.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:15:31.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:15:45.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:16:00.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:16:14.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:16:29.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:16:43.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:16:58.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:17:12.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:17:27.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:17:41.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:17:56.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:18:10.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:18:25.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:18:39.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:18:54.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:19:08.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:19:23.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:19:38.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:19:52.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:20:07.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:20:21.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:20:36.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:20:50.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:21:05.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:21:19.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:21:34.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:21:48.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:22:03.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:22:18.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:22:32.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:22:47.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:23:01.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:23:16.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:23:30.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:23:45.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:23:59.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:24:14.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:24:29.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:24:43.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:24:58.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:25:12.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:25:27.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:25:41.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:25:56.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:26:10.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:26:25.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:26:39.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:26:54.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:27:08.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:27:23.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:27:38.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:27:52.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:28:07.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:28:21.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:28:36.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:28:50.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:29:05.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:29:20.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:29:34.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:29:49.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:30:03.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:30:18.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:30:32.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:30:41\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.37\n",
            "  Validation took: 0:01:08\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:15.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:29.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:00:44.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:00:58.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:01:13.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:01:27.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:01:42.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:01:56.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:02:11.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:02:26.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:02:40.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:02:55.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:03:09.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:03:24.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:03:38.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:03:53.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:04:07.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:04:22.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:04:36.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:04:51.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:05:05.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:05:20.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:05:34.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:05:49.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:06:03.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:06:18.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:06:33.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:06:47.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:07:02.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:07:16.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:07:31.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:07:45.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:08:00.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:08:14.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:08:29.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:08:43.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:08:58.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:09:12.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:09:27.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:09:41.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:09:56.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:10:10.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:10:25.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:10:39.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:10:54.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:11:09.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:11:23.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:11:38.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:11:52.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:12:07.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:12:21.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:12:36.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:12:50.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:13:05.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:13:19.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:13:34.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:13:48.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:14:03.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:14:18.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:14:32.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:14:47.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:15:01.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:15:16.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:15:30.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:15:45.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:15:59.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:16:14.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:16:28.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:16:43.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:16:57.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:17:12.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:17:26.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:17:41.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:17:55.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:18:10.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:18:25.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:18:39.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:18:54.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:19:08.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:19:23.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:19:37.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:19:52.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:20:06.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:20:21.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:20:36.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:20:50.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:21:05.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:21:19.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:21:34.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:21:48.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:22:03.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:22:17.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:22:32.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:22:46.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:23:01.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:23:15.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:23:30.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:23:44.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:23:59.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:24:14.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:24:28.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:24:43.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:24:57.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:25:12.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:25:26.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:25:41.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:25:55.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:26:10.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:26:24.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:26:39.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:26:53.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:27:08.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:27:22.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:27:37.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:27:51.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:28:06.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:28:20.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:28:35.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:28:50.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:29:04.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:29:19.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:29:33.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:29:48.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:30:02.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:30:17.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:30:31.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:30:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.38\n",
            "  Validation took: 0:01:08\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:15.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:29.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:00:44.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:00:58.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:01:13.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:01:27.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:01:42.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:01:56.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:02:11.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:02:25.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:02:40.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:02:54.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:03:09.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:03:23.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:03:38.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:03:52.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:04:07.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:04:21.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:04:36.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:04:51.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:05:05.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:05:20.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:05:34.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:05:49.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:06:03.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:06:18.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:06:32.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:06:47.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:07:01.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:07:16.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:07:30.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:07:45.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:07:59.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:08:14.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:08:28.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:08:43.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:08:57.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:09:12.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:09:27.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:09:41.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:09:56.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:10:10.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:10:25.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:10:39.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:10:54.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:11:08.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:11:23.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:11:37.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:11:52.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:12:06.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:12:21.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:12:36.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:12:50.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:13:05.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:13:19.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:13:34.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:13:48.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:14:03.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:14:17.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:14:32.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:14:46.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:15:01.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:15:15.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:15:30.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:15:44.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:15:59.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:16:13.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:16:28.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:16:43.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:16:57.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:17:12.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:17:26.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:17:41.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:17:55.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:18:10.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:18:24.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:18:39.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:18:53.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:19:08.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:19:22.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:19:37.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:19:51.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:20:06.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:20:20.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:20:35.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:20:49.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:21:04.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:21:18.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:21:33.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:21:47.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:22:02.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:22:16.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:22:31.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:22:46.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:23:00.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:23:15.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:23:29.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:23:44.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:23:58.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VScalcQJlFM1"
      },
      "source": [
        "model = torch.load('/content/model_complete')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odCerYAP_o9I"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1OQwQy3_0ot"
      },
      "source": [
        "with open('/content/test.txt', 'r') as file:\n",
        "    data_test = file.read()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCSjm7bfADTj"
      },
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "labels = ['OBJECTIVE','RESULTS','METHODS','BACKGROUND','CONCLUSIONS']\n",
        "\n",
        "rows = data_test.split('\\n')\n",
        "for row in rows:\n",
        "  if(len(row.split('\\t')) == 2):\n",
        "    label, content = row.split('\\t')\n",
        "    if(label in labels):\n",
        "      y_test.append(labels.index(label))\n",
        "      X_test.append(content)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xewX1sIAbru"
      },
      "source": [
        "sentences = X_test\n",
        "labels = y_test"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z76o4AeNvwr-"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BGqlQaSU-5gH",
        "outputId": "3cc09b74-e31b-419c-8493-e681e5cf1377"
      },
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Load the dataset into a pandas dataframe.\n",
        "# df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# # Report the number of sentences.\n",
        "# print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# # Create sentence and label lists\n",
        "# sentences = df.sentence.values\n",
        "# labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        truncation=True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZUWKwi35-5c6",
        "outputId": "4884866e-d93c-4650-9053-a4e7df705da7"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 30,135 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3ajr03Dxl5M"
      },
      "source": [
        "Please present the per-class classification report (accuracy, precision, recall, f1-score metrics). Also, present the global metrics - all classes (accuracy, precision, recall, f1-score metrics). Did you model beat the baseline results (https://arxiv.org/pdf/1710.06071.pdf)? What do you think you can do to improve it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlIcegT2yT1D"
      },
      "source": [
        "predictions_final = []\n",
        "\n",
        "for batch_pred in predictions:\n",
        "  predictions_final.extend(np.argmax(batch_pred, axis=1).flatten())"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz2Ci3guzXP0"
      },
      "source": [
        "true_final = []\n",
        "\n",
        "for batch_pred in true_labels:\n",
        "  true_final.extend(batch_pred)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAA2IKyGzU0L"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "meqspk2Qy0Mh",
        "outputId": "66a911dd-69c2-4013-d761-694cdd736916"
      },
      "source": [
        "print(classification_report(true_final, predictions_final, digits=4))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6994    0.6074    0.6501      2333\n",
            "           1     0.9247    0.9023    0.9133      9713\n",
            "           2     0.9256    0.9472    0.9363      9897\n",
            "           3     0.6858    0.7735    0.7271      3621\n",
            "           4     0.8400    0.8123    0.8259      4571\n",
            "\n",
            "    accuracy                         0.8651     30135\n",
            "   macro avg     0.8151    0.8085    0.8106     30135\n",
            "weighted avg     0.8660    0.8651    0.8649     30135\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz0Gv0KFDpDn"
      },
      "source": [
        "## Bonus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agTwRCQ5Dry6"
      },
      "source": [
        "BioBert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0LVnIu4kyzuH",
        "outputId": "82bdc379-f0ea-447b-88a9-3b972b01f851"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"dmis-lab/biobert-base-cased-v1.1\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 5, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jYJpxXP0ECiS",
        "outputId": "145613b2-a193-47ef-80bd-d0f2e8c4c376"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (28996, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (5, 768)\n",
            "classifier.bias                                                 (5,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEz0JgJ0ECe7"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 1\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_jompaICccH"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))   "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "c2mwneGREZJU",
        "outputId": "d87898db-fc51-43aa-f06b-63a3726f5da8"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:15.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:29.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:00:44.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:00:58.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:01:12.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:01:27.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:01:41.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:01:56.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:02:10.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:02:24.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:02:39.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:02:53.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:03:08.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:03:22.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:03:36.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:03:51.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:04:05.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:04:20.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:04:34.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:04:49.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:05:03.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:05:17.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:05:32.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:05:46.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:06:00.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:06:15.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:06:29.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:06:44.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:06:58.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:07:12.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:07:27.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:07:41.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:07:56.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:08:10.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:08:24.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:08:39.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:08:53.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:09:08.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:09:22.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:09:37.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:09:51.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:10:06.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:10:20.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:10:35.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:10:49.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:11:04.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:11:18.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:11:33.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:11:47.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:12:02.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:12:16.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:12:30.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:12:45.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:12:59.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:13:14.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:13:28.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:13:43.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:13:57.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:14:11.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:14:26.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:14:40.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:14:55.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:15:09.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:15:23.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:15:38.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:15:52.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:16:07.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:16:21.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:16:35.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:16:50.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:17:04.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:17:19.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:17:33.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:17:47.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:18:02.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:18:16.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:18:31.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:18:45.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:18:59.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:19:14.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:19:28.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:19:43.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:19:57.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:20:12.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:20:26.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:20:41.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:20:55.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:21:10.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:21:24.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:21:39.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:21:53.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:22:07.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:22:22.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:22:36.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:22:51.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:23:05.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:23:20.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:23:34.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:23:48.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:24:03.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:24:17.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:24:32.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:24:46.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:25:00.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:25:15.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:25:29.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:25:44.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:25:58.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:26:12.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:26:27.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:26:41.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:26:55.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:27:10.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:27:24.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:27:39.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:27:53.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:28:07.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:28:22.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:28:36.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:28:50.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:29:05.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:29:19.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:29:34.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:29:48.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:30:02.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:30:17.\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epcoh took: 0:30:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.34\n",
            "  Validation took: 0:01:07\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:31:32 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u64UOjzaEXVK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}